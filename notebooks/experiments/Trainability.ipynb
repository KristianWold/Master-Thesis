{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import qiskit as qk\n",
    "import matplotlib.pyplot as plt\n",
    "from qiskit import Aer\n",
    "from tqdm.notebook import tqdm\n",
    "import multiprocessing as mp\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../src/')\n",
    "from neuralnetwork import *\n",
    "from analysis import *\n",
    "from utils import *\n",
    "\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = Aer.get_backend('qasm_simulator')\n",
    "\n",
    "def parallel(args):\n",
    "    model = args[0]\n",
    "    x = args[1]\n",
    "    y = args[2]\n",
    "    verbose = args[3]\n",
    "    \n",
    "    model.train(x, y, verbose = verbose)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainability, Ideal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D, Gaussian Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "x = np.linspace(0, 1, n).reshape(-1,1)\n",
    "y = gaussian(x, 0.2, 0.01) - gaussian(x, 0.5, 0.01) + gaussian(x, 0.8, 0.01)\n",
    "\n",
    "x_qcn = scaler(x, a=-np.pi/2, b=np.pi/2)\n",
    "x_dnn = scaler(x, mode=\"standard\")\n",
    "y = scaler(y, a=0, b=1)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_qcn, y, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.14081725856495322\n",
      "epoch: 1, loss: 0.12218127948324799\n",
      "epoch: 2, loss: 0.11159762924623241\n",
      "epoch: 3, loss: 0.09973295329258035\n",
      "epoch: 4, loss: 0.08788048826130765\n",
      "epoch: 5, loss: 0.07522901969429212\n",
      "epoch: 6, loss: 0.05868457408361196\n",
      "epoch: 7, loss: 0.04256620730947176\n",
      "epoch: 8, loss: 0.03184672966793481\n",
      "epoch: 9, loss: 0.026789651352350917\n",
      "epoch: 10, loss: 0.02300728113781846\n",
      "epoch: 11, loss: 0.01896895766838567\n",
      "epoch: 12, loss: 0.015751098981688513\n",
      "epoch: 13, loss: 0.01315123202034696\n",
      "epoch: 14, loss: 0.010853290109319222\n",
      "epoch: 15, loss: 0.007928079932426108\n",
      "epoch: 16, loss: 0.005262863024656155\n",
      "epoch: 17, loss: 0.004734152317330536\n",
      "epoch: 18, loss: 0.006117339318444033\n",
      "epoch: 19, loss: 0.006659604777229462\n",
      "epoch: 20, loss: 0.005469015714841625\n",
      "epoch: 21, loss: 0.004092134221492467\n",
      "epoch: 22, loss: 0.0036396501292210114\n",
      "epoch: 23, loss: 0.0036018735331683604\n",
      "epoch: 24, loss: 0.0032680459067654165\n",
      "epoch: 25, loss: 0.0028867927659748972\n",
      "epoch: 26, loss: 0.0030097458835733324\n",
      "epoch: 27, loss: 0.0036310962412130473\n",
      "epoch: 28, loss: 0.004260313883518693\n",
      "epoch: 29, loss: 0.004487483372086583\n",
      "epoch: 30, loss: 0.004247732105367181\n",
      "epoch: 31, loss: 0.0037665258591838653\n",
      "epoch: 32, loss: 0.003377521057742446\n",
      "epoch: 33, loss: 0.0032554649146857902\n",
      "epoch: 34, loss: 0.00328820553554998\n",
      "epoch: 35, loss: 0.003269900809948182\n",
      "epoch: 36, loss: 0.003173018013703346\n",
      "epoch: 37, loss: 0.003114729156248279\n",
      "epoch: 38, loss: 0.0031079628555012286\n",
      "epoch: 39, loss: 0.0030057260123090134\n",
      "epoch: 40, loss: 0.002719908254321852\n",
      "epoch: 41, loss: 0.0023682935853359278\n",
      "epoch: 42, loss: 0.002138832353668646\n",
      "epoch: 43, loss: 0.0020782198056963665\n",
      "epoch: 44, loss: 0.0020702700869914734\n",
      "epoch: 45, loss: 0.001983981382004113\n",
      "epoch: 46, loss: 0.00178693900951675\n",
      "epoch: 47, loss: 0.0015410284414721722\n",
      "epoch: 48, loss: 0.0013403519278797629\n",
      "epoch: 49, loss: 0.0012373746099387703\n",
      "epoch: 50, loss: 0.001202804665884271\n",
      "epoch: 51, loss: 0.0011665265487456923\n",
      "epoch: 52, loss: 0.0010897106367072924\n",
      "epoch: 53, loss: 0.000984352834682742\n",
      "epoch: 54, loss: 0.0008813281166845374\n",
      "epoch: 55, loss: 0.000805547762213187\n",
      "epoch: 56, loss: 0.0007732709139275195\n",
      "epoch: 57, loss: 0.0007755856653510814\n",
      "epoch: 58, loss: 0.0007738773013476441\n",
      "epoch: 59, loss: 0.0007401848345614012\n",
      "epoch: 60, loss: 0.0006861055945391802\n",
      "epoch: 61, loss: 0.000645392461452754\n",
      "epoch: 62, loss: 0.0006373040549217615\n",
      "epoch: 63, loss: 0.0006468924692050221\n",
      "epoch: 64, loss: 0.0006479488334871984\n",
      "epoch: 65, loss: 0.000634189344098436\n",
      "epoch: 66, loss: 0.0006145404063468089\n",
      "epoch: 67, loss: 0.000596901302113827\n",
      "epoch: 68, loss: 0.0005845140550508927\n",
      "epoch: 69, loss: 0.0005782298667287303\n",
      "epoch: 70, loss: 0.0005786505476702263\n",
      "epoch: 71, loss: 0.000582501148615198\n",
      "epoch: 72, loss: 0.000582162340817238\n",
      "epoch: 73, loss: 0.0005755630333536512\n",
      "epoch: 74, loss: 0.0005681730039991101\n",
      "epoch: 75, loss: 0.000563872113763558\n",
      "epoch: 76, loss: 0.0005622118337190689\n",
      "epoch: 77, loss: 0.0005622382634431302\n",
      "epoch: 78, loss: 0.0005638452043257866\n",
      "epoch: 79, loss: 0.0005661864679855938\n",
      "epoch: 80, loss: 0.0005668402173238832\n",
      "epoch: 81, loss: 0.0005647790276810137\n",
      "epoch: 82, loss: 0.0005624067040626365\n",
      "epoch: 83, loss: 0.0005617146406560909\n",
      "epoch: 84, loss: 0.0005619236004256894\n",
      "epoch: 85, loss: 0.0005622779706736511\n",
      "epoch: 86, loss: 0.000562929975648865\n",
      "epoch: 87, loss: 0.0005633468554580512\n",
      "epoch: 88, loss: 0.0005625956349070136\n",
      "epoch: 89, loss: 0.000560799142706766\n",
      "epoch: 90, loss: 0.0005592866905884367\n",
      "epoch: 91, loss: 0.0005588198246923486\n",
      "epoch: 92, loss: 0.0005587592157118892\n",
      "epoch: 93, loss: 0.0005586940945420528\n",
      "epoch: 94, loss: 0.00055881535793053\n",
      "epoch: 95, loss: 0.0005588162847597964\n",
      "epoch: 96, loss: 0.0005583385593080314\n",
      "epoch: 97, loss: 0.0005577097234659195\n",
      "epoch: 98, loss: 0.0005574614340915969\n",
      "epoch: 99, loss: 0.0005576006132544121\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qcn_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = [4, 4],\n",
    "                         dim = [1, 4, 1],\n",
    "                         encoder = Encoder(),\n",
    "                         ansatz = Ansatz(blocks = [\"entangle\", \"ry\"], reps=1),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         shots = 0)\n",
    "    \n",
    "    qcn_list.append([qcn, x_qcn, y, False])\n",
    "\n",
    "    \n",
    "qcn_list[0][3] = True\n",
    "\n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list) \n",
    "    \n",
    "    \n",
    "saver(qcn_list, data_path(\"trainability_qcn_1D_reps_1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.1530543579647957\n",
      "epoch: 1, loss: 0.08411293862964309\n",
      "epoch: 2, loss: 0.08695614588945234\n",
      "epoch: 3, loss: 0.06563699784519417\n",
      "epoch: 4, loss: 0.037318441848250346\n",
      "epoch: 5, loss: 0.023841717281163185\n",
      "epoch: 6, loss: 0.02608004525145454\n",
      "epoch: 7, loss: 0.02486742102346641\n",
      "epoch: 8, loss: 0.018464607872809707\n",
      "epoch: 9, loss: 0.015072543956755136\n",
      "epoch: 10, loss: 0.015684929982633503\n",
      "epoch: 11, loss: 0.014439573721482604\n",
      "epoch: 12, loss: 0.01189909051971972\n",
      "epoch: 13, loss: 0.01134299027180258\n",
      "epoch: 14, loss: 0.010896518864616228\n",
      "epoch: 15, loss: 0.010045964490913339\n",
      "epoch: 16, loss: 0.010206294336565131\n",
      "epoch: 17, loss: 0.008853001259006385\n",
      "epoch: 18, loss: 0.006128191247238835\n",
      "epoch: 19, loss: 0.0053361143389323825\n",
      "epoch: 20, loss: 0.006032957207159386\n",
      "epoch: 21, loss: 0.005757641665438011\n",
      "epoch: 22, loss: 0.004872776553348238\n",
      "epoch: 23, loss: 0.004358048374766876\n",
      "epoch: 24, loss: 0.004104977176322313\n",
      "epoch: 25, loss: 0.004238960931233941\n",
      "epoch: 26, loss: 0.004647830810957601\n",
      "epoch: 27, loss: 0.004359106379833867\n",
      "epoch: 28, loss: 0.00334219626017328\n",
      "epoch: 29, loss: 0.002810878866164143\n",
      "epoch: 30, loss: 0.0031353497089855226\n",
      "epoch: 31, loss: 0.0033397830759233573\n",
      "epoch: 32, loss: 0.002977629469640855\n",
      "epoch: 33, loss: 0.0024797849044676757\n",
      "epoch: 34, loss: 0.0022099423348131944\n",
      "epoch: 35, loss: 0.0021742550713117373\n",
      "epoch: 36, loss: 0.0021515173342248613\n",
      "epoch: 37, loss: 0.0019173454795368638\n",
      "epoch: 38, loss: 0.001610910113393643\n",
      "epoch: 39, loss: 0.0015988023637517038\n",
      "epoch: 40, loss: 0.0017357859193577545\n",
      "epoch: 41, loss: 0.001558307215508575\n",
      "epoch: 42, loss: 0.0012391781782478339\n",
      "epoch: 43, loss: 0.001198839550778496\n",
      "epoch: 44, loss: 0.0013105122241875034\n",
      "epoch: 45, loss: 0.0012448435594393816\n",
      "epoch: 46, loss: 0.001071134236150794\n",
      "epoch: 47, loss: 0.0010289562773155496\n",
      "epoch: 48, loss: 0.0010644695994747363\n",
      "epoch: 49, loss: 0.0009888425263565677\n",
      "epoch: 50, loss: 0.0008704279707044039\n",
      "epoch: 51, loss: 0.0008495923096224225\n",
      "epoch: 52, loss: 0.0008694814985960426\n",
      "epoch: 53, loss: 0.0008310452040200053\n",
      "epoch: 54, loss: 0.0007659798270945238\n",
      "epoch: 55, loss: 0.0007438804713442052\n",
      "epoch: 56, loss: 0.0007384750734855291\n",
      "epoch: 57, loss: 0.0006927091816901736\n",
      "epoch: 58, loss: 0.0006425266368248438\n",
      "epoch: 59, loss: 0.0006460759379229622\n",
      "epoch: 60, loss: 0.0006405337349108272\n",
      "epoch: 61, loss: 0.0005908919689852072\n",
      "epoch: 62, loss: 0.0005799316443038489\n",
      "epoch: 63, loss: 0.000582497418311257\n",
      "epoch: 64, loss: 0.0005339079901323491\n",
      "epoch: 65, loss: 0.0005164848569844854\n",
      "epoch: 66, loss: 0.0005259353636386089\n",
      "epoch: 67, loss: 0.0004888021334282328\n",
      "epoch: 68, loss: 0.0004784698574777451\n",
      "epoch: 69, loss: 0.00048601261099832574\n",
      "epoch: 70, loss: 0.00045250793799533743\n",
      "epoch: 71, loss: 0.0004464372354121109\n",
      "epoch: 72, loss: 0.00044520541933199784\n",
      "epoch: 73, loss: 0.00041880026323132014\n",
      "epoch: 74, loss: 0.00042081495306769355\n",
      "epoch: 75, loss: 0.0004149335366121433\n",
      "epoch: 76, loss: 0.0003983907145516785\n",
      "epoch: 77, loss: 0.0004009732492654074\n",
      "epoch: 78, loss: 0.0003898198248847042\n",
      "epoch: 79, loss: 0.00037969727069121306\n",
      "epoch: 80, loss: 0.0003794018926799666\n",
      "epoch: 81, loss: 0.0003685841619299878\n",
      "epoch: 82, loss: 0.0003648415457837697\n",
      "epoch: 83, loss: 0.0003629321167965403\n",
      "epoch: 84, loss: 0.00035405610308208947\n",
      "epoch: 85, loss: 0.0003530159933843051\n",
      "epoch: 86, loss: 0.0003473771149534732\n",
      "epoch: 87, loss: 0.0003412105699152452\n",
      "epoch: 88, loss: 0.000340443279502643\n",
      "epoch: 89, loss: 0.00033335088534244334\n",
      "epoch: 90, loss: 0.00033197451568046563\n",
      "epoch: 91, loss: 0.00032834474564690213\n",
      "epoch: 92, loss: 0.0003234378845126596\n",
      "epoch: 93, loss: 0.0003222638602245858\n",
      "epoch: 94, loss: 0.00031652608919150767\n",
      "epoch: 95, loss: 0.00031492261046964584\n",
      "epoch: 96, loss: 0.0003112512831016104\n",
      "epoch: 97, loss: 0.00030805108185185493\n",
      "epoch: 98, loss: 0.00030614738498880065\n",
      "epoch: 99, loss: 0.0003022677870944786\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qcn_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = [4, 4],\n",
    "                         dim = [1, 4, 1],\n",
    "                         encoder= Encoder(),\n",
    "                         ansatz = Ansatz(blocks = [\"entangle\", \"ry\"], reps=2),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         shots=0)\n",
    "    \n",
    "    qcn_list.append([qcn, x_qcn, y, False])\n",
    "\n",
    "qcn_list[0][3] = True    \n",
    "    \n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list)     \n",
    "    \n",
    "saver(qcn_list, data_path(\"trainability_qcn_1D_reps_2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dnn_list = []\n",
    "for i in range(10):\n",
    "    dnn = sequential_dnn(dim = [1, 5, 1],\n",
    "                         optimizer = Adam(lr=0.1))\n",
    "    \n",
    "    dnn.train(x_dnn, y, epochs=100)\n",
    "    dnn_list.append(dnn)\n",
    "\n",
    "saver(dnn_list, data_path(\"trainability_dnn_1D_epochs_100\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dnn_list = []\n",
    "for i in range(10):\n",
    "    dnn = sequential_dnn(dim = [1, 5, 1],\n",
    "                         optimizer = Adam(lr=0.1))\n",
    "    \n",
    "    dnn.train(x_dnn, y, epochs=10000)\n",
    "    dnn_list.append(dnn)\n",
    "\n",
    "saver(dnn_list, data_path(\"trainability_dnn_1D_epochs_10000\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n = 12\n",
    "x = np.linspace(0, 1, n)\n",
    "x = generate_meshgrid([x,x])\n",
    "\n",
    "mean1 = np.array([[0.2, 0.8]])\n",
    "var1 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "mean2 = np.array([[0.5, 0.8]])\n",
    "var2 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "mean3 = np.array([[0.8, 0.8]])\n",
    "var3 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "mean4 = np.array([[0.2, 0.5]])\n",
    "var4 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "mean5 = np.array([[0.5, 0.5]])\n",
    "var5 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "mean6 = np.array([[0.8, 0.5]])\n",
    "var6 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "mean7 = np.array([[0.2, 0.2]])\n",
    "var7 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "mean8 = np.array([[0.5, 0.2]])\n",
    "var8 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "mean9 = np.array([[0.8, 0.2]])\n",
    "var9 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "\n",
    "y = gaussian(x, mean1, var1) - gaussian(x, mean2, var2) + gaussian(x, mean3, var3) - gaussian(x, mean4, var4) +\\\n",
    "gaussian(x, mean5, var5) - gaussian(x, mean6, var6) + gaussian(x, mean7, var7) - gaussian(x, mean8, var8) +\\\n",
    "gaussian(x, mean9, var9)\n",
    "\n",
    "\n",
    "x_qcn = scaler(x, a=-np.pi/2, b=np.pi/2)\n",
    "x_dnn = scaler(x, mode=\"standard\")\n",
    "y = scaler(y, a=0, b=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(y.reshape(n,n))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.09783735088606117\n",
      "epoch: 1, loss: 0.06373078458353953\n",
      "epoch: 2, loss: 0.0617285178205876\n",
      "epoch: 3, loss: 0.05469282392788234\n",
      "epoch: 4, loss: 0.05075490654825418\n",
      "epoch: 5, loss: 0.047835554437980723\n",
      "epoch: 6, loss: 0.04660724059785007\n",
      "epoch: 7, loss: 0.045598964667709976\n",
      "epoch: 8, loss: 0.043476618670068835\n",
      "epoch: 9, loss: 0.040396470670807705\n",
      "epoch: 10, loss: 0.03903326006257023\n",
      "epoch: 11, loss: 0.03909610469295487\n",
      "epoch: 12, loss: 0.03905794559356885\n",
      "epoch: 13, loss: 0.03820819647726504\n",
      "epoch: 14, loss: 0.03662139993038411\n",
      "epoch: 15, loss: 0.0352118865546723\n",
      "epoch: 16, loss: 0.034447654148563524\n",
      "epoch: 17, loss: 0.0340536790777196\n",
      "epoch: 18, loss: 0.0333509837367035\n",
      "epoch: 19, loss: 0.032407860087998966\n",
      "epoch: 20, loss: 0.03172596167928474\n",
      "epoch: 21, loss: 0.031128909807777865\n",
      "epoch: 22, loss: 0.030247218901869672\n",
      "epoch: 23, loss: 0.029608191918649322\n",
      "epoch: 24, loss: 0.029221284534123402\n",
      "epoch: 25, loss: 0.02885029310191234\n",
      "epoch: 26, loss: 0.0283726620688898\n",
      "epoch: 27, loss: 0.027557747395261307\n",
      "epoch: 28, loss: 0.02704473173374493\n",
      "epoch: 29, loss: 0.026908851982515376\n",
      "epoch: 30, loss: 0.02683924403726103\n",
      "epoch: 31, loss: 0.026468526443582108\n",
      "epoch: 32, loss: 0.025773259773914262\n",
      "epoch: 33, loss: 0.025398478048975548\n",
      "epoch: 34, loss: 0.025072927278036828\n",
      "epoch: 35, loss: 0.024552848766253382\n",
      "epoch: 36, loss: 0.024332571437920884\n",
      "epoch: 37, loss: 0.024358057589563165\n",
      "epoch: 38, loss: 0.024033969595502035\n",
      "epoch: 39, loss: 0.023656411122864214\n",
      "epoch: 40, loss: 0.023683424082429086\n",
      "epoch: 41, loss: 0.023682032817433876\n",
      "epoch: 42, loss: 0.02340545002240961\n",
      "epoch: 43, loss: 0.023169009744441874\n",
      "epoch: 44, loss: 0.023066740143007566\n",
      "epoch: 45, loss: 0.022911485144126022\n",
      "epoch: 46, loss: 0.022729563871837184\n",
      "epoch: 47, loss: 0.022558529914945138\n",
      "epoch: 48, loss: 0.02236965020381752\n",
      "epoch: 49, loss: 0.02214729320748979\n",
      "epoch: 50, loss: 0.022029081872489944\n",
      "epoch: 51, loss: 0.021865361449957946\n",
      "epoch: 52, loss: 0.02161304039567763\n",
      "epoch: 53, loss: 0.02151761041192479\n",
      "epoch: 54, loss: 0.021348947192850503\n",
      "epoch: 55, loss: 0.021183271083566078\n",
      "epoch: 56, loss: 0.021046631604077062\n",
      "epoch: 57, loss: 0.020945330908578093\n",
      "epoch: 58, loss: 0.020825998700768955\n",
      "epoch: 59, loss: 0.020811886890619056\n",
      "epoch: 60, loss: 0.020823769759208258\n",
      "epoch: 61, loss: 0.021061021932152313\n",
      "epoch: 62, loss: 0.021416002993613212\n",
      "epoch: 63, loss: 0.021020626729007875\n",
      "epoch: 64, loss: 0.02035620052846799\n",
      "epoch: 65, loss: 0.020615263879604995\n",
      "epoch: 66, loss: 0.020836328155436\n",
      "epoch: 67, loss: 0.020270619224420867\n",
      "epoch: 68, loss: 0.02022022740238814\n",
      "epoch: 69, loss: 0.02047479995498436\n",
      "epoch: 70, loss: 0.020104220828552115\n",
      "epoch: 71, loss: 0.01998182794661378\n",
      "epoch: 72, loss: 0.020128846232355713\n",
      "epoch: 73, loss: 0.01978121790149277\n",
      "epoch: 74, loss: 0.019782477669192992\n",
      "epoch: 75, loss: 0.01978803546019833\n",
      "epoch: 76, loss: 0.01951215953552739\n",
      "epoch: 77, loss: 0.019588311564163526\n",
      "epoch: 78, loss: 0.019485176103252462\n",
      "epoch: 79, loss: 0.01935924266559529\n",
      "epoch: 80, loss: 0.019416206395205443\n",
      "epoch: 81, loss: 0.01928635119385372\n",
      "epoch: 82, loss: 0.019256625346529655\n",
      "epoch: 83, loss: 0.019273129162201863\n",
      "epoch: 84, loss: 0.019166518836307548\n",
      "epoch: 85, loss: 0.019188086384558503\n",
      "epoch: 86, loss: 0.019163710610563975\n",
      "epoch: 87, loss: 0.019100022576016742\n",
      "epoch: 88, loss: 0.01913524889448835\n",
      "epoch: 89, loss: 0.019089106712008433\n",
      "epoch: 90, loss: 0.01906160484274793\n",
      "epoch: 91, loss: 0.01908864718227319\n",
      "epoch: 92, loss: 0.01904951605468379\n",
      "epoch: 93, loss: 0.01904055824250255\n",
      "epoch: 94, loss: 0.01906092886452032\n",
      "epoch: 95, loss: 0.0190280820498296\n",
      "epoch: 96, loss: 0.019024968956750536\n",
      "epoch: 97, loss: 0.01903771401927934\n",
      "epoch: 98, loss: 0.01901279870532172\n",
      "epoch: 99, loss: 0.019005932664214454\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qcn_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = [4, 4, 4],\n",
    "                         dim = [2, 4, 4, 1],\n",
    "                         encoder= Encoder(),\n",
    "                         ansatz = Ansatz(blocks = [\"entangle\", \"ry\"], reps=1),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         backend=backend,\n",
    "                         shots=0)\n",
    "    qcn_list.append([qcn, x_qcn, y, False])\n",
    "    \n",
    "qcn_list[0][3] = True    \n",
    "    \n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list)   \n",
    "\n",
    "saver(qcn_list, data_path(\"trainability_qcn_2D_reps_1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.08960496168871653\n",
      "epoch: 1, loss: 0.09015198242521527\n",
      "epoch: 2, loss: 0.07401824848241088\n",
      "epoch: 3, loss: 0.05732993821546242\n",
      "epoch: 4, loss: 0.04826012948735936\n",
      "epoch: 5, loss: 0.050079276354196525\n",
      "epoch: 6, loss: 0.0505027648985183\n",
      "epoch: 7, loss: 0.048127901900601594\n",
      "epoch: 8, loss: 0.0462132572911002\n",
      "epoch: 9, loss: 0.04587222547959448\n",
      "epoch: 10, loss: 0.0458837445329465\n",
      "epoch: 11, loss: 0.04416705274399303\n",
      "epoch: 12, loss: 0.0398841272907861\n",
      "epoch: 13, loss: 0.03882971795373327\n",
      "epoch: 14, loss: 0.03567620293412895\n",
      "epoch: 15, loss: 0.03393152231647876\n",
      "epoch: 16, loss: 0.03238278146844824\n",
      "epoch: 17, loss: 0.030603555977391825\n",
      "epoch: 18, loss: 0.030195177951087306\n",
      "epoch: 19, loss: 0.029994091889296574\n",
      "epoch: 20, loss: 0.02852096139781264\n",
      "epoch: 21, loss: 0.026106110658141383\n",
      "epoch: 22, loss: 0.024374094662271015\n",
      "epoch: 23, loss: 0.02423719967683111\n",
      "epoch: 24, loss: 0.024294517433738456\n",
      "epoch: 25, loss: 0.022805035758399803\n",
      "epoch: 26, loss: 0.020887442848670126\n",
      "epoch: 27, loss: 0.020217026804717843\n",
      "epoch: 28, loss: 0.02031184945039163\n",
      "epoch: 29, loss: 0.020733634482036026\n",
      "epoch: 30, loss: 0.020171659331697393\n",
      "epoch: 31, loss: 0.019274510067380964\n",
      "epoch: 32, loss: 0.019129497289094674\n",
      "epoch: 33, loss: 0.018876877174605844\n",
      "epoch: 34, loss: 0.018237448482340726\n",
      "epoch: 35, loss: 0.017466695894804065\n",
      "epoch: 36, loss: 0.01685770450246349\n",
      "epoch: 37, loss: 0.016612068552838803\n",
      "epoch: 38, loss: 0.016425383030474357\n",
      "epoch: 39, loss: 0.015867295282796217\n",
      "epoch: 40, loss: 0.015362094158782452\n",
      "epoch: 41, loss: 0.015135421351902533\n",
      "epoch: 42, loss: 0.014815087920726416\n",
      "epoch: 43, loss: 0.014445652170466863\n",
      "epoch: 44, loss: 0.013950573278401292\n",
      "epoch: 45, loss: 0.013545654399668868\n",
      "epoch: 46, loss: 0.012980052827795643\n",
      "epoch: 47, loss: 0.012618197456421204\n",
      "epoch: 48, loss: 0.012457486219893463\n",
      "epoch: 49, loss: 0.012107613591405195\n",
      "epoch: 50, loss: 0.011730910752704438\n",
      "epoch: 51, loss: 0.011585139388679491\n",
      "epoch: 52, loss: 0.011365549729245687\n",
      "epoch: 53, loss: 0.011066059286668893\n",
      "epoch: 54, loss: 0.010862845659977634\n",
      "epoch: 55, loss: 0.01054919801265608\n",
      "epoch: 56, loss: 0.010187360614028565\n",
      "epoch: 57, loss: 0.009886105016103942\n",
      "epoch: 58, loss: 0.009533157340170066\n",
      "epoch: 59, loss: 0.009158416938928127\n",
      "epoch: 60, loss: 0.00894635940202481\n",
      "epoch: 61, loss: 0.008765328871941282\n",
      "epoch: 62, loss: 0.008592079435044444\n",
      "epoch: 63, loss: 0.00850707319633787\n",
      "epoch: 64, loss: 0.008381192915069086\n",
      "epoch: 65, loss: 0.008240047685785144\n",
      "epoch: 66, loss: 0.0081313373295913\n",
      "epoch: 67, loss: 0.00797283127747535\n",
      "epoch: 68, loss: 0.007765797516372806\n",
      "epoch: 69, loss: 0.007591172346552399\n",
      "epoch: 70, loss: 0.007450836070851797\n",
      "epoch: 71, loss: 0.007361522751451747\n",
      "epoch: 72, loss: 0.0072801470073729346\n",
      "epoch: 73, loss: 0.007211700016486878\n",
      "epoch: 74, loss: 0.007111868238647088\n",
      "epoch: 75, loss: 0.006988709741601254\n",
      "epoch: 76, loss: 0.006867961278847943\n",
      "epoch: 77, loss: 0.006771109265389575\n",
      "epoch: 78, loss: 0.0066704399764290784\n",
      "epoch: 79, loss: 0.00659052536600777\n",
      "epoch: 80, loss: 0.006516308218541832\n",
      "epoch: 81, loss: 0.006450056004352451\n",
      "epoch: 82, loss: 0.006395370235161326\n",
      "epoch: 83, loss: 0.006349713847256553\n",
      "epoch: 84, loss: 0.00629466972270853\n",
      "epoch: 85, loss: 0.006233964306424599\n",
      "epoch: 86, loss: 0.006181181351132762\n",
      "epoch: 87, loss: 0.006126278714333135\n",
      "epoch: 88, loss: 0.006076217546477172\n",
      "epoch: 89, loss: 0.006038970316571989\n",
      "epoch: 90, loss: 0.006000759885049103\n",
      "epoch: 91, loss: 0.005952136014056706\n",
      "epoch: 92, loss: 0.005906393227694755\n",
      "epoch: 93, loss: 0.005858980344252724\n",
      "epoch: 94, loss: 0.005809024531136953\n",
      "epoch: 95, loss: 0.005763363101256107\n",
      "epoch: 96, loss: 0.0057180326305716995\n",
      "epoch: 97, loss: 0.00568344487473505\n",
      "epoch: 98, loss: 0.0056802582521265155\n",
      "epoch: 99, loss: 0.005750520307676616\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qcn_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = [4, 4, 4],\n",
    "                         dim = [2, 4, 4, 1],\n",
    "                         encoder= Encoder(),\n",
    "                         ansatz = Ansatz(blocks = [\"entangle\", \"ry\"], reps=2),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         backend=backend,\n",
    "                         shots=0)\n",
    "   \n",
    "    qcn_list.append([qcn, x_qcn, y, False])\n",
    "\n",
    "qcn_list[0][3] = True    \n",
    "    \n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list)   \n",
    "    \n",
    "saver(qcn_list, data_path(\"trainability_qcn_2D_reps_2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dnn_list = []\n",
    "for i in range(10):\n",
    "    dnn = sequential_dnn(dim = [2, 5, 5, 1],\n",
    "                         optimizer = Adam(lr=0.1))\n",
    "    \n",
    "    dnn.train(x_dnn, y, epochs=100)\n",
    "    dnn_list.append(dnn)\n",
    "\n",
    "saver(dnn_list, data_path(\"trainability_dnn_2D_epochs_100\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dnn_list = []\n",
    "for i in range(10):\n",
    "    dnn = sequential_dnn(dim = [2, 5, 5, 1],\n",
    "                         optimizer = Adam(lr=0.1))\n",
    "    \n",
    "    dnn.train(x_dnn, y, epochs=10000)\n",
    "    dnn_list.append(dnn)\n",
    "\n",
    "saver(dnn_list, data_path(\"trainability_dnn_2D_epochs_10000\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(216, 1)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n = 6\n",
    "x = np.linspace(0, 1, n)\n",
    "x = generate_meshgrid([x, x, x])\n",
    "\n",
    "mean1 = np.array([[0.25, 0.25, 0.25]])\n",
    "mean2 = np.array([[0.25, 0.25, 0.75]])\n",
    "mean3 = np.array([[0.25, 0.75, 0.75]])\n",
    "mean4 = np.array([[0.25, 0.75, 0.25]])\n",
    "\n",
    "mean5 = np.array([[0.75, 0.25, 0.25]])\n",
    "mean6 = np.array([[0.75, 0.25, 0.75]])\n",
    "mean7 = np.array([[0.75, 0.75, 0.75]])\n",
    "mean8 = np.array([[0.75, 0.75, 0.25]])\n",
    "\n",
    "var = np.array([[0.02, 0, 0], [0, 0.02, 0], [0, 0, 0.02]])\n",
    "\n",
    "y = gaussian(x, mean1, var) - gaussian(x, mean2, var) + gaussian(x, mean3, var) - gaussian(x, mean4, var) - gaussian(x, mean5, var) + gaussian(x, mean6, var) - gaussian(x, mean7, var) + gaussian(x, mean8, var)\n",
    "\n",
    "x_qcn = scaler(x, a=-np.pi/2, b=np.pi/2)\n",
    "x_dnn = scaler(x, mode=\"standard\")\n",
    "y = scaler(y, a=0, b=1)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(y.reshape(n,n,n)[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.024215806789506855\n",
      "epoch: 1, loss: 0.022827086737002997\n",
      "epoch: 2, loss: 0.022070295859276466\n",
      "epoch: 3, loss: 0.021569850449989804\n",
      "epoch: 4, loss: 0.02024860756199184\n",
      "epoch: 5, loss: 0.018401360450545617\n",
      "epoch: 6, loss: 0.01632740732120656\n",
      "epoch: 7, loss: 0.013638738943685592\n",
      "epoch: 8, loss: 0.010933278153778604\n",
      "epoch: 9, loss: 0.01126132100494103\n",
      "epoch: 10, loss: 0.010275801598483457\n",
      "epoch: 11, loss: 0.00942734312048578\n",
      "epoch: 12, loss: 0.009621296764464273\n",
      "epoch: 13, loss: 0.009529836796622308\n",
      "epoch: 14, loss: 0.009203731273209111\n",
      "epoch: 15, loss: 0.009370030533861472\n",
      "epoch: 16, loss: 0.00909380477666458\n",
      "epoch: 17, loss: 0.008936410374313756\n",
      "epoch: 18, loss: 0.008952008817541716\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qcn_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = [5, 5, 5],\n",
    "                         dim = [3, 5, 5, 1],\n",
    "                         encoder= Encoder(),\n",
    "                         ansatz = Ansatz(blocks = [\"entangle\", \"ry\"], reps = 1),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         backend = backend,\n",
    "                         shots = 0)\n",
    "\n",
    "    qcn_list.append([qcn, x_qcn, y, False])\n",
    "\n",
    "qcn_list[0][3] = True    \n",
    "    \n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list) \n",
    "    \n",
    "saver(qcn_list, data_path(\"trainability_qcn_3D_reps_1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qcn_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = [5, 5, 5],\n",
    "                         dim = [3, 5, 5, 1],\n",
    "                         encoder= Encoder(),\n",
    "                         ansatz = Ansatz(blocks = [\"entangle\", \"ry\"], reps = 2),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         backend = backend,\n",
    "                         shots = 0)\n",
    "\n",
    "    qcn_list.append([qcn, x_qcn, y, False])\n",
    "\n",
    "qcn_list[0][3] = True    \n",
    "    \n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list) \n",
    "    \n",
    "saver(qcn_list, data_path(\"trainability_qcn_3D_reps_2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dnn_list = []\n",
    "for i in range(10):\n",
    "    dnn = sequential_dnn(dim = [3, 8, 8, 1],\n",
    "                         optimizer = Adam(lr=0.1))\n",
    "    \n",
    "    dnn.train(x_dnn, y, epochs=100)\n",
    "    dnn_list.append(dnn)\n",
    "\n",
    "saver(dnn_list, data_path(\"trainability_dnn_3D_epochs_100\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dnn_list = []\n",
    "for i in range(10):\n",
    "    dnn = sequential_dnn(dim = [3, 8, 8, 1],\n",
    "                         optimizer = Adam(lr=0.1))\n",
    "    \n",
    "    dnn.train(x_dnn, y, epochs=10000)\n",
    "    dnn_list.append(dnn)\n",
    "\n",
    "saver(dnn_list, data_path(\"trainability_dnn_3D_epochs_10000\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainability, Noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend_santiago = pickle.load(open(\"backend_santiago\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D, Gaussian Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "x = np.linspace(0, 1, n).reshape(-1,1)\n",
    "y = gaussian(x, 0.2, 0.01) - gaussian(x, 0.5, 0.01) + gaussian(x, 0.8, 0.01)\n",
    "\n",
    "x_qcn = scaler(x, a=-np.pi/2, b=np.pi/2)\n",
    "x_dnn = scaler(x, mode=\"standard\")\n",
    "y = scaler(y, a=0, b=1)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_qcn, y, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.14116189887302164\n",
      "epoch: 1, loss: 0.12248295090363229\n",
      "epoch: 2, loss: 0.11250269420402588\n",
      "epoch: 3, loss: 0.10616333798002887\n",
      "epoch: 4, loss: 0.09757624753238513\n",
      "epoch: 5, loss: 0.08794267603754535\n",
      "epoch: 6, loss: 0.07417260759845884\n",
      "epoch: 7, loss: 0.06135294878786685\n",
      "epoch: 8, loss: 0.05328782649160126\n",
      "epoch: 9, loss: 0.051034924512023044\n",
      "epoch: 10, loss: 0.04366365807739563\n",
      "epoch: 11, loss: 0.03823363828391696\n",
      "epoch: 12, loss: 0.03501960160647086\n",
      "epoch: 13, loss: 0.031219152603103706\n",
      "epoch: 14, loss: 0.027083290694734953\n",
      "epoch: 15, loss: 0.02477528380217088\n",
      "epoch: 16, loss: 0.02061730770744847\n",
      "epoch: 17, loss: 0.021600236265254362\n",
      "epoch: 18, loss: 0.019057734434734595\n",
      "epoch: 19, loss: 0.01751063972223564\n",
      "epoch: 20, loss: 0.015742868180815876\n",
      "epoch: 21, loss: 0.015080866122253676\n",
      "epoch: 22, loss: 0.013625957879584592\n",
      "epoch: 23, loss: 0.013987704328860928\n",
      "epoch: 24, loss: 0.013565494380335705\n",
      "epoch: 25, loss: 0.012478381957743444\n",
      "epoch: 26, loss: 0.011875328189383099\n",
      "epoch: 27, loss: 0.011242423373787383\n",
      "epoch: 28, loss: 0.011672386574982279\n",
      "epoch: 29, loss: 0.011258001510883155\n",
      "epoch: 30, loss: 0.01155517976386075\n",
      "epoch: 31, loss: 0.010655369377733178\n",
      "epoch: 32, loss: 0.008668508960752113\n",
      "epoch: 33, loss: 0.010595598531105392\n",
      "epoch: 34, loss: 0.009439531735937262\n",
      "epoch: 35, loss: 0.010494820601344854\n",
      "epoch: 36, loss: 0.010315044203472307\n",
      "epoch: 37, loss: 0.009370288650422024\n",
      "epoch: 38, loss: 0.008221532588692926\n",
      "epoch: 39, loss: 0.007583557991065259\n",
      "epoch: 40, loss: 0.008164776134815796\n",
      "epoch: 41, loss: 0.008356540366018574\n",
      "epoch: 42, loss: 0.00860108811855395\n",
      "epoch: 43, loss: 0.008041591158257762\n",
      "epoch: 44, loss: 0.007695049089477725\n",
      "epoch: 45, loss: 0.008114051263031264\n",
      "epoch: 46, loss: 0.007771733417786395\n",
      "epoch: 47, loss: 0.0072941423087852465\n",
      "epoch: 48, loss: 0.00807026507465029\n",
      "epoch: 49, loss: 0.007608636694606582\n",
      "epoch: 50, loss: 0.007520139680969666\n",
      "epoch: 51, loss: 0.00829254938326082\n",
      "epoch: 52, loss: 0.007674993802930149\n",
      "epoch: 53, loss: 0.007530112505439953\n",
      "epoch: 54, loss: 0.007408229895511365\n",
      "epoch: 55, loss: 0.006888892407713878\n",
      "epoch: 56, loss: 0.007832967888758112\n",
      "epoch: 57, loss: 0.007891389559798189\n",
      "epoch: 58, loss: 0.007576860534595073\n",
      "epoch: 59, loss: 0.007221113892288038\n",
      "epoch: 60, loss: 0.007560664686289424\n",
      "epoch: 61, loss: 0.0076533379681644476\n",
      "epoch: 62, loss: 0.007782562680891665\n",
      "epoch: 63, loss: 0.007408321458853231\n",
      "epoch: 64, loss: 0.008610431703781089\n",
      "epoch: 65, loss: 0.008302160167077221\n",
      "epoch: 66, loss: 0.008598382168972253\n",
      "epoch: 67, loss: 0.007868625289143704\n",
      "epoch: 68, loss: 0.007588379978167029\n",
      "epoch: 69, loss: 0.007491887376689421\n",
      "epoch: 70, loss: 0.007405156682407107\n",
      "epoch: 71, loss: 0.007177979130234805\n",
      "epoch: 72, loss: 0.0074186489571560045\n",
      "epoch: 73, loss: 0.006720539941659645\n",
      "epoch: 74, loss: 0.006716317477111961\n",
      "epoch: 75, loss: 0.007030797260994375\n",
      "epoch: 76, loss: 0.007125102107679436\n",
      "epoch: 77, loss: 0.007537981027500786\n",
      "epoch: 78, loss: 0.007243062112702476\n",
      "epoch: 79, loss: 0.006917835481977329\n",
      "epoch: 80, loss: 0.007329562776751846\n",
      "epoch: 81, loss: 0.006898063070144671\n",
      "epoch: 82, loss: 0.007255603611870046\n",
      "epoch: 83, loss: 0.007504685997293932\n",
      "epoch: 84, loss: 0.007374804527291095\n",
      "epoch: 85, loss: 0.007998251792853177\n",
      "epoch: 86, loss: 0.007132681817017899\n",
      "epoch: 87, loss: 0.007116907207915893\n",
      "epoch: 88, loss: 0.007415600563845145\n",
      "epoch: 89, loss: 0.006947692739009919\n",
      "epoch: 90, loss: 0.00775618794683732\n",
      "epoch: 91, loss: 0.006996828261409067\n",
      "epoch: 92, loss: 0.008037452034604238\n",
      "epoch: 93, loss: 0.007457919361385622\n",
      "epoch: 94, loss: 0.007024393550941315\n",
      "epoch: 95, loss: 0.008225898846610721\n",
      "epoch: 96, loss: 0.0072590893443956386\n",
      "epoch: 97, loss: 0.007151049734946308\n",
      "epoch: 98, loss: 0.008043681640700864\n",
      "epoch: 99, loss: 0.007960275370788344\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qcn_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = [4, 4],\n",
    "                         dim = [1, 4, 1],\n",
    "                         encoder = Encoder(),\n",
    "                         ansatz = Ansatz(blocks = [\"entangle\", \"ry\"], reps=1),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         backend = backend_santiago,\n",
    "                         shots = 8192)\n",
    "    \n",
    "    qcn_list.append([qcn, x_qcn, y, False])\n",
    "\n",
    "    \n",
    "qcn_list[0][3] = True\n",
    "\n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list) \n",
    "    \n",
    "saver(qcn_list, data_path(\"trainability_qcn_1D_reps_1_noisy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "22:32"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_qiskit",
   "language": "python",
   "name": "env_qiskit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
