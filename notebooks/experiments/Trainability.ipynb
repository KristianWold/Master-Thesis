{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import qiskit as qk\n",
    "import matplotlib.pyplot as plt\n",
    "from qiskit import Aer\n",
    "from tqdm.notebook import tqdm\n",
    "import multiprocessing as mp\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../src/')\n",
    "from neuralnetwork import *\n",
    "from analysis import *\n",
    "from utils import *\n",
    "\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = Aer.get_backend('qasm_simulator')\n",
    "\n",
    "def parallel(args):\n",
    "    model = args[0]\n",
    "    x = args[1]\n",
    "    y = args[2]\n",
    "    verbose = args[3]\n",
    "    \n",
    "    model.train(x, y, verbose = verbose)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainability, Ideal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D, Gaussian Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = generate_1D_mixed_gaussian()\n",
    "\n",
    "x_qcn = scaler(x, a=-np.pi/2, b=np.pi/2)\n",
    "x_qnn = np.hstack([x_qcn, x_qcn, x_qcn])\n",
    "x_dnn = scaler(x, mode=\"standard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZYklEQVR4nO3df4xdZZ3H8feXYbo7RNchtmtkwG13g6zsIlRHcJfVRYwW2M22EjeARiIxIaxiXLIhjPuHbuIfdEM2yEbcpiFk4z8Wo6TWUG1MiGJQVqZSwEJKuhihrQmDMm6EUdvy3T/uveX09Jx7z517fj3P+bySJr33ns48zznP/fac7/N9zjF3R0REwnda0w0QEZFyKKCLiERCAV1EJBIK6CIikVBAFxGJxOlN/eK1a9f6+vXrm/r1IiJB2rt374vuvi7rs8YC+vr161lcXGzq14uIBMnMfp73mVIuIiKRUEAXEYmEArqISCQU0EVEIqGALiISiZFVLmZ2L/D3wAvu/pcZnxtwF3AV8ArwcXf/SdkN7Zqdjx3mjj0HOLK8whtmpjGD5VeOctbsDLduOo8tG+eabqLIqml8V8NG3W3RzN4L/Ab4Sk5Avwr4NL2Afglwl7tfMuoXz8/Pu8oWTzYY5IeXVzAg78gMPpvT4JeAaHyXw8z2uvt81mcjz9Dd/SEzWz9kk830gr0Dj5jZrJm92d1/sbrmdtPOxw7z2fufZOXocSB/sCc/O7y8wmfvfxJAg15aTeO7HmXk0OeA5xOvD/XfO4WZ3Whmi2a2uLS0VMKvDt/Oxw5z6dYH+ef79p0Y7ONYOXqcO/YcqKBlIuW5Y8+BVY/vf/na42xYeIBLtz7IzscOV9C6eJQR0C3jvcz/gN19u7vPu/v8unWZK1c7ZXDWcnh5ZaKfc3h5RYNdWmlwwjLJGD/ujvPaGbvGeb4yAvoh4JzE67OBIyX83Oit9qwliwa7tE1ZJyxJuiIdroyAvgu43nreDfxa+fNijowY6INLn9mZac48Y/qk97JosEubjDphGXd8D4z63nRZkbLFrwKXAWvN7BDweWAawN23AbvpVbgcpFe2eENVjY3FYLZ/2MRQ3gx/slIgyyD9ouoAacqoMQqjx/eR5RVOM+N4RhWeg8Z4jpFli1XpatlierY/bWZ6ituvvmDkQB2Vlyz6c0TKNGp8Qy+YP7xw+cQ/q6tjfFjZolaK1mzYZejc7EzhAXrrpvOYmZ7K/VzpF2nCqDTLzPQUt246r9DP2rJxjtuvvoC52ZnMzzXGT6WAXpNRs/0GPLxweeGzjVGDHZRrlPoNG3PjnLAMbNk4x8MLl+fm1lXhdTIF9BoUme0/a0hgzjMY7HlBfZBr1GCXqg1OWPISuIM0y2rTI8O+H6rweo0Ceg3KvAzNMiz9osEuVRt1wjLp+AalGItSQK9B2Zehaco1SpPKmhcaRinGYhTQa5B3uTjpZWjSqFyjBrtUJW9sjTsvNMqoFONq0paxUUCvyCCnuGHhAV7+3TGmp04OtWVchmbJG9Qa7FKVusdcVvrF0AQpKKBXIplTdGB55Sg4nHnGNEZ5l6FZsgZ7Vf95iED9Yy6dfkneirfrc0ZaWFSBvPLEogsqJqWHB0gd2jDOmv6uNWGi+6HL+PJyinXlsbdsnGPLxrlTVtrp/tJSlvTYWl45ysz0FHdec1GtY6vp71rbKOVSgbbksbOqD1TxImVoy9hqy3etLRTQS5RcDZquNmkij62zF6lKW8aWJkhPpoBekvTiCue1W4FWOQk6jM5epCptGVuaID2ZAnpJsi5BBw+6LbMWdxyqeJGqtGlsJevT0yUeXUsxalK0JG25BE0a/CeSrkS45b593LHngCpeZGzpypY/nD6tNRVUbfwO1k0BvSRnzc5klk81nd5QxYuUpS2VLXna+h2sk1IuJWnTJWiWtlQlSLjaPoba/h2sg87QJ9TmS9AkXY7KpNo+hpRiVECfSNsvQZN0OSqTCmEMdT3FqJTLBNp+CZqky1GZVEhjKKTvZpl0hj6Btl+CJqUvR9uWEpL2C2kMhfTdLJMC+gRCuARNGlyOwmu5/1vu29fqL6Y0LzlPFMpYCe27WRalXCYQ0iVoUvr2vl1cUSfFhDpWQv1uTkoBfRUG92y55b59/MHpp9Vyn/MydTW/KOMLdawkbwlgwGy/Au2W+/ZFfY8XpVzGFFJlS56u5hdlfCGPlS5WvOgMfUyhnrEkteXGStJ+MYyVGL6zRSmgjynkM5aBruYXZXwxjJUYvrNFKaCPKYYzlnR+MZTcv9QvhrESw3e2KOXQx3TrpvNOysdBeGcscHIJo8gwoY+VWL6zRSigFxTKPVtWK8RaY6lOTOOhS/d4Mff0LeHrMT8/74uLi4387nGlZ8mh9z98aJeeeWLvn4wn5vEQQ9/MbK+7z2d9ViiHbmZXmNkBMztoZgsZn7/BzL5lZo+b2X4zu2HSRrdJ7LPksfdPxhPzeIi5b1AgoJvZFHA3cCVwPnCdmZ2f2uxTwFPufiFwGfAfZram5LY2JvZZ8tj7J+OJeTzE3DcodoZ+MXDQ3Z91998DO4DNqW0ceL2ZGfA64FfAsVJb2qDYZ8lj75+MJ+bxEHPfoFhAnwOeT7w+1H8v6UvA24AjwJPAZ9z91fQPMrMbzWzRzBaXlpZW2eT6xVCLO0zs/ZPxxDweYu4bFAvolvFeeiZ1E7APOAu4CPiSmf3RKf/Ifbu7z7v7/Lp168Zsav1Cv2dLUTHUGkt5Yh4Psd/jZWSVi5n9FfBv7r6p//qzAO5+e2KbB4Ct7v6D/usHgQV3/3Hez217lUsMs+Eiki/U7/ikVS6PAuea2Yb+ROe1wK7UNs8B7+//sjcB5wHPrr7JzYt9NnyYwZXJhoUHojhrkWK6dtxj/I6PXFjk7sfM7GZgDzAF3Ovu+83spv7n24AvAP9tZk/SS9Hc5u4vVtjuysU+G56nS3emk9d08bjH+B0vtFLU3XcDu1PvbUv8/QjwwXKb1qyuPvFk2FlLrF9s6eZxj/E7rptz5Yh9NjxPjGctMloXj3uM33EF9JSuVLbkib1OV7J18bjHWPGigJ6Qfn7i8spRfnv0Ve685iIeXrg8+mAOcZ61yGhdPe5bNs7x8MLl3HnNRfzu2Ku89MrRoJ6dmqaAnhDjrPe4Yq5BlnxdP+6xfPd1+9yELuYRs4R+/2tZnS4f91i++zpDT+hiHlFE4vnuK6AndDWPOEzXFpt0jY5vTyzffT3gglOfRmRGVE8jWq1Ql0ZLMTq+JwslDkz8gIuYqbIlXywTRZJNx/dkMVS8dD6ga1Dni2WiSLLp+GYLOSZ0PqBrUOeLZaJIsun4Zgs5JnQ+oGtQ54tlokiy6fhmCzkmdD6ga1Dn6/pik9jp+GYLOSZ0tsollBltEalfm+PDsCqXTq4UTZdrLa8cZWZ6ijuvuUiBXEROrJoN7T7xnQzoXbz3cxmSZy1tOFOR8ekYjie0WNHJgB7yLHZTQjtTkVPpGI4vtFjRyUnRkGexmxJyba706BiOL7RY0amAPrhvxeHlFSz1WSiz2E0J7UxFTqVjOL6sihejd3XTxnvfdCagJ5f4AzicCOoq1xottDMVOZWO4fiSpZ3QixmDusA23hKgMwE963LT6QXzrt+zpYiQa3OlR8dwdQb3eJmbnSFd5N22lFVnJkV1uTmZwX94qpAIl47hZEKIIZ0J6GfNzpxIt6Tfl2K6/ESbWOgYrl4IMST6lIsmQkWkDCFMkEZ9hp6uux1MhA5y57rcFJGikimrwQlieoI0uV0Tog7ooyZCZfW04jAcOlblGaSsBlf9SW1YQRp1QA9hEiNEWnEYDh2rarQ1tkSZQx/kzfPuI9mmSYwQacVhOHSsqpEXQ04za/SB29EF9PQCojRNhE6urWcnciodq2pkTZACHHdv9Dmk0QX0rDOSAa0ILYdWHIZDx6oa6YeDTFm6hq6ZK6FCAd3MrjCzA2Z20MwWcra5zMz2mdl+M/t+uc0sLu/Mw0ArQkuiFYfh0LGqzmAF6c+2/h2v5jwoqO4roZEB3cymgLuBK4HzgevM7PzUNrPAl4F/cPe/AP6x/KYOp7x5ffTosnDoWNUjL7441JpPL1LlcjFw0N2fBTCzHcBm4KnENh8B7nf35wDc/YWyGzpMeiY/TWck5dOKw3DoWFXv1k3n5cagOiuLiqRc5oDnE68P9d9Leitwppl9z8z2mtn1WT/IzG40s0UzW1xaWlpdizMoby4iTUrflTGtrnx6kTP0U7P9nJLZOB14J/B+YAb4kZk94u7PnPSP3LcD26H3kOjxm/ua5GKJvB80yJtLtbRwpX10TOo3uBLasPBAZkwa3CKgymNRJKAfAs5JvD4bOJKxzYvu/jLwspk9BFwIPEMFRqVYBpQ3r54WrrSPjkmz8m7iBdUfiyIpl0eBc81sg5mtAa4FdqW2+SbwHjM73czOAC4Bni63qa8ZlmIZUN68Hlq40j46Js3Kq1EfqPJYjAzo7n4MuBnYQy9If83d95vZTWZ2U3+bp4HvAE8APwbucfeflt3Y5J0T82gmv15auNI+OibNGpVPh+ru0FjoXi7uvhvYnXpvW+r1HcAd5TXtZEXSLLrpVv1CuEd01+iYNG/YTbwGqki/BLNSdFSaRSmWZmjhSvvomLRH3emXYO62OOxyUfc2b44ea9Y+Oibtkb6HepYyU2HmOUtWqzY/P++Li4uFt8+7dFGaRURCUFYMM7O97j6f9VkwKRddRopIyOqIYcGkXHQZKSIhqyOGBZNykTBohWJztO+7YVjKJZgzdGk/rVBsjva9QEA5dGk/rVBsjva9gAK6lEgrFJujfS+ggC4l0uPOmqN9L6CALiVSaWlztO8FNCkqJVJpaXO07wVUtigiEpQoVoqKiMhwCugiIpFQDl0qo5WL1dM+liQFdKmEVi5WT/tY0pRykUpo5WL1tI8lTQFdKqGVi9XTPpY0BXSphFYuVk/7WNIU0KUSWrlYPe1jSdOkqFRCKxerp30saVopKiISEK0UFRHpAAV0EZFIKIcutdCKxvJoX0oeBXSpnFY0lkf7UoZRykUqpxWN5dG+lGEU0KVyWtFYHu1LGUYBXSqnFY3l0b6UYRTQpXJa0Vge7UsZplBAN7MrzOyAmR00s4Uh273LzI6b2YfLa6KEbsvGOW6/+gLmZmcwYG52htuvvkCTeKugfSnDjFwpamZTwDPAB4BDwKPAde7+VMZ23wV+C9zr7l8f9nO1UlREZHyTrhS9GDjo7s+6+++BHcDmjO0+DXwDeGHVLRURkVUrEtDngOcTrw/13zvBzOaADwHbhv0gM7vRzBbNbHFpaWnctoqIyBBFFhZZxnvpPM0Xgdvc/bhZ1ub9f+S+HdgOvZRLwTZKZLTScXzaZ1JEkYB+CDgn8fps4Ehqm3lgRz+YrwWuMrNj7r6zjEZKPLTScXzaZ1JUkZTLo8C5ZrbBzNYA1wK7khu4+wZ3X+/u64GvA59UMJcsWuk4Pu0zKWrkGbq7HzOzm4E9wBS9Cpb9ZnZT//OheXORJK10HJ/2mRRV6OZc7r4b2J16LzOQu/vHJ2+WxOqs2RkOZwQirXTMp30mRWmlqNRKKx3Hp30mRen2uVIrPQdzfNpnUpSeKSoiEhA9U1REpAOUcpFGacFMPu0bGZcCujRGC2byad/IaijlIo3Rgpl82jeyGgro0hgtmMmnfSOroYAujdHj1PJp38hqKKBLY7RgJp/2jayGJkWlMVowk0/7RlZDC4tERAKihUUiIh2ggC4iEgnl0KU1tDJS+0Amo4AuraCVkdoHMjmlXKQVtDJS+0Amp4AuraCVkdoHMjkFdGkFrYzUPpDJKaBLK2hlpPaBTE6TotIKWhmpfSCT00pREZGAaKWoiEgHKOUirdSlBTZd6qtUSwFdWqdLC2y61FepnlIu0jpdWmDTpb5K9RTQpXW6tMCmS32V6imgS+t0aYFNl/oq1VNAl9bp0gKbLvVVqqdJUWmdLi2w6VJfpXqFFhaZ2RXAXcAUcI+7b019/lHgtv7L3wD/5O6PD/uZWlgkIjK+YQuLRp6hm9kUcDfwAeAQ8KiZ7XL3pxKb/Qz4W3d/ycyuBLYDl0zedJE467Rj7JM0r0jK5WLgoLs/C2BmO4DNwImA7u4/TGz/CHB2mY2U7oqxTjvGPkk7FJkUnQOeT7w+1H8vzyeAb2d9YGY3mtmimS0uLS0Vb6V0Vox12jH2SdqhSEC3jPcyE+9m9j56Af22rM/dfbu7z7v7/Lp164q3UjorxjrtGPsk7VAkoB8Czkm8Phs4kt7IzN4O3ANsdvdfltM86boY67Rj7JO0Q5GA/ihwrpltMLM1wLXAruQGZvYW4H7gY+7+TPnNlK6KsU47xj5JO4ycFHX3Y2Z2M7CHXtnive6+38xu6n++Dfgc8Ebgy2YGcCyvrEZkHDHWacfYJ2kHPeBCRCQgE9Whi7RNqDXcobZbwqGALkEJtYY71HZLWHRzLglKqDXcobZbwqKALkEJtYY71HZLWBTQJSih1nCH2m4JiwK6BCXUGu5Q2y1h0aSoBCXUGu5Q2y1hUR26BK3tpYBtb5+ER3XoEqW2lwK2vX0SH+XQJVhtLwVse/skPgroEqy2lwK2vX0SHwV0CVbbSwHb3j6JjwK6BKvtpYBtb5/ER5OiEqy2lwK2vX0SH5UtSjTaUiLYlnZInFS2KNFrS4lgW9oh3aQcukShLSWCbWmHdJMCukShLSWCbWmHdJMCukShLSWCbWmHdJMCukQhq0TQ6OWwL936IDsfO1zZ79752GEu3fogGxYe4OXfHWN6yk76XKWKUhdNikoUkiWCh5dXMGBQv1XlxGR6EnR55SjTpxlnnjHN8itHVeUitVJAl2hs2TjHlo1zXLr1QQ6nctaDicmyA2vWJOjRV50z1pzOY5/7YKm/S2QUpVwkOnVOTGoSVNpEAV2iU+fEpCZBpU0U0CU6dUyQDiZCB/n6JE2CSlOUQ5foVD1Bmp4IdTjxO+Y0CSoN0hm6RGnLxjkeXricudkZ0ncrmnTlZtZE6CCYP7xwuYK5NEYBXaKWNzm5mvRLMs0yzu8SqYsCukRt2OTkIP1SJKgP0ix5wXzU7xKpgwK6RC1rgjSpaPolK82SpIlQaQMFdInalo1z3H71BcyNOFPPS7+MSrNAL3d++9UXKHcujSv0gAszuwK4C5gC7nH3ranPrf/5VcArwMfd/SfDfqYecCF1GxWYB5UqszPTmMFLrxw9qUImy2AiVKQuwx5wMfIM3cymgLuBK4HzgevM7PzUZlcC5/b/3Aj810QtFqnAqPTLIHAvrxzlpVeOnvReFqVZpG2KpFwuBg66+7Pu/ntgB7A5tc1m4Cve8wgwa2ZvLrmtIhMpkn4pSmkWaaMiAX0OeD7x+lD/vXG3wcxuNLNFM1tcWloat60iE0vWp6+W6s2lrYoE9PTKZjj1SrTINrj7dnefd/f5devWFWmfSCVGpV/yKM0ibVZk6f8h4JzE67OBI6vYRqQ1ht0eIE3L+iUURQL6o8C5ZrYBOAxcC3wktc0u4GYz2wFcAvza3X9RaktFSja4fzr0yhPv2HOAI8srvKFf5aIHVEhoRgZ0dz9mZjcDe+iVLd7r7vvN7Kb+59uA3fRKFg/SK1u8obomi5QvGdxFQlXobovuvpte0E6+ty3xdwc+VW7TRERkHFopKiISCQV0EZFIKKCLiERCAV1EJBKFbs5VyS82WwJ+vsp/vhZ4scTmhEB97gb1uRsm6fOfuHvmyszGAvokzGwx725jsVKfu0F97oaq+qyUi4hIJBTQRUQiEWpA3950AxqgPneD+twNlfQ5yBy6iIicKtQzdBERSVFAFxGJRKsDupldYWYHzOygmS1kfG5m9p/9z58ws3c00c4yFejzR/t9fcLMfmhmFzbRzjKN6nNiu3eZ2XEz+3Cd7atCkT6b2WVmts/M9pvZ9+tuY9kKjO03mNm3zOzxfp+Dvmurmd1rZi+Y2U9zPi8/frl7K//Qu1Xv/wJ/CqwBHgfOT21zFfBtes8geDfwP023u4Y+/zVwZv/vV3ahz4ntHqR3188PN93uGo7zLPAU8Jb+6z9uut019PlfgX/v/30d8CtgTdNtn6DP7wXeAfw05/PS41ebz9C7+HDqkX129x+6+0v9l4/QezpUyIocZ4BPA98AXqizcRUp0uePAPe7+3MA7h56v4v02YHXm5kBr6MX0I/V28zyuPtD9PqQp/T41eaAXtrDqQMybn8+Qe9/+JCN7LOZzQEfArYRhyLH+a3AmWb2PTPba2bX19a6ahTp85eAt9F7fOWTwGfc/dV6mteI0uNXoQdcNKS0h1MHpHB/zOx99AL631TaouoV6fMXgdvc/Xjv5C14Rfp8OvBO4P3ADPAjM3vE3Z+punEVKdLnTcA+4HLgz4DvmtkP3P3/Km5bU0qPX20O6F18OHWh/pjZ24F7gCvd/Zc1ta0qRfo8D+zoB/O1wFVmdszdd9bSwvIVHdsvuvvLwMtm9hBwIRBqQC/S5xuArd5LMB80s58Bfw78uJ4m1q70+NXmlMuJh1Ob2Rp6D6feldpmF3B9f7b43YT/cOqRfTaztwD3Ax8L+GwtaWSf3X2Du6939/XA14FPBhzModjY/ibwHjM73czOoPfw9adrbmeZivT5OXpXJJjZm4DzgGdrbWW9So9frT1D9w4+nLpgnz8HvBH4cv+M9ZgHfKe6gn2OSpE+u/vTZvYd4AngVeAed88sfwtBweP8BeC/zexJeumI29w92NvqmtlXgcuAtWZ2CPg8MA3VxS8t/RcRiUSbUy4iIjIGBXQRkUgooIuIREIBXUQkEgroIiKRUEAXEYmEArqISCT+H+rrglyAXxqTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, y, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.13209024177543846\n",
      "epoch: 1, loss: 0.11440680469598491\n",
      "epoch: 2, loss: 0.1027552604707016\n",
      "epoch: 3, loss: 0.08988679141641795\n",
      "epoch: 4, loss: 0.07959109915967323\n",
      "epoch: 5, loss: 0.07347983770870156\n",
      "epoch: 6, loss: 0.06956901619041175\n",
      "epoch: 7, loss: 0.06526933723665074\n",
      "epoch: 8, loss: 0.06101588426182048\n",
      "epoch: 9, loss: 0.057893622879691825\n",
      "epoch: 10, loss: 0.0557600065117\n",
      "epoch: 11, loss: 0.05441768451676799\n",
      "epoch: 12, loss: 0.05419954928904867\n",
      "epoch: 13, loss: 0.05495167901644336\n",
      "epoch: 14, loss: 0.055578014299572605\n",
      "epoch: 15, loss: 0.05541153859407137\n",
      "epoch: 16, loss: 0.05483193376059643\n",
      "epoch: 17, loss: 0.05427750924699657\n",
      "epoch: 18, loss: 0.05373289165851596\n",
      "epoch: 19, loss: 0.053153225810155344\n",
      "epoch: 20, loss: 0.05267760833608299\n",
      "epoch: 21, loss: 0.05235811083020934\n",
      "epoch: 22, loss: 0.052040251168435844\n",
      "epoch: 23, loss: 0.051589435459180814\n",
      "epoch: 24, loss: 0.051096392355337146\n",
      "epoch: 25, loss: 0.0507572895697857\n",
      "epoch: 26, loss: 0.050605738215689235\n",
      "epoch: 27, loss: 0.05050100490036324\n",
      "epoch: 28, loss: 0.05036454315066761\n",
      "epoch: 29, loss: 0.050243313904485394\n",
      "epoch: 30, loss: 0.05014735999964227\n",
      "epoch: 31, loss: 0.05000436153768516\n",
      "epoch: 32, loss: 0.049807045235255455\n",
      "epoch: 33, loss: 0.04964477519645419\n",
      "epoch: 34, loss: 0.0495414598076203\n",
      "epoch: 35, loss: 0.04942151909050591\n",
      "epoch: 36, loss: 0.04926827156041381\n",
      "epoch: 37, loss: 0.04913719884261056\n",
      "epoch: 38, loss: 0.04901992208567237\n",
      "epoch: 39, loss: 0.04886077585137523\n",
      "epoch: 40, loss: 0.04866927284146434\n",
      "epoch: 41, loss: 0.04848349623574727\n",
      "epoch: 42, loss: 0.04828973632690612\n",
      "epoch: 43, loss: 0.0480727701156461\n",
      "epoch: 44, loss: 0.04786643544853108\n",
      "epoch: 45, loss: 0.04768856055522421\n",
      "epoch: 46, loss: 0.047504755906168664\n",
      "epoch: 47, loss: 0.04730256939727014\n",
      "epoch: 48, loss: 0.0471116476257318\n",
      "epoch: 49, loss: 0.04694250722767594\n",
      "epoch: 50, loss: 0.046796423983571235\n",
      "epoch: 51, loss: 0.04669130259085269\n",
      "epoch: 52, loss: 0.04661772728086347\n",
      "epoch: 53, loss: 0.046552004703369926\n",
      "epoch: 54, loss: 0.046503502662541586\n",
      "epoch: 55, loss: 0.046474589940202676\n",
      "epoch: 56, loss: 0.04645091129269589\n",
      "epoch: 57, loss: 0.046438555859911676\n",
      "epoch: 58, loss: 0.04643420445119808\n",
      "epoch: 59, loss: 0.04642532741659351\n",
      "epoch: 60, loss: 0.04642105496891702\n",
      "epoch: 61, loss: 0.04642055805577162\n",
      "epoch: 62, loss: 0.046417698091893216\n",
      "epoch: 63, loss: 0.04641588098272896\n",
      "epoch: 64, loss: 0.04640519713419567\n",
      "epoch: 65, loss: 0.04638472958334485\n",
      "epoch: 66, loss: 0.04636214348857319\n",
      "epoch: 67, loss: 0.04633552517911469\n",
      "epoch: 68, loss: 0.0463103491944387\n",
      "epoch: 69, loss: 0.04628582661667613\n",
      "epoch: 70, loss: 0.046257487525705104\n",
      "epoch: 71, loss: 0.04623003998640971\n",
      "epoch: 72, loss: 0.04620311059320066\n",
      "epoch: 73, loss: 0.04617987019927357\n",
      "epoch: 74, loss: 0.046162525209384346\n",
      "epoch: 75, loss: 0.04614699051363757\n",
      "epoch: 76, loss: 0.04613366523733622\n",
      "epoch: 77, loss: 0.04612067149517103\n",
      "epoch: 78, loss: 0.04610848888626076\n",
      "epoch: 79, loss: 0.046099869053436306\n",
      "epoch: 80, loss: 0.0460935929501839\n",
      "epoch: 81, loss: 0.04609007721565533\n",
      "epoch: 82, loss: 0.04608748785117919\n",
      "epoch: 83, loss: 0.04608434783172258\n",
      "epoch: 84, loss: 0.04608161656354331\n",
      "epoch: 85, loss: 0.046078829834694614\n",
      "epoch: 86, loss: 0.04607700281316471\n",
      "epoch: 87, loss: 0.046075640613628746\n",
      "epoch: 88, loss: 0.046073811839251494\n",
      "epoch: 89, loss: 0.04607179416966839\n",
      "epoch: 90, loss: 0.04606917402529171\n",
      "epoch: 91, loss: 0.04606687044616625\n",
      "epoch: 92, loss: 0.04606490317928784\n",
      "epoch: 93, loss: 0.0460629681873132\n",
      "epoch: 94, loss: 0.04606105752809141\n",
      "epoch: 95, loss: 0.04605871415091829\n",
      "epoch: 96, loss: 0.04605649953069147\n",
      "epoch: 97, loss: 0.04605446154613618\n",
      "epoch: 98, loss: 0.04605273724358263\n",
      "epoch: 99, loss: 0.04605128607363785\n",
      "epoch: 100, loss: 0.04604980306601525\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qnn_list = []\n",
    "for i in range(10):\n",
    "    qnn = sequential_qnn(n_qubits = [4],\n",
    "                         dim = [3,1],\n",
    "                         encoder = RZZEncoder(),\n",
    "                         ansatz = Ansatz(blocks=[\"entangle\", \"ry\"], reps=5),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         shots = 0)\n",
    "    \n",
    "    qnn_list.append([qnn, x_qnn, y, False])\n",
    "\n",
    "    \n",
    "qnn_list[0][3] = True\n",
    "\n",
    "with mp.Pool(10) as p:\n",
    "    qnn_list = p.map(parallel, qnn_list) \n",
    "    \n",
    "    \n",
    "saver(qnn_list, data_path(\"trainability_qnn_1D\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.10532612648318006\n",
      "epoch: 1, loss: 0.0950843681266217\n",
      "epoch: 2, loss: 0.08589157214200861\n",
      "epoch: 3, loss: 0.0777693878709735\n",
      "epoch: 4, loss: 0.07129066464678031\n",
      "epoch: 5, loss: 0.06629647770597295\n",
      "epoch: 6, loss: 0.06252594506100619\n",
      "epoch: 7, loss: 0.0602326223104478\n",
      "epoch: 8, loss: 0.0592359634198268\n",
      "epoch: 9, loss: 0.05924097904375527\n",
      "epoch: 10, loss: 0.05965542875470903\n",
      "epoch: 11, loss: 0.059611619885659654\n",
      "epoch: 12, loss: 0.058893081281640614\n",
      "epoch: 13, loss: 0.05772891565949274\n",
      "epoch: 14, loss: 0.05642512360412467\n",
      "epoch: 15, loss: 0.055284531702181304\n",
      "epoch: 16, loss: 0.054563968765456494\n",
      "epoch: 17, loss: 0.05436133692937492\n",
      "epoch: 18, loss: 0.05450374523915266\n",
      "epoch: 19, loss: 0.054678068815129294\n",
      "epoch: 20, loss: 0.05464460989884012\n",
      "epoch: 21, loss: 0.05430397373458801\n",
      "epoch: 22, loss: 0.05370520651100903\n",
      "epoch: 23, loss: 0.05302790169193508\n",
      "epoch: 24, loss: 0.05248668964940049\n",
      "epoch: 25, loss: 0.05219213999514818\n",
      "epoch: 26, loss: 0.052100321907955716\n",
      "epoch: 27, loss: 0.05208570934121162\n",
      "epoch: 28, loss: 0.052008773613865064\n",
      "epoch: 29, loss: 0.051762900463049315\n",
      "epoch: 30, loss: 0.05136489101933349\n",
      "epoch: 31, loss: 0.050951553093947236\n",
      "epoch: 32, loss: 0.05064891954640954\n",
      "epoch: 33, loss: 0.05044824072468683\n",
      "epoch: 34, loss: 0.050262153400391245\n",
      "epoch: 35, loss: 0.0501116067463749\n",
      "epoch: 36, loss: 0.050066124416806274\n",
      "epoch: 37, loss: 0.050035591017362435\n",
      "epoch: 38, loss: 0.049910555896129714\n",
      "epoch: 39, loss: 0.04972039243743021\n",
      "epoch: 40, loss: 0.04948807633742272\n",
      "epoch: 41, loss: 0.049258168487507754\n",
      "epoch: 42, loss: 0.049143710387920064\n",
      "epoch: 43, loss: 0.04913527797248916\n",
      "epoch: 44, loss: 0.04914260740679944\n",
      "epoch: 45, loss: 0.04913522132189306\n",
      "epoch: 46, loss: 0.04911018382310672\n",
      "epoch: 47, loss: 0.04907658412879504\n",
      "epoch: 48, loss: 0.04905628469269216\n",
      "epoch: 49, loss: 0.04903331127766743\n",
      "epoch: 50, loss: 0.04898704526991384\n",
      "epoch: 51, loss: 0.04894085194999383\n",
      "epoch: 52, loss: 0.04891852893844764\n",
      "epoch: 53, loss: 0.048921686565609274\n",
      "epoch: 54, loss: 0.04894325577699738\n",
      "epoch: 55, loss: 0.048962735316670274\n",
      "epoch: 56, loss: 0.048962052958055564\n",
      "epoch: 57, loss: 0.04895028082423363\n",
      "epoch: 58, loss: 0.048943100690595376\n",
      "epoch: 59, loss: 0.04893844179239307\n",
      "epoch: 60, loss: 0.04893024523546618\n",
      "epoch: 61, loss: 0.048917737950065154\n",
      "epoch: 62, loss: 0.04890390564891915\n",
      "epoch: 63, loss: 0.04889725844992181\n",
      "epoch: 64, loss: 0.048897613900768064\n",
      "epoch: 65, loss: 0.048893483478227945\n",
      "epoch: 66, loss: 0.048883255155552974\n",
      "epoch: 67, loss: 0.048873145381368464\n",
      "epoch: 68, loss: 0.04886574655191429\n",
      "epoch: 69, loss: 0.048861961223973106\n",
      "epoch: 70, loss: 0.04885878329610426\n",
      "epoch: 71, loss: 0.04885420255853897\n",
      "epoch: 72, loss: 0.04885147935008303\n",
      "epoch: 73, loss: 0.048850137876573524\n",
      "epoch: 74, loss: 0.048847700732089244\n",
      "epoch: 75, loss: 0.04884402632254793\n",
      "epoch: 76, loss: 0.04883857100869588\n",
      "epoch: 77, loss: 0.04883297987764489\n",
      "epoch: 78, loss: 0.04882928420819181\n",
      "epoch: 79, loss: 0.048826829065432155\n",
      "epoch: 80, loss: 0.04882551969304415\n",
      "epoch: 81, loss: 0.04882451295940858\n",
      "epoch: 82, loss: 0.04882323923540098\n",
      "epoch: 83, loss: 0.048822366469174615\n",
      "epoch: 84, loss: 0.04882080146708689\n",
      "epoch: 85, loss: 0.04881837943446042\n",
      "epoch: 86, loss: 0.04881567917475379\n",
      "epoch: 87, loss: 0.04881333057938554\n",
      "epoch: 88, loss: 0.048812068190533554\n",
      "epoch: 89, loss: 0.048811066924182196\n",
      "epoch: 90, loss: 0.048810152831687964\n",
      "epoch: 91, loss: 0.0488092492760169\n",
      "epoch: 92, loss: 0.04880817435192689\n",
      "epoch: 93, loss: 0.048807049376473746\n",
      "epoch: 94, loss: 0.04880560156028066\n",
      "epoch: 95, loss: 0.048804227506125016\n",
      "epoch: 96, loss: 0.04880303326251443\n",
      "epoch: 97, loss: 0.048802084811572756\n",
      "epoch: 98, loss: 0.048801303040613905\n",
      "epoch: 99, loss: 0.048800364020433175\n",
      "epoch: 100, loss: 0.04879934466561025\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qnn_list = []\n",
    "for i in range(10):\n",
    "    qnn = sequential_qnn(n_qubits = [5],\n",
    "                         dim = [3,1],\n",
    "                         encoder = RZZEncoder(),\n",
    "                         ansatz = Ansatz(blocks=[\"entangle\", \"ry\"], reps=4),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         shots = 0)\n",
    "    \n",
    "    qnn_list.append([qnn, x_qnn, y, False])\n",
    "\n",
    "    \n",
    "qnn_list[0][3] = True\n",
    "\n",
    "with mp.Pool(10) as p:\n",
    "    qnn_list = p.map(parallel, qnn_list) \n",
    "    \n",
    "    \n",
    "saver(qnn_list, data_path(\"trainability_qnn_1D_2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.13088905684647234\n",
      "epoch: 1, loss: 0.11819851186573099\n",
      "epoch: 2, loss: 0.11339199316912929\n",
      "epoch: 3, loss: 0.11183678777995237\n",
      "epoch: 4, loss: 0.11051236598865995\n",
      "epoch: 5, loss: 0.1085382550070879\n",
      "epoch: 6, loss: 0.1050031136827332\n",
      "epoch: 7, loss: 0.10000858790799574\n",
      "epoch: 8, loss: 0.09486052322526753\n",
      "epoch: 9, loss: 0.09107681776214108\n",
      "epoch: 10, loss: 0.08874730260326996\n",
      "epoch: 11, loss: 0.08680296812548682\n",
      "epoch: 12, loss: 0.0850651046088233\n",
      "epoch: 13, loss: 0.08399551461270911\n",
      "epoch: 14, loss: 0.08353067847712811\n",
      "epoch: 15, loss: 0.08288069801994323\n",
      "epoch: 16, loss: 0.08158729711270936\n",
      "epoch: 17, loss: 0.07983539872092713\n",
      "epoch: 18, loss: 0.07809801901391611\n",
      "epoch: 19, loss: 0.07685574990720458\n",
      "epoch: 20, loss: 0.07627560469216299\n",
      "epoch: 21, loss: 0.07591716495432159\n",
      "epoch: 22, loss: 0.075234927121309\n",
      "epoch: 23, loss: 0.07425813485697944\n",
      "epoch: 24, loss: 0.07326838138738241\n",
      "epoch: 25, loss: 0.07223814702059121\n",
      "epoch: 26, loss: 0.07088289476606348\n",
      "epoch: 27, loss: 0.06901223320153732\n",
      "epoch: 28, loss: 0.06664848485024394\n",
      "epoch: 29, loss: 0.06403614797143074\n",
      "epoch: 30, loss: 0.06166901404383785\n",
      "epoch: 31, loss: 0.06011512347973365\n",
      "epoch: 32, loss: 0.059502140467888535\n",
      "epoch: 33, loss: 0.0592042031274083\n",
      "epoch: 34, loss: 0.05852196481256853\n",
      "epoch: 35, loss: 0.05751259981223383\n",
      "epoch: 36, loss: 0.05675499845515896\n",
      "epoch: 37, loss: 0.056599560582891596\n",
      "epoch: 38, loss: 0.05683339408545942\n",
      "epoch: 39, loss: 0.05703923459441956\n",
      "epoch: 40, loss: 0.05697367360474899\n",
      "epoch: 41, loss: 0.05652525442536954\n",
      "epoch: 42, loss: 0.0556975729133515\n",
      "epoch: 43, loss: 0.05481454479106208\n",
      "epoch: 44, loss: 0.054401610100864514\n",
      "epoch: 45, loss: 0.054346380001024326\n",
      "epoch: 46, loss: 0.05386639334857053\n",
      "epoch: 47, loss: 0.05306654376624292\n",
      "epoch: 48, loss: 0.0527693112978745\n",
      "epoch: 49, loss: 0.05288521476523708\n",
      "epoch: 50, loss: 0.05281921955598449\n",
      "epoch: 51, loss: 0.05273702592324333\n",
      "epoch: 52, loss: 0.05271657405491603\n",
      "epoch: 53, loss: 0.05241041657352862\n",
      "epoch: 54, loss: 0.05204506941994689\n",
      "epoch: 55, loss: 0.05201268384203914\n",
      "epoch: 56, loss: 0.052011852598987086\n",
      "epoch: 57, loss: 0.05178686294529033\n",
      "epoch: 58, loss: 0.051553206068200054\n",
      "epoch: 59, loss: 0.051393671393129024\n",
      "epoch: 60, loss: 0.051260359205592174\n",
      "epoch: 61, loss: 0.051210094890058205\n",
      "epoch: 62, loss: 0.05114862747390075\n",
      "epoch: 63, loss: 0.05092553077876158\n",
      "epoch: 64, loss: 0.05066541687436696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-29:\n",
      "Process ForkPoolWorker-25:\n",
      "Process ForkPoolWorker-22:\n",
      "Process ForkPoolWorker-26:\n",
      "Process ForkPoolWorker-30:\n",
      "Process ForkPoolWorker-24:\n",
      "Process ForkPoolWorker-28:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ed38528d34fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mqnn_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqnn_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_qiskit/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         '''\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_qiskit/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_qiskit/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_qiskit/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_qiskit/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qnn_list = []\n",
    "for i in range(10):\n",
    "    qnn = sequential_qnn(n_qubits = [6],\n",
    "                         dim = [3,1],\n",
    "                         encoder = RZZEncoder(),\n",
    "                         ansatz = Ansatz(blocks=[\"entangle\", \"ry\"], reps=3),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         shots = 0)\n",
    "    \n",
    "    qnn_list.append([qnn, x_qnn, y, False])\n",
    "\n",
    "    \n",
    "qnn_list[0][3] = True\n",
    "\n",
    "with mp.Pool(10) as p:\n",
    "    qnn_list = p.map(parallel, qnn_list) \n",
    "    \n",
    "    \n",
    "saver(qnn_list, data_path(\"trainability_qnn_1D_3\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qcn_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = [4, 4],\n",
    "                         dim = [1, 4, 1],\n",
    "                         encoder = Encoder(),\n",
    "                         ansatz = Ansatz(blocks = [\"entangle\", \"ry\"], reps=1),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         shots = 0)\n",
    "    \n",
    "    qcn_list.append([qcn, x_qcn, y, False])\n",
    "\n",
    "    \n",
    "qcn_list[0][3] = True\n",
    "\n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list) \n",
    "    \n",
    "    \n",
    "saver(qcn_list, data_path(\"trainability_qcn_1D_reps_1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qcn_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = [4, 4],\n",
    "                         dim = [1, 4, 1],\n",
    "                         encoder= Encoder(),\n",
    "                         ansatz = Ansatz(blocks = [\"entangle\", \"ry\"], reps=2),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         shots=0)\n",
    "    \n",
    "    qcn_list.append([qcn, x_qcn, y, False])\n",
    "\n",
    "qcn_list[0][3] = True    \n",
    "    \n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list)     \n",
    "    \n",
    "saver(qcn_list, data_path(\"trainability_qcn_1D_reps_2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dnn_list = []\n",
    "for i in range(10):\n",
    "    dnn = sequential_dnn(dim = [1, 5, 1],\n",
    "                         activation = [Tanh(), Identity()],\n",
    "                         optimizer = Adam(lr=0.1))\n",
    "    \n",
    "    dnn.train(x_dnn, y, epochs=100)\n",
    "    dnn_list.append(dnn)\n",
    "\n",
    "saver(dnn_list, data_path(\"trainability_dnn_1D_epochs_100\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dnn_list = []\n",
    "for i in range(10):\n",
    "    dnn = sequential_dnn(dim = [1, 5, 1],\n",
    "                         activation = [Tanh(), Identity()],\n",
    "                         optimizer = Adam(lr=0.1))\n",
    "    \n",
    "    dnn.train(x_dnn, y, epochs=10000)\n",
    "    dnn_list.append(dnn)\n",
    "\n",
    "saver(dnn_list, data_path(\"trainability_dnn_1D_epochs_10000\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 12\n",
    "x, y = generate_2D_mixed_gaussian()\n",
    "x_qcn = scaler(x, a=-np.pi/2, b=np.pi/2)\n",
    "x_qnn = np.hstack([x_qcn, x_qcn[:,0:1]])\n",
    "x_dnn = scaler(x, mode=\"standard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(y.reshape(n,n))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.07013283589351635\n",
      "epoch: 1, loss: 0.056516319964252215\n",
      "epoch: 2, loss: 0.04798150173865559\n",
      "epoch: 3, loss: 0.04581213403154008\n",
      "epoch: 4, loss: 0.043839570096269855\n",
      "epoch: 5, loss: 0.04058047904438728\n",
      "epoch: 6, loss: 0.03946655111334087\n",
      "epoch: 7, loss: 0.039806303326709945\n",
      "epoch: 8, loss: 0.03998617955479706\n",
      "epoch: 9, loss: 0.03985229308172952\n",
      "epoch: 10, loss: 0.03919460809280099\n",
      "epoch: 11, loss: 0.03853872247052692\n",
      "epoch: 12, loss: 0.038358171719759776\n",
      "epoch: 13, loss: 0.03826562721150733\n",
      "epoch: 14, loss: 0.03790829679298562\n",
      "epoch: 15, loss: 0.03749627249837904\n",
      "epoch: 16, loss: 0.03716034898954449\n",
      "epoch: 17, loss: 0.036800166623352615\n",
      "epoch: 18, loss: 0.0364610411337796\n",
      "epoch: 19, loss: 0.03635221485813865\n",
      "epoch: 20, loss: 0.03648092999756507\n",
      "epoch: 21, loss: 0.03660774693341411\n",
      "epoch: 22, loss: 0.036603276253938194\n",
      "epoch: 23, loss: 0.0365365372103302\n",
      "epoch: 24, loss: 0.03649109307086237\n",
      "epoch: 25, loss: 0.03643578830342303\n",
      "epoch: 26, loss: 0.03631939214511516\n",
      "epoch: 27, loss: 0.03621240680637117\n",
      "epoch: 28, loss: 0.0361792321913699\n",
      "epoch: 29, loss: 0.036136348120308\n",
      "epoch: 30, loss: 0.03602296668983259\n",
      "epoch: 31, loss: 0.03592149021495338\n",
      "epoch: 32, loss: 0.035898771414439805\n",
      "epoch: 33, loss: 0.03590533512225178\n",
      "epoch: 34, loss: 0.03587822471086912\n",
      "epoch: 35, loss: 0.03583512373409255\n",
      "epoch: 36, loss: 0.03582478773052941\n",
      "epoch: 37, loss: 0.03583566138038753\n",
      "epoch: 38, loss: 0.03582027445127593\n",
      "epoch: 39, loss: 0.03578331580367747\n",
      "epoch: 40, loss: 0.03576631376959491\n",
      "epoch: 41, loss: 0.03576907566523568\n",
      "epoch: 42, loss: 0.03575440334697228\n",
      "epoch: 43, loss: 0.03571693069040101\n",
      "epoch: 44, loss: 0.03569298881773592\n",
      "epoch: 45, loss: 0.035696926266189526\n",
      "epoch: 46, loss: 0.035697153812177716\n",
      "epoch: 47, loss: 0.03567666454047366\n",
      "epoch: 48, loss: 0.03566056694331955\n",
      "epoch: 49, loss: 0.035660635983242116\n",
      "epoch: 50, loss: 0.03565477483940505\n",
      "epoch: 51, loss: 0.03563686790219773\n",
      "epoch: 52, loss: 0.035627881302432836\n",
      "epoch: 53, loss: 0.03563000240329665\n",
      "epoch: 54, loss: 0.03562535757213125\n",
      "epoch: 55, loss: 0.03561674726496229\n",
      "epoch: 56, loss: 0.0356161232845426\n",
      "epoch: 57, loss: 0.035614113122565336\n",
      "epoch: 58, loss: 0.03560306375997893\n",
      "epoch: 59, loss: 0.03559607150706415\n",
      "epoch: 60, loss: 0.03559757797612284\n",
      "epoch: 61, loss: 0.035596079144384146\n",
      "epoch: 62, loss: 0.035592683052081714\n",
      "epoch: 63, loss: 0.0355936317290051\n",
      "epoch: 64, loss: 0.03559194108695724\n",
      "epoch: 65, loss: 0.03558596954573426\n",
      "epoch: 66, loss: 0.0355839522722904\n",
      "epoch: 67, loss: 0.03558408328257793\n",
      "epoch: 68, loss: 0.03558119497026099\n",
      "epoch: 69, loss: 0.035579468030932156\n",
      "epoch: 70, loss: 0.03557983362868603\n",
      "epoch: 71, loss: 0.035577879924907074\n",
      "epoch: 72, loss: 0.0355756123495142\n",
      "epoch: 73, loss: 0.035575459778032184\n",
      "epoch: 74, loss: 0.035574108008794694\n",
      "epoch: 75, loss: 0.03557196510505302\n",
      "epoch: 76, loss: 0.035572005872401356\n",
      "epoch: 77, loss: 0.03557196454003458\n",
      "epoch: 78, loss: 0.03557053508515452\n",
      "epoch: 79, loss: 0.0355700546149535\n",
      "epoch: 80, loss: 0.03556986006749409\n",
      "epoch: 81, loss: 0.035568781589262334\n",
      "epoch: 82, loss: 0.03556844831962794\n",
      "epoch: 83, loss: 0.03556844846898161\n",
      "epoch: 84, loss: 0.03556746113683863\n",
      "epoch: 85, loss: 0.03556675906893173\n",
      "epoch: 86, loss: 0.035566588170852426\n",
      "epoch: 87, loss: 0.03556587385996289\n",
      "epoch: 88, loss: 0.03556525477447414\n",
      "epoch: 89, loss: 0.035564921850758574\n",
      "epoch: 90, loss: 0.03556417961041962\n",
      "epoch: 91, loss: 0.03556361925101639\n",
      "epoch: 92, loss: 0.03556339845033768\n",
      "epoch: 93, loss: 0.03556289008918604\n",
      "epoch: 94, loss: 0.03556248721107529\n",
      "epoch: 95, loss: 0.035562296736534424\n",
      "epoch: 96, loss: 0.035561872796090986\n",
      "epoch: 97, loss: 0.035561521634335916\n",
      "epoch: 98, loss: 0.03556128585709119\n",
      "epoch: 99, loss: 0.03556090267278879\n",
      "epoch: 100, loss: 0.03556066800597982\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qnn_list = []\n",
    "for i in range(10):\n",
    "    qnn = sequential_qnn(n_qubits = [4],\n",
    "                         dim = [3,1],\n",
    "                         encoder = RZZEncoder(),\n",
    "                         ansatz = Ansatz(blocks=[\"entangle\", \"ry\"], reps=10),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         shots = 0)\n",
    "    \n",
    "    qnn_list.append([qnn, x_qnn, y, False])\n",
    "\n",
    "    \n",
    "qnn_list[0][3] = True\n",
    "\n",
    "with mp.Pool(10) as p:\n",
    "    qnn_list = p.map(parallel, qnn_list) \n",
    "    \n",
    "    \n",
    "saver(qnn_list, data_path(\"trainability_qnn_2D\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qcn_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = [4, 4, 4],\n",
    "                         dim = [2, 4, 4, 1],\n",
    "                         encoder= Encoder(),\n",
    "                         ansatz = Ansatz(blocks = [\"entangle\", \"ry\"], reps=1),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         backend=backend,\n",
    "                         shots=0)\n",
    "    qcn_list.append([qcn, x_qcn, y, False])\n",
    "    \n",
    "qcn_list[0][3] = True    \n",
    "    \n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list)   \n",
    "\n",
    "saver(qcn_list, data_path(\"trainability_qcn_2D_reps_1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qcn_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = [4, 4, 4],\n",
    "                         dim = [2, 4, 4, 1],\n",
    "                         encoder= Encoder(),\n",
    "                         ansatz = Ansatz(blocks = [\"entangle\", \"ry\"], reps=2),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         backend=backend,\n",
    "                         shots=0)\n",
    "   \n",
    "    qcn_list.append([qcn, x_qcn, y, False])\n",
    "\n",
    "qcn_list[0][3] = True    \n",
    "    \n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list)   \n",
    "    \n",
    "saver(qcn_list, data_path(\"trainability_qcn_2D_reps_2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dnn_list = []\n",
    "for i in range(10):\n",
    "    dnn = sequential_dnn(dim = [2, 5, 5, 1],\n",
    "                         activation = [Tanh(), Tanh(), Identity()],\n",
    "                         optimizer = Adam(lr=0.1))\n",
    "    \n",
    "    dnn.train(x_dnn, y, epochs=100)\n",
    "    dnn_list.append(dnn)\n",
    "\n",
    "saver(dnn_list, data_path(\"trainability_dnn_2D_epochs_100\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dnn_list = []\n",
    "for i in range(10):\n",
    "    dnn = sequential_dnn(dim = [2, 5, 5, 1],\n",
    "                         activation = [Tanh(), Tanh(), Identity()],\n",
    "                         optimizer = Adam(lr=0.1))\n",
    "    \n",
    "    dnn.train(x_dnn, y, epochs=10000)\n",
    "    dnn_list.append(dnn)\n",
    "\n",
    "saver(dnn_list, data_path(\"trainability_dnn_2D_epochs_10000\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 6\n",
    "x, y = generate_3D_mixed_gaussian()\n",
    "x_qcn = scaler(x, a=-np.pi/2, b=np.pi/2)\n",
    "x_qnn = x_qcn\n",
    "x_dnn = scaler(x, mode=\"standard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(y.reshape(n,n,n)[1])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.030833617985558084\n",
      "epoch: 1, loss: 0.030247041311208728\n",
      "epoch: 2, loss: 0.02350912040519421\n",
      "epoch: 3, loss: 0.024701122495593916\n",
      "epoch: 4, loss: 0.024100254928790334\n",
      "epoch: 5, loss: 0.021488260858062977\n",
      "epoch: 6, loss: 0.02145526409352309\n",
      "epoch: 7, loss: 0.021906443126305936\n",
      "epoch: 8, loss: 0.021193105270017214\n",
      "epoch: 9, loss: 0.020614032134376487\n",
      "epoch: 10, loss: 0.020683446724597536\n",
      "epoch: 11, loss: 0.02085096565639248\n",
      "epoch: 12, loss: 0.020821605405740153\n",
      "epoch: 13, loss: 0.020676847037667683\n",
      "epoch: 14, loss: 0.020479998449086087\n",
      "epoch: 15, loss: 0.020262769665705484\n",
      "epoch: 16, loss: 0.020112797587682193\n",
      "epoch: 17, loss: 0.02008149999197412\n",
      "epoch: 18, loss: 0.020096317895330333\n",
      "epoch: 19, loss: 0.02006682295727245\n",
      "epoch: 20, loss: 0.019985547343352453\n",
      "epoch: 21, loss: 0.019898218877782124\n",
      "epoch: 22, loss: 0.019834762390935106\n",
      "epoch: 23, loss: 0.01979418512657666\n",
      "epoch: 24, loss: 0.01977105507279797\n",
      "epoch: 25, loss: 0.019754667853251893\n",
      "epoch: 26, loss: 0.019726370279944946\n",
      "epoch: 27, loss: 0.019682434313265232\n",
      "epoch: 28, loss: 0.019642040139727323\n",
      "epoch: 29, loss: 0.01962197230898072\n",
      "epoch: 30, loss: 0.019616476777239766\n",
      "epoch: 31, loss: 0.019609571528744887\n",
      "epoch: 32, loss: 0.01959704069509116\n",
      "epoch: 33, loss: 0.01958733720441473\n",
      "epoch: 34, loss: 0.019584833600901512\n",
      "epoch: 35, loss: 0.01958242361911636\n",
      "epoch: 36, loss: 0.019572397518290124\n",
      "epoch: 37, loss: 0.019557353977615\n",
      "epoch: 38, loss: 0.01954494137432205\n",
      "epoch: 39, loss: 0.01953634904191028\n",
      "epoch: 40, loss: 0.01952801199261068\n",
      "epoch: 41, loss: 0.01952054888798911\n",
      "epoch: 42, loss: 0.019516803860746265\n",
      "epoch: 43, loss: 0.019514319435789258\n",
      "epoch: 44, loss: 0.019507143291765856\n",
      "epoch: 45, loss: 0.019494452227052754\n",
      "epoch: 46, loss: 0.019483096619939574\n",
      "epoch: 47, loss: 0.0194795494849697\n",
      "epoch: 48, loss: 0.01948188676401039\n",
      "epoch: 49, loss: 0.01948386831490488\n",
      "epoch: 50, loss: 0.019483821356900983\n",
      "epoch: 51, loss: 0.019483451917235425\n",
      "epoch: 52, loss: 0.019482275919788097\n",
      "epoch: 53, loss: 0.019479658387693086\n",
      "epoch: 54, loss: 0.019478096846256922\n",
      "epoch: 55, loss: 0.01947934728696983\n",
      "epoch: 56, loss: 0.0194806493154789\n",
      "epoch: 57, loss: 0.019478926046246146\n",
      "epoch: 58, loss: 0.01947569374470726\n",
      "epoch: 59, loss: 0.0194740171706733\n",
      "epoch: 60, loss: 0.019473731766994545\n",
      "epoch: 61, loss: 0.019473019932785673\n",
      "epoch: 62, loss: 0.019471759853975895\n",
      "epoch: 63, loss: 0.019470550538684833\n",
      "epoch: 64, loss: 0.019469023841125574\n",
      "epoch: 65, loss: 0.019467297773788264\n",
      "epoch: 66, loss: 0.01946673735857312\n",
      "epoch: 67, loss: 0.019467723734136883\n",
      "epoch: 68, loss: 0.019468654931558756\n",
      "epoch: 69, loss: 0.019468196489905668\n",
      "epoch: 70, loss: 0.019467014257196432\n",
      "epoch: 71, loss: 0.019466412548257917\n",
      "epoch: 72, loss: 0.019466518007910837\n",
      "epoch: 73, loss: 0.019466729684450762\n",
      "epoch: 74, loss: 0.019466819094067642\n",
      "epoch: 75, loss: 0.01946672785848175\n",
      "epoch: 76, loss: 0.019466281262418592\n",
      "epoch: 77, loss: 0.01946566801005191\n",
      "epoch: 78, loss: 0.019465351064910076\n",
      "epoch: 79, loss: 0.019465350545956633\n",
      "epoch: 80, loss: 0.019465346850406462\n",
      "epoch: 81, loss: 0.019465301741829196\n",
      "epoch: 82, loss: 0.019465344826573097\n",
      "epoch: 83, loss: 0.019465384895807698\n",
      "epoch: 84, loss: 0.019465297117612065\n",
      "epoch: 85, loss: 0.019465150315673117\n",
      "epoch: 86, loss: 0.019465032749144143\n",
      "epoch: 87, loss: 0.01946495082924121\n",
      "epoch: 88, loss: 0.01946491514778427\n",
      "epoch: 89, loss: 0.019464916262989226\n",
      "epoch: 90, loss: 0.019464890560872777\n",
      "epoch: 91, loss: 0.019464811624441764\n",
      "epoch: 92, loss: 0.019464732648662598\n",
      "epoch: 93, loss: 0.019464705469643708\n",
      "epoch: 94, loss: 0.019464708245754594\n",
      "epoch: 95, loss: 0.01946469095234809\n",
      "epoch: 96, loss: 0.0194646670568527\n",
      "epoch: 97, loss: 0.019464677726570526\n",
      "epoch: 98, loss: 0.019464694490009565\n",
      "epoch: 99, loss: 0.01946466645950213\n",
      "epoch: 100, loss: 0.019464615234113993\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qnn_list = []\n",
    "for i in range(10):\n",
    "    qnn = sequential_qnn(n_qubits = [5],\n",
    "                         dim = [3,1],\n",
    "                         encoder = RZZEncoder(),\n",
    "                         ansatz = Ansatz(blocks=[\"entangle\", \"ry\"], reps=11),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         shots = 0)\n",
    "    \n",
    "    qnn_list.append([qnn, x_qnn, y, False])\n",
    "\n",
    "    \n",
    "qnn_list[0][3] = True\n",
    "\n",
    "with mp.Pool(10) as p:\n",
    "    qnn_list = p.map(parallel, qnn_list) \n",
    "    \n",
    "    \n",
    "saver(qnn_list, data_path(\"trainability_qnn_3D\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qcn_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = [5, 5, 5],\n",
    "                         dim = [3, 5, 5, 1],\n",
    "                         encoder= Encoder(),\n",
    "                         ansatz = Ansatz(blocks = [\"entangle\", \"ry\"], reps = 1),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         backend = backend,\n",
    "                         shots = 0)\n",
    "\n",
    "    qcn_list.append([qcn, x_qcn, y, False])\n",
    "\n",
    "qcn_list[0][3] = True    \n",
    "    \n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list) \n",
    "    \n",
    "saver(qcn_list, data_path(\"trainability_qcn_3D_reps_1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qcn_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = [5, 5, 5],\n",
    "                         dim = [3, 5, 5, 1],\n",
    "                         encoder= Encoder(),\n",
    "                         ansatz = Ansatz(blocks = [\"entangle\", \"ry\"], reps = 2),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         backend = backend,\n",
    "                         shots = 0)\n",
    "\n",
    "    qcn_list.append([qcn, x_qcn, y, False])\n",
    "\n",
    "qcn_list[0][3] = True    \n",
    "    \n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list) \n",
    "    \n",
    "saver(qcn_list, data_path(\"trainability_qcn_3D_reps_2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dnn_list = []\n",
    "for i in range(10):\n",
    "    dnn = sequential_dnn(dim = [3, 8, 8, 1],\n",
    "                         activation = [Tanh(), Tanh(), Identity()],\n",
    "                         optimizer = Adam(lr=0.1))\n",
    "    \n",
    "    dnn.train(x_dnn, y, epochs=100)\n",
    "    dnn_list.append(dnn)\n",
    "\n",
    "saver(dnn_list, data_path(\"trainability_dnn_3D_epochs_100\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dnn_list = []\n",
    "for i in range(10):\n",
    "    dnn = sequential_dnn(dim = [3, 8, 8, 1],\n",
    "                         activation = [Tanh(), Tanh(), Identity()],\n",
    "                         optimizer = Adam(lr=0.1))\n",
    "    \n",
    "    dnn.train(x_dnn, y, epochs=10000)\n",
    "    dnn_list.append(dnn)\n",
    "\n",
    "saver(dnn_list, data_path(\"trainability_dnn_3D_epochs_10000\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_qiskit",
   "language": "python",
   "name": "env_qiskit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
