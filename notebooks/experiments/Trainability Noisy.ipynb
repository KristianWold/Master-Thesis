{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qiskit as qk\n",
    "import matplotlib.pyplot as plt\n",
    "from qiskit import Aer\n",
    "from tqdm.notebook import tqdm\n",
    "import multiprocessing as mp\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../src/')\n",
    "from neuralnetwork import *\n",
    "from analysis import *\n",
    "from utils import *\n",
    "\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = Aer.get_backend('qasm_simulator')\n",
    "\n",
    "def parallel(args):\n",
    "    model = args[0]\n",
    "    x = args[1]\n",
    "    y = args[2]\n",
    "    verbose = args[3]\n",
    "    \n",
    "    model.train(x, y, epochs=100, verbose = verbose)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend_santiago = pickle.load(open(\"backend_santiago\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainability, Ideal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D, Gaussian Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "x, y = generate_1D_mixed_gaussian()\n",
    "\n",
    "x_qcn = scaler(x, a=-np.pi/2, b=np.pi/2)\n",
    "x_qnn = np.hstack([x_qcn, x_qcn, x_qcn])\n",
    "x_dnn = scaler(x, mode=\"standard\")\n",
    "y = scaler(y, a=0, b=1)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_qcn, y, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.12683268375000614\n",
      "epoch: 1, loss: 0.11450010715383609\n",
      "epoch: 2, loss: 0.10899115575411202\n",
      "epoch: 3, loss: 0.09832812193873464\n",
      "epoch: 4, loss: 0.08858726967949977\n",
      "epoch: 5, loss: 0.08275227608672914\n",
      "epoch: 6, loss: 0.08047662400848293\n",
      "epoch: 7, loss: 0.07562840079289368\n",
      "epoch: 8, loss: 0.07549882446541824\n",
      "epoch: 9, loss: 0.07284268451402759\n",
      "epoch: 10, loss: 0.07057216631993178\n",
      "epoch: 11, loss: 0.07317669600587137\n",
      "epoch: 12, loss: 0.07325121194489975\n",
      "epoch: 13, loss: 0.07126183450343197\n",
      "epoch: 14, loss: 0.06944889643220402\n",
      "epoch: 15, loss: 0.06947370221939984\n",
      "epoch: 16, loss: 0.07044278768662375\n",
      "epoch: 17, loss: 0.06999022258153492\n",
      "epoch: 18, loss: 0.07022719373994091\n",
      "epoch: 19, loss: 0.06615743082736242\n",
      "epoch: 20, loss: 0.06831813404852308\n",
      "epoch: 21, loss: 0.06776876755889051\n",
      "epoch: 22, loss: 0.06538012622086911\n",
      "epoch: 23, loss: 0.0705501777319372\n",
      "epoch: 24, loss: 0.06870853690820171\n",
      "epoch: 25, loss: 0.06699947944626916\n",
      "epoch: 26, loss: 0.06749429106917008\n",
      "epoch: 27, loss: 0.06774876440969801\n",
      "epoch: 28, loss: 0.06819125281016389\n",
      "epoch: 29, loss: 0.06633194171939275\n",
      "epoch: 30, loss: 0.06927374168124\n",
      "epoch: 31, loss: 0.06424444276596177\n",
      "epoch: 32, loss: 0.06647466899312823\n",
      "epoch: 33, loss: 0.06632249209991083\n",
      "epoch: 34, loss: 0.06502223550325927\n",
      "epoch: 35, loss: 0.06454612262843808\n",
      "epoch: 36, loss: 0.06329500799166263\n",
      "epoch: 37, loss: 0.06489588482186011\n",
      "epoch: 38, loss: 0.06449615810029394\n",
      "epoch: 39, loss: 0.0653858946156883\n",
      "epoch: 40, loss: 0.06526095959042581\n",
      "epoch: 41, loss: 0.06632545751643656\n",
      "epoch: 42, loss: 0.06646453504949823\n",
      "epoch: 43, loss: 0.06645971432992494\n",
      "epoch: 44, loss: 0.06496200851401601\n",
      "epoch: 45, loss: 0.06549092557881823\n",
      "epoch: 46, loss: 0.06721648902687768\n",
      "epoch: 47, loss: 0.06484201926852569\n",
      "epoch: 48, loss: 0.06559321511895438\n",
      "epoch: 49, loss: 0.0636220732800678\n",
      "epoch: 50, loss: 0.06445219815689268\n",
      "epoch: 51, loss: 0.06405090902042097\n",
      "epoch: 52, loss: 0.06466093648241199\n",
      "epoch: 53, loss: 0.06515460737323772\n",
      "epoch: 54, loss: 0.06685493020812443\n",
      "epoch: 55, loss: 0.0659857508418653\n",
      "epoch: 56, loss: 0.06537755047336692\n",
      "epoch: 57, loss: 0.06558217961314833\n",
      "epoch: 58, loss: 0.06447861951092163\n",
      "epoch: 59, loss: 0.0626764215504097\n",
      "epoch: 60, loss: 0.06428928670392464\n",
      "epoch: 61, loss: 0.06342765287477388\n",
      "epoch: 62, loss: 0.06639956244900601\n",
      "epoch: 63, loss: 0.06619232652471474\n",
      "epoch: 64, loss: 0.06459140378210558\n",
      "epoch: 65, loss: 0.06346051260836429\n",
      "epoch: 66, loss: 0.06431189942057751\n",
      "epoch: 67, loss: 0.06471714486856327\n",
      "epoch: 68, loss: 0.06464401318432338\n",
      "epoch: 69, loss: 0.06270918232972451\n",
      "epoch: 70, loss: 0.06740605520610725\n",
      "epoch: 71, loss: 0.06639457179139716\n",
      "epoch: 72, loss: 0.06281881725134043\n",
      "epoch: 73, loss: 0.06633738391126125\n",
      "epoch: 74, loss: 0.0640614872013545\n",
      "epoch: 75, loss: 0.06299588045990634\n",
      "epoch: 76, loss: 0.06671882132502434\n",
      "epoch: 77, loss: 0.06400045501481513\n",
      "epoch: 78, loss: 0.06665199244856237\n",
      "epoch: 79, loss: 0.06447716059414488\n",
      "epoch: 80, loss: 0.06344994422883285\n",
      "epoch: 81, loss: 0.06528147140898997\n",
      "epoch: 82, loss: 0.06457087539507801\n",
      "epoch: 83, loss: 0.06550529341034306\n",
      "epoch: 84, loss: 0.0651120618634599\n",
      "epoch: 85, loss: 0.0649359422780813\n",
      "epoch: 86, loss: 0.06526842706300945\n",
      "epoch: 87, loss: 0.06554078051526556\n",
      "epoch: 88, loss: 0.06738851509295488\n",
      "epoch: 89, loss: 0.06321197899657298\n",
      "epoch: 90, loss: 0.06482802606042522\n",
      "epoch: 91, loss: 0.06449697685989643\n",
      "epoch: 92, loss: 0.06518644410251309\n",
      "epoch: 93, loss: 0.06481231221548192\n",
      "epoch: 94, loss: 0.06356340331808494\n",
      "epoch: 95, loss: 0.06293818279280865\n",
      "epoch: 96, loss: 0.06339662655039319\n",
      "epoch: 97, loss: 0.06419871848327789\n",
      "epoch: 98, loss: 0.06579900443606107\n",
      "epoch: 99, loss: 0.0652220453314507\n",
      "epoch: 100, loss: 0.06592321180920409\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qnn_list = []\n",
    "for i in range(10):\n",
    "    qnn = sequential_qnn(n_qubits = [4],\n",
    "                         dim = [3,1],\n",
    "                         encoder = RZZEncoder(),\n",
    "                         ansatz = Ansatz(blocks=[\"entangle\", \"ry\"], reps=5),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         backend=backend_santiago,\n",
    "                         shots = 1024)\n",
    "    \n",
    "    qnn_list.append([qnn, x_qnn, y, False])\n",
    "\n",
    "    \n",
    "qnn_list[0][3] = True\n",
    "\n",
    "with mp.Pool(10) as p:\n",
    "    qnn_list = p.map(parallel, qnn_list) \n",
    "    \n",
    "    \n",
    "saver(qnn_list, data_path(\"trainability_qnn_1D_noisy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.13782207310031894\n",
      "epoch: 1, loss: 0.12082813943569562\n",
      "epoch: 2, loss: 0.11319703495806706\n",
      "epoch: 3, loss: 0.10431275842392589\n",
      "epoch: 4, loss: 0.09879752203290255\n",
      "epoch: 5, loss: 0.08643947659328453\n",
      "epoch: 6, loss: 0.0738450300917962\n",
      "epoch: 7, loss: 0.06140143395760164\n",
      "epoch: 8, loss: 0.051247305430959844\n",
      "epoch: 9, loss: 0.04852302304843979\n",
      "epoch: 10, loss: 0.04412173447191851\n",
      "epoch: 11, loss: 0.03911248681394623\n",
      "epoch: 12, loss: 0.03657841147341408\n",
      "epoch: 13, loss: 0.034990440362007345\n",
      "epoch: 14, loss: 0.030513398168545515\n",
      "epoch: 15, loss: 0.026355867379136564\n",
      "epoch: 16, loss: 0.02203043299792694\n",
      "epoch: 17, loss: 0.02144178522249634\n",
      "epoch: 18, loss: 0.020126110713316495\n",
      "epoch: 19, loss: 0.02028877300728014\n",
      "epoch: 20, loss: 0.019519681936064737\n",
      "epoch: 21, loss: 0.01763435737095374\n",
      "epoch: 22, loss: 0.01796364711781339\n",
      "epoch: 23, loss: 0.016071515812282427\n",
      "epoch: 24, loss: 0.014534456203442833\n",
      "epoch: 25, loss: 0.01387192740748806\n",
      "epoch: 26, loss: 0.013829977823685342\n",
      "epoch: 27, loss: 0.014339052983073655\n",
      "epoch: 28, loss: 0.01210557273531447\n",
      "epoch: 29, loss: 0.01241971444598345\n",
      "epoch: 30, loss: 0.012855687820125987\n",
      "epoch: 31, loss: 0.010745567474224022\n",
      "epoch: 32, loss: 0.010690106550019493\n",
      "epoch: 33, loss: 0.010204133058113997\n",
      "epoch: 34, loss: 0.010088946800320393\n",
      "epoch: 35, loss: 0.009965372621438269\n",
      "epoch: 36, loss: 0.009648421497475003\n",
      "epoch: 37, loss: 0.00875275285825989\n",
      "epoch: 38, loss: 0.009189721835466444\n",
      "epoch: 39, loss: 0.008834014999940347\n",
      "epoch: 40, loss: 0.008095964935498443\n",
      "epoch: 41, loss: 0.008363076858497066\n",
      "epoch: 42, loss: 0.006795810718414188\n",
      "epoch: 43, loss: 0.007912983519079377\n",
      "epoch: 44, loss: 0.008032868396173202\n",
      "epoch: 45, loss: 0.008181500618124407\n",
      "epoch: 46, loss: 0.008215194385762537\n",
      "epoch: 47, loss: 0.008187405133857885\n",
      "epoch: 48, loss: 0.006957880907433425\n",
      "epoch: 49, loss: 0.008172085172797139\n",
      "epoch: 50, loss: 0.008185458036444522\n",
      "epoch: 51, loss: 0.00822014955006656\n",
      "epoch: 52, loss: 0.008507419375138582\n",
      "epoch: 53, loss: 0.008297824298247533\n",
      "epoch: 54, loss: 0.0076111133229540325\n",
      "epoch: 55, loss: 0.008104813655498241\n",
      "epoch: 56, loss: 0.007598415162246436\n",
      "epoch: 57, loss: 0.007834315695660378\n",
      "epoch: 58, loss: 0.007784409236575453\n",
      "epoch: 59, loss: 0.00802734355563212\n",
      "epoch: 60, loss: 0.006943207179630444\n",
      "epoch: 61, loss: 0.00739707372551819\n",
      "epoch: 62, loss: 0.007132579563745206\n",
      "epoch: 63, loss: 0.007051713242377202\n",
      "epoch: 64, loss: 0.007008729540301467\n",
      "epoch: 65, loss: 0.006767003612739576\n",
      "epoch: 66, loss: 0.0077406869347596795\n",
      "epoch: 67, loss: 0.0068031856575789165\n",
      "epoch: 68, loss: 0.006560671690871018\n",
      "epoch: 69, loss: 0.00774146980107499\n",
      "epoch: 70, loss: 0.007652079571660801\n",
      "epoch: 71, loss: 0.007363062185103586\n",
      "epoch: 72, loss: 0.007311007233040207\n",
      "epoch: 73, loss: 0.0075023355134454725\n",
      "epoch: 74, loss: 0.006871058816599748\n",
      "epoch: 75, loss: 0.007450245694635349\n",
      "epoch: 76, loss: 0.00725432219674031\n",
      "epoch: 77, loss: 0.007139178133913675\n",
      "epoch: 78, loss: 0.00880889068622948\n",
      "epoch: 79, loss: 0.007451309627622384\n",
      "epoch: 80, loss: 0.007838883068485798\n",
      "epoch: 81, loss: 0.007437118323110024\n",
      "epoch: 82, loss: 0.006712449127837714\n",
      "epoch: 83, loss: 0.006782826579092015\n",
      "epoch: 84, loss: 0.007678682481590812\n",
      "epoch: 85, loss: 0.007480097214022909\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qcn_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = [4, 4],\n",
    "                         dim = [1, 4, 1],\n",
    "                         encoder = Encoder(),\n",
    "                         ansatz = Ansatz(blocks = [\"entangle\", \"ry\"], reps=1),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         backend = backend_santiago,\n",
    "                         shots = 1024)\n",
    "    \n",
    "    qcn_list.append([qcn, x_qcn, y, False])\n",
    "\n",
    "    \n",
    "qcn_list[0][3] = True\n",
    "\n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list) \n",
    "    \n",
    "    \n",
    "saver(qcn_list, data_path(\"trainability_qcn_1D_reps_1_noisy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.1593583265595664\n",
      "epoch: 1, loss: 0.08846082761067726\n",
      "epoch: 2, loss: 0.08847660208377212\n",
      "epoch: 3, loss: 0.0798060818086736\n",
      "epoch: 4, loss: 0.058430023534644555\n",
      "epoch: 5, loss: 0.03832025330183968\n",
      "epoch: 6, loss: 0.030628235663976596\n",
      "epoch: 7, loss: 0.03083024729787644\n",
      "epoch: 8, loss: 0.026817076443331006\n",
      "epoch: 9, loss: 0.022779475579639594\n",
      "epoch: 10, loss: 0.020697399761722877\n",
      "epoch: 11, loss: 0.020365547698956044\n",
      "epoch: 12, loss: 0.01969589279792761\n",
      "epoch: 13, loss: 0.019417756538345765\n",
      "epoch: 14, loss: 0.020688450720140833\n",
      "epoch: 15, loss: 0.018755605459717654\n",
      "epoch: 16, loss: 0.01959442863134125\n",
      "epoch: 17, loss: 0.02063576274995773\n",
      "epoch: 18, loss: 0.019127212201426748\n",
      "epoch: 19, loss: 0.01785086443371705\n",
      "epoch: 20, loss: 0.01626145075587007\n",
      "epoch: 21, loss: 0.014873250538031292\n",
      "epoch: 22, loss: 0.01394084458692247\n",
      "epoch: 23, loss: 0.013055982744538659\n",
      "epoch: 24, loss: 0.013157455967315539\n",
      "epoch: 25, loss: 0.012842086278010645\n",
      "epoch: 26, loss: 0.012003059407746963\n",
      "epoch: 27, loss: 0.012876646307150968\n",
      "epoch: 28, loss: 0.011940489770704525\n",
      "epoch: 29, loss: 0.01269958670986458\n",
      "epoch: 30, loss: 0.011727415976830809\n",
      "epoch: 31, loss: 0.011536129231948172\n",
      "epoch: 32, loss: 0.011059147243272638\n",
      "epoch: 33, loss: 0.010774378062536432\n",
      "epoch: 34, loss: 0.01127242674532452\n",
      "epoch: 35, loss: 0.010283908902165996\n",
      "epoch: 36, loss: 0.010424906758083892\n",
      "epoch: 37, loss: 0.009628012432912137\n",
      "epoch: 38, loss: 0.009541456440700749\n",
      "epoch: 39, loss: 0.009818692724478089\n",
      "epoch: 40, loss: 0.009802896448806185\n",
      "epoch: 41, loss: 0.009817113684461285\n",
      "epoch: 42, loss: 0.00910892012962618\n",
      "epoch: 43, loss: 0.00912931471234984\n",
      "epoch: 44, loss: 0.009759336136482577\n",
      "epoch: 45, loss: 0.00910525573841519\n",
      "epoch: 46, loss: 0.008929545239063197\n",
      "epoch: 47, loss: 0.008144331188780446\n",
      "epoch: 48, loss: 0.009323213231938144\n",
      "epoch: 49, loss: 0.008904490317637204\n",
      "epoch: 50, loss: 0.009147657672766788\n",
      "epoch: 51, loss: 0.008744956546680204\n",
      "epoch: 52, loss: 0.007548825088245461\n",
      "epoch: 53, loss: 0.007333344465820958\n",
      "epoch: 54, loss: 0.007898217739662504\n",
      "epoch: 55, loss: 0.007415097356751206\n",
      "epoch: 56, loss: 0.007392122417307646\n",
      "epoch: 57, loss: 0.008143957738974498\n",
      "epoch: 58, loss: 0.007861209523269238\n",
      "epoch: 59, loss: 0.007034439112299511\n",
      "epoch: 60, loss: 0.007171664682696101\n",
      "epoch: 61, loss: 0.007274201488145721\n",
      "epoch: 62, loss: 0.006914260548609571\n",
      "epoch: 63, loss: 0.007451233777300052\n",
      "epoch: 64, loss: 0.006993922945376014\n",
      "epoch: 65, loss: 0.00785817582279718\n",
      "epoch: 66, loss: 0.006947454079769127\n",
      "epoch: 67, loss: 0.0067822260826396995\n",
      "epoch: 68, loss: 0.006807365223176042\n",
      "epoch: 69, loss: 0.006622875415258443\n",
      "epoch: 70, loss: 0.006646835793762741\n",
      "epoch: 71, loss: 0.007099378016301536\n",
      "epoch: 72, loss: 0.0059921727959344195\n",
      "epoch: 73, loss: 0.007164646451342417\n",
      "epoch: 74, loss: 0.00677935416241331\n",
      "epoch: 75, loss: 0.006394276273678377\n",
      "epoch: 76, loss: 0.00756875303418657\n",
      "epoch: 77, loss: 0.00688159813186228\n",
      "epoch: 78, loss: 0.007054131226435847\n",
      "epoch: 79, loss: 0.006187776029165153\n",
      "epoch: 80, loss: 0.006514012333559877\n",
      "epoch: 81, loss: 0.006975851647776872\n",
      "epoch: 82, loss: 0.005838756497772561\n",
      "epoch: 83, loss: 0.006382845023919496\n",
      "epoch: 84, loss: 0.006199951978864994\n",
      "epoch: 85, loss: 0.00651228994211078\n",
      "epoch: 86, loss: 0.006735452543628689\n",
      "epoch: 87, loss: 0.006321872052351332\n",
      "epoch: 88, loss: 0.00667555888753844\n",
      "epoch: 89, loss: 0.005995829307984245\n",
      "epoch: 90, loss: 0.0068064452219093515\n",
      "epoch: 91, loss: 0.006539751870405788\n",
      "epoch: 92, loss: 0.005882730114631728\n",
      "epoch: 93, loss: 0.006145550196970383\n",
      "epoch: 94, loss: 0.006094711914682138\n",
      "epoch: 95, loss: 0.006687671125406972\n",
      "epoch: 96, loss: 0.006264857399097068\n",
      "epoch: 97, loss: 0.006288080855623157\n",
      "epoch: 98, loss: 0.006602896256247917\n",
      "epoch: 99, loss: 0.0067595959619709935\n",
      "epoch: 100, loss: 0.006025718075988242\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qcn_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = [4, 4],\n",
    "                         dim = [1, 4, 1],\n",
    "                         encoder= Encoder(),\n",
    "                         ansatz = Ansatz(blocks = [\"entangle\", \"ry\"], reps=2),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         backend = backend_santiago,\n",
    "                         shots=1024)\n",
    "    \n",
    "    qcn_list.append([qcn, x_qcn, y, False])\n",
    "\n",
    "qcn_list[0][3] = True    \n",
    "    \n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list)     \n",
    "    \n",
    "saver(qcn_list, data_path(\"trainability_qcn_1D_reps_2_noisy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n = 12\n",
    "x, y = generate_2D_mixed_gaussian()\n",
    "x_qcn = scaler(x, a=-np.pi/2, b=np.pi/2)\n",
    "x_qnn = np.hstack([x_qcn, x_qcn[:,0:1]])\n",
    "x_dnn = scaler(x, mode=\"standard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y.reshape(n,n))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qnn_list = []\n",
    "for i in range(10):\n",
    "    qnn = sequential_qnn(n_qubits = [4],\n",
    "                         dim = [3,1],\n",
    "                         encoder = RZZEncoder(),\n",
    "                         ansatz = Ansatz(blocks=[\"entangle\", \"ry\"], reps=10),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         shots = 0)\n",
    "    \n",
    "    qnn_list.append([qnn, x_qnn, y, False])\n",
    "    print(x_qnn.shape)\n",
    "\n",
    "    \n",
    "qnn_list[0][3] = True\n",
    "\n",
    "with mp.Pool(10) as p:\n",
    "    qnn_list = p.map(parallel, qnn_list) \n",
    "    \n",
    "    \n",
    "saver(qnn_list, data_path(\"trainability_qnn_2D_noisy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qcn_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = [4, 4, 4],\n",
    "                         dim = [2, 4, 4, 1],\n",
    "                         encoder= Encoder(),\n",
    "                         ansatz = Ansatz(blocks = [\"entangle\", \"ry\"], reps=1),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         backend = backend_santiago,\n",
    "                         shots=1024)\n",
    "    qcn_list.append([qcn, x_qcn, y, False])\n",
    "    \n",
    "qcn_list[0][3] = True    \n",
    "    \n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list)\n",
    "\n",
    "saver(qcn_list, data_path(\"trainability_qcn_2D_reps_1_noisy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qcn_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = [4, 4, 4],\n",
    "                         dim = [2, 4, 4, 1],\n",
    "                         encoder= Encoder(),\n",
    "                         ansatz = Ansatz(blocks = [\"entangle\", \"ry\"], reps=2),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         backend = backend_santiago,\n",
    "                         shots=1024)\n",
    "   \n",
    "    qcn_list.append([qcn, x_qcn, y, False])\n",
    "\n",
    "qcn_list[0][3] = True    \n",
    "    \n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list)   \n",
    "    \n",
    "saver(qcn_list, data_path(\"trainability_qcn_2D_reps_2_noisy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcn_list = loader(data_path(\"trainability_qcn_2D_reps_2_noisy\"))\n",
    "qcn_list = [[qcn, x_qcn, y, False] for qcn in qcn_list]\n",
    "qcn_list[0][3] = True  \n",
    "\n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list)   \n",
    "    \n",
    "saver(qcn_list, data_path(\"trainability_qcn_2D_reps_2_noisy_2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcn_list = loader(data_path(\"trainability_qcn_2D_reps_2_noisy_2\"))\n",
    "qcn_list = [[qcn, x_qcn, y, False] for qcn in qcn_list]\n",
    "qcn_list[0][3] = True  \n",
    "\n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list)   \n",
    "    \n",
    "saver(qcn_list, data_path(\"trainability_qcn_2D_reps_2_noisy_3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcn_list = loader(data_path(\"trainability_qcn_2D_reps_2_noisy_3\"))\n",
    "qcn_list = [[qcn, x_qcn, y, False] for qcn in qcn_list]\n",
    "qcn_list[0][3] = True  \n",
    "\n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list)   \n",
    "    \n",
    "saver(qcn_list, data_path(\"trainability_qcn_2D_reps_2_noisy_4\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_qiskit",
   "language": "python",
   "name": "env_qiskit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
