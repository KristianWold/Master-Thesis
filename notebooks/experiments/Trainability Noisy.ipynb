{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import qiskit as qk\n",
    "import matplotlib.pyplot as plt\n",
    "from qiskit import Aer\n",
    "from tqdm.notebook import tqdm\n",
    "import multiprocessing as mp\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../src/')\n",
    "from neuralnetwork import *\n",
    "from analysis import *\n",
    "from utils import *\n",
    "\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = Aer.get_backend('qasm_simulator')\n",
    "\n",
    "def parallel(args):\n",
    "    model = args[0]\n",
    "    x = args[1]\n",
    "    y = args[2]\n",
    "    verbose = args[3]\n",
    "    \n",
    "    model.train(x, y, epochs=25, verbose = verbose)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend_santiago = pickle.load(open(\"backend_santiago\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainability, Ideal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D, Gaussian Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "x = np.linspace(0, 1, n).reshape(-1,1)\n",
    "y = gaussian(x, 0.2, 0.01) - gaussian(x, 0.5, 0.01) + gaussian(x, 0.8, 0.01)\n",
    "\n",
    "x_qcn = scaler(x, a=-np.pi/2, b=np.pi/2)\n",
    "x_dnn = scaler(x, mode=\"standard\")\n",
    "y = scaler(y, a=0, b=1)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(x_qcn, y, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qcn_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = [4, 4],\n",
    "                         dim = [1, 4, 1],\n",
    "                         encoder = Encoder(),\n",
    "                         ansatz = Ansatz(blocks = [\"entangle\", \"ry\"], reps=1),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         backend = backend_santiago,\n",
    "                         shots = 1024)\n",
    "    \n",
    "    qcn_list.append([qcn, x_qcn, y, False])\n",
    "\n",
    "    \n",
    "qcn_list[0][3] = True\n",
    "\n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list) \n",
    "    \n",
    "    \n",
    "saver(qcn_list, data_path(\"trainability_qcn_1D_reps_1_noisy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qcn_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = [4, 4],\n",
    "                         dim = [1, 4, 1],\n",
    "                         encoder= Encoder(),\n",
    "                         ansatz = Ansatz(blocks = [\"entangle\", \"ry\"], reps=2),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         backend = backend_santiago,\n",
    "                         shots=1024)\n",
    "    \n",
    "    qcn_list.append([qcn, x_qcn, y, False])\n",
    "\n",
    "qcn_list[0][3] = True    \n",
    "    \n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list)     \n",
    "    \n",
    "saver(qcn_list, data_path(\"trainability_qcn_1D_reps_2_noisy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dnn_list = []\n",
    "for i in range(10):\n",
    "    dnn = sequential_dnn(dim = [1, 5, 1],\n",
    "                         optimizer = Adam(lr=0.1))\n",
    "    \n",
    "    dnn.train(x_dnn, y, epochs=100)\n",
    "    dnn_list.append(dnn)\n",
    "\n",
    "saver(dnn_list, data_path(\"trainability_dnn_1D_epochs_100\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dnn_list = []\n",
    "for i in range(10):\n",
    "    dnn = sequential_dnn(dim = [1, 5, 1],\n",
    "                         optimizer = Adam(lr=0.1))\n",
    "    \n",
    "    dnn.train(x_dnn, y, epochs=10000)\n",
    "    dnn_list.append(dnn)\n",
    "\n",
    "saver(dnn_list, data_path(\"trainability_dnn_1D_epochs_10000\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n = 12\n",
    "x = np.linspace(0, 1, n)\n",
    "x = generate_meshgrid([x,x])\n",
    "\n",
    "mean1 = np.array([[0.2, 0.8]])\n",
    "var1 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "mean2 = np.array([[0.5, 0.8]])\n",
    "var2 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "mean3 = np.array([[0.8, 0.8]])\n",
    "var3 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "mean4 = np.array([[0.2, 0.5]])\n",
    "var4 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "mean5 = np.array([[0.5, 0.5]])\n",
    "var5 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "mean6 = np.array([[0.8, 0.5]])\n",
    "var6 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "mean7 = np.array([[0.2, 0.2]])\n",
    "var7 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "mean8 = np.array([[0.5, 0.2]])\n",
    "var8 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "mean9 = np.array([[0.8, 0.2]])\n",
    "var9 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "\n",
    "y = gaussian(x, mean1, var1) - gaussian(x, mean2, var2) + gaussian(x, mean3, var3) - gaussian(x, mean4, var4) +\\\n",
    "gaussian(x, mean5, var5) - gaussian(x, mean6, var6) + gaussian(x, mean7, var7) - gaussian(x, mean8, var8) +\\\n",
    "gaussian(x, mean9, var9)\n",
    "\n",
    "\n",
    "x_qcn = scaler(x, a=-np.pi/2, b=np.pi/2)\n",
    "x_dnn = scaler(x, mode=\"standard\")\n",
    "y = scaler(y, a=0, b=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(y.reshape(n,n))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qcn_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = [4, 4, 4],\n",
    "                         dim = [2, 4, 4, 1],\n",
    "                         encoder= Encoder(),\n",
    "                         ansatz = Ansatz(blocks = [\"entangle\", \"ry\"], reps=1),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         backend = backend_santiago,\n",
    "                         shots=1024)\n",
    "    qcn_list.append([qcn, x_qcn, y, False])\n",
    "    \n",
    "qcn_list[0][3] = True    \n",
    "    \n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list)\n",
    "\n",
    "saver(qcn_list, data_path(\"trainability_qcn_2D_reps_1_noisy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qcn_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = [4, 4, 4],\n",
    "                         dim = [2, 4, 4, 1],\n",
    "                         encoder= Encoder(),\n",
    "                         ansatz = Ansatz(blocks = [\"entangle\", \"ry\"], reps=2),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         backend = backend_santiago,\n",
    "                         shots=1024)\n",
    "   \n",
    "    qcn_list.append([qcn, x_qcn, y, False])\n",
    "\n",
    "qcn_list[0][3] = True    \n",
    "    \n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list)   \n",
    "    \n",
    "saver(qcn_list, data_path(\"trainability_qcn_2D_reps_2_noisy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcn_list = loader(data_path(\"trainability_qcn_2D_reps_2_noisy\"))\n",
    "qcn_list = [[qcn, x_qcn, y, False] for qcn in qcn_list]\n",
    "qcn_list[0][3] = True  \n",
    "\n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list)   \n",
    "    \n",
    "saver(qcn_list, data_path(\"trainability_qcn_2D_reps_2_noisy_2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.014248881094018808\n",
      "epoch: 1, loss: 0.014563353734831752\n",
      "epoch: 2, loss: 0.014233192160906606\n",
      "epoch: 3, loss: 0.013763548402494415\n",
      "epoch: 4, loss: 0.01320665931879265\n",
      "epoch: 5, loss: 0.013293760031773327\n",
      "epoch: 6, loss: 0.014063057064171717\n",
      "epoch: 7, loss: 0.013741476972163543\n",
      "epoch: 8, loss: 0.013065030750523367\n",
      "epoch: 9, loss: 0.01252382458331512\n",
      "epoch: 10, loss: 0.01258895114929391\n",
      "epoch: 11, loss: 0.01222069549992553\n",
      "epoch: 12, loss: 0.011623621251773988\n",
      "epoch: 13, loss: 0.01163061594087947\n"
     ]
    }
   ],
   "source": [
    "qcn_list = loader(data_path(\"trainability_qcn_2D_reps_2_noisy_2\"))\n",
    "qcn_list = [[qcn, x_qcn, y, False] for qcn in qcn_list]\n",
    "qcn_list[0][3] = True  \n",
    "\n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list)   \n",
    "    \n",
    "saver(qcn_list, data_path(\"trainability_qcn_2D_reps_2_noisy_3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcn_list = loader(data_path(\"trainability_qcn_2D_reps_2_noisy_3\"))\n",
    "qcn_list = [[qcn, x_qcn, y, False] for qcn in qcn_list]\n",
    "qcn_list[0][3] = True  \n",
    "\n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list)   \n",
    "    \n",
    "saver(qcn_list, data_path(\"trainability_qcn_2D_reps_2_noisy_4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dnn_list = []\n",
    "for i in range(10):\n",
    "    dnn = sequential_dnn(dim = [2, 5, 5, 1],\n",
    "                         optimizer = Adam(lr=0.1))\n",
    "    \n",
    "    dnn.train(x_dnn, y, epochs=100)\n",
    "    dnn_list.append(dnn)\n",
    "\n",
    "saver(dnn_list, data_path(\"trainability_dnn_2D_epochs_100\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dnn_list = []\n",
    "for i in range(10):\n",
    "    dnn = sequential_dnn(dim = [2, 5, 5, 1],\n",
    "                         optimizer = Adam(lr=0.1))\n",
    "    \n",
    "    dnn.train(x_dnn, y, epochs=10000)\n",
    "    dnn_list.append(dnn)\n",
    "\n",
    "saver(dnn_list, data_path(\"trainability_dnn_2D_epochs_10000\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n = 6\n",
    "x = np.linspace(0, 1, n)\n",
    "x = generate_meshgrid([x, x, x])\n",
    "\n",
    "mean1 = np.array([[0.25, 0.25, 0.25]])\n",
    "mean2 = np.array([[0.25, 0.25, 0.75]])\n",
    "mean3 = np.array([[0.25, 0.75, 0.75]])\n",
    "mean4 = np.array([[0.25, 0.75, 0.25]])\n",
    "\n",
    "mean5 = np.array([[0.75, 0.25, 0.25]])\n",
    "mean6 = np.array([[0.75, 0.25, 0.75]])\n",
    "mean7 = np.array([[0.75, 0.75, 0.75]])\n",
    "mean8 = np.array([[0.75, 0.75, 0.25]])\n",
    "\n",
    "var = np.array([[0.02, 0, 0], [0, 0.02, 0], [0, 0, 0.02]])\n",
    "\n",
    "y = gaussian(x, mean1, var) - gaussian(x, mean2, var) + gaussian(x, mean3, var) - gaussian(x, mean4, var) - gaussian(x, mean5, var) + gaussian(x, mean6, var) - gaussian(x, mean7, var) + gaussian(x, mean8, var)\n",
    "\n",
    "x_qcn = scaler(x, a=-np.pi/2, b=np.pi/2)\n",
    "x_dnn = scaler(x, mode=\"standard\")\n",
    "y = scaler(y, a=0, b=1)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y.reshape(n,n,n)[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qcn_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = [5, 5, 5],\n",
    "                         dim = [3, 5, 5, 1],\n",
    "                         encoder= Encoder(),\n",
    "                         ansatz = Ansatz(blocks = [\"entangle\", \"ry\"], reps = 1),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         backend = backend,\n",
    "                         shots = 0)\n",
    "\n",
    "    qcn_list.append([qcn, x_qcn, y, False])\n",
    "\n",
    "qcn_list[0][3] = True    \n",
    "    \n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list) \n",
    "    \n",
    "saver(qcn_list, data_path(\"trainability_qcn_3D_reps_1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qcn_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = [5, 5, 5],\n",
    "                         dim = [3, 5, 5, 1],\n",
    "                         encoder= Encoder(),\n",
    "                         ansatz = Ansatz(blocks = [\"entangle\", \"ry\"], reps = 2),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         backend = backend,\n",
    "                         shots = 0)\n",
    "\n",
    "    qcn_list.append([qcn, x_qcn, y, False])\n",
    "\n",
    "qcn_list[0][3] = True    \n",
    "    \n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list) \n",
    "    \n",
    "saver(qcn_list, data_path(\"trainability_qcn_3D_reps_2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dnn_list = []\n",
    "for i in range(10):\n",
    "    dnn = sequential_dnn(dim = [3, 8, 8, 1],\n",
    "                         optimizer = Adam(lr=0.1))\n",
    "    \n",
    "    dnn.train(x_dnn, y, epochs=100)\n",
    "    dnn_list.append(dnn)\n",
    "\n",
    "saver(dnn_list, data_path(\"trainability_dnn_3D_epochs_100\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dnn_list = []\n",
    "for i in range(10):\n",
    "    dnn = sequential_dnn(dim = [3, 8, 8, 1],\n",
    "                         optimizer = Adam(lr=0.1))\n",
    "    \n",
    "    dnn.train(x_dnn, y, epochs=10000)\n",
    "    dnn_list.append(dnn)\n",
    "\n",
    "saver(dnn_list, data_path(\"trainability_dnn_3D_epochs_10000\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_qiskit",
   "language": "python",
   "name": "env_qiskit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
