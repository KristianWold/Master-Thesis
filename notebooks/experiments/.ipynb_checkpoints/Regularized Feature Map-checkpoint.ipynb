{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import qiskit as qk\n",
    "import matplotlib.pyplot as plt\n",
    "from qiskit import Aer\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../src/')\n",
    "from neuralnetwork import *\n",
    "from analysis import *\n",
    "from utils import *\n",
    "\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = Aer.get_backend('qasm_simulator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized Feature Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n = 200\n",
    "n_features = 4\n",
    "epochs = 100\n",
    "x = np.random.uniform(0, np.pi, (n, n_features))\n",
    "\n",
    "std = 0.2\n",
    "y = np.sin(2*x[:,2])\n",
    "y = scaler(y, a=0.1, b=0.9).reshape(-1, 1)\n",
    "\n",
    "x_train, y_train = x[:100,:], y[:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_train[:,2], y_train,\"o\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "model_list = []\n",
    "for i in tqdm(range(1)):\n",
    "    optimizer = Adam(lr=0.1)\n",
    "    model = RegularizedModel(n_features=n_features, \n",
    "                             n_targets=1, \n",
    "                             reps=2,\n",
    "                             alpha=0.00,\n",
    "                             backend=backend, \n",
    "                             shots=10000, \n",
    "                             optimizer=optimizer)\n",
    "    \n",
    "    model.train(x_train, y_train, epochs=epochs, verbose=True) \n",
    "    model_list.append(model)\n",
    "    print(model.loss[-1])\n",
    "\n",
    "saver(model_list, data_path(\"sparse_regularisation_model_no_penalty\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low Penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "model_list = []\n",
    "for i in tqdm(range(10)):\n",
    "    optimizer = Adam(lr=0.1)\n",
    "    model = RegularizedModel(n_features=n_features, \n",
    "                             n_targets=1, \n",
    "                             reps=2,\n",
    "                             alpha=0.001,\n",
    "                             backend=backend, \n",
    "                             shots=10000, \n",
    "                             optimizer=optimizer)\n",
    "    \n",
    "    model.train(x_train, y_train, epochs=epochs, verbose=True) \n",
    "    model_list.append(model)\n",
    "    print(model.loss[-1])\n",
    "\n",
    "saver(model_list, data_path(\"sparse_regularisation_model_low_penalty\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "model_list = []\n",
    "for i in tqdm(range(10)):\n",
    "    optimizer = Adam(lr=0.1)\n",
    "    model = RegularizedModel(n_features=n_features, \n",
    "                             n_targets=1, \n",
    "                             reps=2,\n",
    "                             alpha=0.01,\n",
    "                             backend=backend, \n",
    "                             shots=10000, \n",
    "                             optimizer=optimizer)\n",
    "    \n",
    "    model.train(x_train, y_train, epochs=epochs) \n",
    "    model_list.append(model)\n",
    "    print(model.loss[-1])\n",
    "\n",
    "saver(model_list, data_path(\"sparse_regularisation_model_high_penalty\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No-Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad3e93d82254aa0957b0989bbecf60e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdaf1e3f1a5445c9a27a8b18a9f85f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.09559016166388344\n",
      "epoch: 1, loss: 0.07763653804795972\n",
      "epoch: 2, loss: 0.06629940140997256\n",
      "epoch: 3, loss: 0.06203183274140439\n",
      "epoch: 4, loss: 0.05990754040036295\n",
      "epoch: 5, loss: 0.05719841942748674\n",
      "epoch: 6, loss: 0.05407732645957505\n",
      "epoch: 7, loss: 0.05062937609841777\n",
      "epoch: 8, loss: 0.048127324652284205\n",
      "epoch: 9, loss: 0.046095605139456985\n",
      "epoch: 10, loss: 0.0445095401012463\n",
      "epoch: 11, loss: 0.042749125092228724\n",
      "epoch: 12, loss: 0.04112803683534045\n",
      "epoch: 13, loss: 0.03852382583364874\n",
      "epoch: 14, loss: 0.03667331181233971\n",
      "epoch: 15, loss: 0.03580967507223566\n",
      "epoch: 16, loss: 0.03525546279810853\n",
      "epoch: 17, loss: 0.034896913366402\n",
      "epoch: 18, loss: 0.034577043636941106\n",
      "epoch: 19, loss: 0.034754696712709955\n",
      "epoch: 20, loss: 0.03469440292913434\n",
      "epoch: 21, loss: 0.03428808717270867\n",
      "epoch: 22, loss: 0.03338297982681935\n",
      "epoch: 23, loss: 0.032508781918724756\n",
      "epoch: 24, loss: 0.03171774864643913\n",
      "epoch: 25, loss: 0.031123518023918374\n",
      "epoch: 26, loss: 0.030497675689803688\n",
      "epoch: 27, loss: 0.029924409767834507\n",
      "epoch: 28, loss: 0.02892505034680657\n",
      "epoch: 29, loss: 0.028754514589277705\n",
      "epoch: 30, loss: 0.027810233637303266\n",
      "epoch: 31, loss: 0.02715397479620117\n",
      "epoch: 32, loss: 0.026576546729326352\n",
      "epoch: 33, loss: 0.025488800646499152\n",
      "epoch: 34, loss: 0.024595733047276733\n",
      "epoch: 35, loss: 0.02339129427643341\n",
      "epoch: 36, loss: 0.02280297469512338\n",
      "epoch: 37, loss: 0.02228435986523766\n",
      "epoch: 38, loss: 0.02184168072484341\n",
      "epoch: 39, loss: 0.0216941840545636\n",
      "epoch: 40, loss: 0.021353733803649112\n",
      "epoch: 41, loss: 0.021160419209913562\n",
      "epoch: 42, loss: 0.020897091392849863\n",
      "epoch: 43, loss: 0.020311635366359968\n",
      "epoch: 44, loss: 0.020033595879354903\n",
      "epoch: 45, loss: 0.019816898762272654\n",
      "epoch: 46, loss: 0.01904258212722862\n",
      "epoch: 47, loss: 0.019087401681697865\n",
      "epoch: 48, loss: 0.018925637769211794\n",
      "epoch: 49, loss: 0.018925246811315525\n",
      "epoch: 50, loss: 0.018953388095083002\n",
      "epoch: 51, loss: 0.018599109685453263\n",
      "epoch: 52, loss: 0.018669898481030286\n",
      "epoch: 53, loss: 0.01887437870821302\n",
      "epoch: 54, loss: 0.018771787565643083\n",
      "epoch: 55, loss: 0.01901990496823512\n",
      "epoch: 56, loss: 0.01859805955188637\n",
      "epoch: 57, loss: 0.018708607261792097\n",
      "epoch: 58, loss: 0.018776934286986794\n",
      "epoch: 59, loss: 0.01889397223691539\n",
      "epoch: 60, loss: 0.018600646005309803\n",
      "epoch: 61, loss: 0.01882033552857558\n",
      "epoch: 62, loss: 0.01857636191464297\n",
      "epoch: 63, loss: 0.018692909098271402\n",
      "epoch: 64, loss: 0.018395080327110815\n",
      "epoch: 65, loss: 0.018532621415564013\n",
      "epoch: 66, loss: 0.0183286141352655\n",
      "epoch: 67, loss: 0.018548922957004454\n",
      "epoch: 68, loss: 0.01836714760960866\n",
      "epoch: 69, loss: 0.018399497488864273\n",
      "epoch: 70, loss: 0.018427011522356512\n",
      "epoch: 71, loss: 0.018452798329973524\n",
      "epoch: 72, loss: 0.01835617334049949\n",
      "epoch: 73, loss: 0.018406624423233105\n",
      "epoch: 74, loss: 0.018434850504281248\n",
      "epoch: 75, loss: 0.01853546695618873\n",
      "epoch: 76, loss: 0.018151620735412297\n",
      "epoch: 77, loss: 0.018588080973299274\n",
      "epoch: 78, loss: 0.018114515767304672\n",
      "epoch: 79, loss: 0.018573955192677735\n",
      "epoch: 80, loss: 0.018378423955061677\n",
      "epoch: 81, loss: 0.0183264320785306\n",
      "epoch: 82, loss: 0.018284529084983753\n",
      "epoch: 83, loss: 0.018243518520526\n",
      "epoch: 84, loss: 0.018241453810646808\n",
      "epoch: 85, loss: 0.018183845072971782\n",
      "epoch: 86, loss: 0.01817256528953233\n",
      "epoch: 87, loss: 0.018332558887008715\n",
      "epoch: 88, loss: 0.018368132492322484\n",
      "epoch: 89, loss: 0.018505598520540224\n",
      "epoch: 90, loss: 0.018222487649998467\n",
      "epoch: 91, loss: 0.018278173038264768\n",
      "epoch: 92, loss: 0.01832435364577337\n",
      "epoch: 93, loss: 0.018196872355359998\n",
      "epoch: 94, loss: 0.018469872659750145\n",
      "epoch: 95, loss: 0.018182152928315133\n",
      "epoch: 96, loss: 0.01842627662426255\n",
      "epoch: 97, loss: 0.018373519369342926\n",
      "epoch: 98, loss: 0.018132178830666618\n",
      "epoch: 99, loss: 0.018348682878884467\n",
      "0.01849067201651418\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "model_list = []\n",
    "for i in tqdm(range(1)):\n",
    "    optimizer = Adam(lr=0.1)\n",
    "    model = RegularizedModel(n_features=n_features, \n",
    "                             n_targets=1, \n",
    "                             reps=3,\n",
    "                             alpha=0,\n",
    "                             train_map=False,\n",
    "                             backend=backend, \n",
    "                             shots=10000, \n",
    "                             optimizer=optimizer)\n",
    "    \n",
    "    model.train(x_train, y_train, epochs=epochs, verbose=True) \n",
    "    model_list.append(model)\n",
    "    print(model.loss[-1])\n",
    "\n",
    "saver(model_list, data_path(\"sparse_no_train_model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3629ba9b167243f3ba8632db78b4d392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b8683686f7e480a9398084c4caf5c3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.07328912082325022\n",
      "epoch: 1, loss: 0.05286396906682561\n",
      "epoch: 2, loss: 0.03411853532170011\n",
      "epoch: 3, loss: 0.02280312044248059\n",
      "epoch: 4, loss: 0.017530109288133054\n",
      "epoch: 5, loss: 0.015368532687874713\n",
      "epoch: 6, loss: 0.015404735474853735\n",
      "epoch: 7, loss: 0.016538601820326862\n",
      "epoch: 8, loss: 0.016922415853440915\n",
      "epoch: 9, loss: 0.0163536833966227\n",
      "epoch: 10, loss: 0.014544288212475246\n",
      "epoch: 11, loss: 0.013030017421520967\n",
      "epoch: 12, loss: 0.011730829593906745\n",
      "epoch: 13, loss: 0.011196526561296742\n",
      "epoch: 14, loss: 0.010938221404598296\n",
      "epoch: 15, loss: 0.010495193927367086\n",
      "epoch: 16, loss: 0.01011845079242857\n",
      "epoch: 17, loss: 0.009867746021174273\n",
      "epoch: 18, loss: 0.00935788424658885\n",
      "epoch: 19, loss: 0.00896251510219976\n",
      "epoch: 20, loss: 0.008746769033286665\n",
      "epoch: 21, loss: 0.008289528519211437\n",
      "epoch: 22, loss: 0.007728695223402655\n",
      "epoch: 23, loss: 0.007089212633676623\n",
      "epoch: 24, loss: 0.006670371564314399\n",
      "epoch: 25, loss: 0.005992601817855877\n",
      "epoch: 26, loss: 0.005481413071249277\n",
      "epoch: 27, loss: 0.005357270399127383\n",
      "epoch: 28, loss: 0.004958400065802826\n",
      "epoch: 29, loss: 0.0049713235308395266\n",
      "epoch: 30, loss: 0.004779967290571524\n",
      "epoch: 31, loss: 0.004804923241288117\n",
      "epoch: 32, loss: 0.004740563288421098\n",
      "epoch: 33, loss: 0.004709152145497361\n",
      "epoch: 34, loss: 0.004678772750754294\n",
      "epoch: 35, loss: 0.004417456687331037\n",
      "epoch: 36, loss: 0.004367022306829498\n",
      "epoch: 37, loss: 0.004364553059091743\n",
      "epoch: 38, loss: 0.0042564906988754245\n",
      "epoch: 39, loss: 0.004119289352115904\n",
      "epoch: 40, loss: 0.0040512097058864995\n",
      "epoch: 41, loss: 0.0039053795932365142\n",
      "epoch: 42, loss: 0.003911205559109514\n",
      "epoch: 43, loss: 0.003957307125294679\n",
      "epoch: 44, loss: 0.003820172785502478\n",
      "epoch: 45, loss: 0.0038278142220767924\n",
      "epoch: 46, loss: 0.0038205784335223186\n",
      "epoch: 47, loss: 0.00391323571993966\n",
      "epoch: 48, loss: 0.003723210847674967\n",
      "epoch: 49, loss: 0.0037896821362927153\n",
      "epoch: 50, loss: 0.003942021223912723\n",
      "epoch: 51, loss: 0.0039034157746728965\n",
      "epoch: 52, loss: 0.003843147289423709\n",
      "epoch: 53, loss: 0.0038698455458323956\n",
      "epoch: 54, loss: 0.0037927292965600754\n",
      "epoch: 55, loss: 0.00369259788221379\n",
      "epoch: 56, loss: 0.0037480741567401093\n",
      "epoch: 57, loss: 0.0037733051653917136\n",
      "epoch: 58, loss: 0.003870434682107232\n",
      "epoch: 59, loss: 0.0037431794790008144\n",
      "epoch: 60, loss: 0.0038459125111793423\n",
      "epoch: 61, loss: 0.0038415873248959483\n",
      "epoch: 62, loss: 0.0037410184892569293\n",
      "epoch: 63, loss: 0.0037617016180123935\n",
      "epoch: 64, loss: 0.00381087034116087\n",
      "epoch: 65, loss: 0.003674634940930869\n",
      "epoch: 66, loss: 0.0037802728705826068\n",
      "epoch: 67, loss: 0.0037326697022454377\n",
      "epoch: 68, loss: 0.0038074016241314945\n",
      "epoch: 69, loss: 0.003801207744195167\n",
      "epoch: 70, loss: 0.003743516586916184\n",
      "epoch: 71, loss: 0.0038055084053055526\n",
      "epoch: 72, loss: 0.003715662125319838\n",
      "epoch: 73, loss: 0.0037376760194503507\n",
      "epoch: 74, loss: 0.0038181263513766602\n",
      "epoch: 75, loss: 0.0038062532774185776\n",
      "epoch: 76, loss: 0.0037776995710919687\n",
      "epoch: 77, loss: 0.0037149166784673105\n",
      "epoch: 78, loss: 0.00378556965419319\n",
      "epoch: 79, loss: 0.0037460384956586566\n",
      "epoch: 80, loss: 0.0037879931938624685\n",
      "epoch: 81, loss: 0.003693101162318247\n",
      "epoch: 82, loss: 0.0037623655809150146\n",
      "epoch: 83, loss: 0.0037560686840535664\n",
      "epoch: 84, loss: 0.0037482300896612393\n",
      "epoch: 85, loss: 0.003762645521179511\n",
      "epoch: 86, loss: 0.003715786512522933\n",
      "epoch: 87, loss: 0.003733734568198794\n",
      "epoch: 88, loss: 0.0037356747495454184\n",
      "epoch: 89, loss: 0.003726783067811129\n",
      "epoch: 90, loss: 0.003668373622690812\n",
      "epoch: 91, loss: 0.0037562082454267853\n",
      "epoch: 92, loss: 0.0037304936868107668\n",
      "epoch: 93, loss: 0.0036543785115001324\n",
      "epoch: 94, loss: 0.0035840834799090882\n",
      "epoch: 95, loss: 0.0036690150788789553\n",
      "epoch: 96, loss: 0.0037131896062523395\n",
      "epoch: 97, loss: 0.00357023209563773\n",
      "epoch: 98, loss: 0.003658274765485572\n",
      "epoch: 99, loss: 0.0037887530795541304\n",
      "0.0036846426414865875\n"
     ]
    }
   ],
   "source": [
    "x_train[:,0] = np.pi/2\n",
    "x_train[:,1] = np.pi/2\n",
    "x_train[:,3] = np.pi/2\n",
    "\n",
    "np.random.seed(42)\n",
    "model_list = []\n",
    "for i in tqdm(range(1)):\n",
    "    optimizer = Adam(lr=0.1)\n",
    "    model = RegularizedModel(n_features=n_features, \n",
    "                             n_targets=1, \n",
    "                             reps=3,\n",
    "                             alpha=0,\n",
    "                             train_map=False,\n",
    "                             backend=backend, \n",
    "                             shots=10000, \n",
    "                             optimizer=optimizer)\n",
    "    \n",
    "    model.train(x_train, y_train, epochs=epochs, verbose=True) \n",
    "    model_list.append(model)\n",
    "    print(model.loss[-1])\n",
    "\n",
    "saver(model_list, data_path(\"sparse_no_train_model_dense\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Single Circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "model_list = []\n",
    "for i in tqdm(range(1)):\n",
    "    model = sequential_qnn(q_bits = [n_features+1],\n",
    "                     dim = [n_features, 1],\n",
    "                     reps = 3,\n",
    "                     backend=backend,\n",
    "                     shots=10000,\n",
    "                     lr = 0.1)\n",
    "    \n",
    "    model.train(x_train, y_train, epochs=epochs, verbose=True) \n",
    "    model_list.append(model)\n",
    "    print(model.loss[-1])\n",
    "\n",
    "saver(model_list, data_path(\"sparse_standard_model\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_qiskit",
   "language": "python",
   "name": "env_qiskit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
