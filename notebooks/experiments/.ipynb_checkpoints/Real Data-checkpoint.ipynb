{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qiskit as qk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from qiskit import Aer\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import multiprocessing as mp\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../src/')\n",
    "from neuralnetwork import *\n",
    "from analysis import *\n",
    "\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel(args):\n",
    "    model = args[0]\n",
    "    x = args[1]\n",
    "    y = args[2]\n",
    "    x_test = args[3]\n",
    "    y_test = args[4]\n",
    "    verbose = args[5]\n",
    "    \n",
    "    model.train(x, y, x_test=x_test, y_test=y_test, verbose = verbose)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston Housing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston()\n",
    "x = data.data\n",
    "x_scaled = scaler(x, mode=\"standard\")\n",
    "\n",
    "y = data.target.reshape(-1, 1)\n",
    "y = scaler(y, a=0, b=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=4)\n",
    "x_pca = pca.fit_transform(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_qcn = scaler(x_pca, a=-np.pi/2, b=np.pi/2)\n",
    "x_dnn = scaler(x_pca, mode=\"standard\")\n",
    "\n",
    "np.random.seed(42)\n",
    "x_train_qcn, x_test_qcn, y_train, y_test = train_test_split(x_qcn, y, train_size=100, test_size=100)\n",
    "np.random.seed(42)\n",
    "x_train_dnn, x_test_dnn, y_train, y_test = train_test_split(x_dnn, y, train_size=100, test_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.05459361007549361\n",
      "epoch: 1, loss: 0.039335914733830545\n",
      "epoch: 2, loss: 0.02827439761174896\n",
      "epoch: 3, loss: 0.02110358036045847\n",
      "epoch: 4, loss: 0.01599291098440256\n",
      "epoch: 5, loss: 0.012885989550563819\n",
      "epoch: 6, loss: 0.013694923824741922\n",
      "epoch: 7, loss: 0.014755665839254122\n",
      "epoch: 8, loss: 0.01553644987777486\n",
      "epoch: 9, loss: 0.014987640208505203\n",
      "epoch: 10, loss: 0.013419986749718076\n",
      "epoch: 11, loss: 0.012490436023202132\n",
      "epoch: 12, loss: 0.011161159842172133\n",
      "epoch: 13, loss: 0.010953398283427188\n",
      "epoch: 14, loss: 0.01022892375475193\n",
      "epoch: 15, loss: 0.009799310334163779\n",
      "epoch: 16, loss: 0.009246051943732235\n",
      "epoch: 17, loss: 0.008934495908036862\n",
      "epoch: 18, loss: 0.008695795192192565\n",
      "epoch: 19, loss: 0.008386915054890535\n",
      "epoch: 20, loss: 0.00841073655441808\n",
      "epoch: 21, loss: 0.008156475893793981\n",
      "epoch: 22, loss: 0.00796722015067266\n",
      "epoch: 23, loss: 0.007839685156963374\n",
      "epoch: 24, loss: 0.007624476669653456\n",
      "epoch: 25, loss: 0.007521466590878549\n",
      "epoch: 26, loss: 0.007330886712168237\n",
      "epoch: 27, loss: 0.007201192752139131\n",
      "epoch: 28, loss: 0.0070002433857863765\n",
      "epoch: 29, loss: 0.0067303286010045186\n",
      "epoch: 30, loss: 0.006570921461005914\n",
      "epoch: 31, loss: 0.006405701417286264\n",
      "epoch: 32, loss: 0.00635944377569301\n",
      "epoch: 33, loss: 0.006281855915654586\n",
      "epoch: 34, loss: 0.006200083818227266\n",
      "epoch: 35, loss: 0.0061763564831581975\n",
      "epoch: 36, loss: 0.0060209587228452375\n",
      "epoch: 37, loss: 0.005949172411252995\n",
      "epoch: 38, loss: 0.005910524404447625\n",
      "epoch: 39, loss: 0.0058249906306384715\n",
      "epoch: 40, loss: 0.0058377281248576255\n",
      "epoch: 41, loss: 0.005838149769780825\n",
      "epoch: 42, loss: 0.005784419068237139\n",
      "epoch: 43, loss: 0.005763138907039089\n",
      "epoch: 44, loss: 0.005699645609713708\n",
      "epoch: 45, loss: 0.0056173903016704715\n",
      "epoch: 46, loss: 0.005580258214592918\n",
      "epoch: 47, loss: 0.005525136238499202\n",
      "epoch: 48, loss: 0.005472500781681036\n",
      "epoch: 49, loss: 0.005460171389149298\n",
      "epoch: 50, loss: 0.00542887278029504\n",
      "epoch: 51, loss: 0.005397394279282161\n",
      "epoch: 52, loss: 0.0053884452869485235\n",
      "epoch: 53, loss: 0.0053652968312709985\n",
      "epoch: 54, loss: 0.005351134215868545\n",
      "epoch: 55, loss: 0.005348424623491635\n",
      "epoch: 56, loss: 0.005323459530522687\n",
      "epoch: 57, loss: 0.005292869370807084\n",
      "epoch: 58, loss: 0.005263462859664565\n",
      "epoch: 59, loss: 0.005234881636375692\n",
      "epoch: 60, loss: 0.005212548092873661\n",
      "epoch: 61, loss: 0.005193743676409512\n",
      "epoch: 62, loss: 0.005184358544508946\n",
      "epoch: 63, loss: 0.005172969863999248\n",
      "epoch: 64, loss: 0.0051530090601805125\n",
      "epoch: 65, loss: 0.005133354782843976\n",
      "epoch: 66, loss: 0.005113026028789871\n",
      "epoch: 67, loss: 0.005096153732162284\n",
      "epoch: 68, loss: 0.005078834281977961\n",
      "epoch: 69, loss: 0.005058872644999918\n",
      "epoch: 70, loss: 0.005041337600697038\n",
      "epoch: 71, loss: 0.005025508375872425\n",
      "epoch: 72, loss: 0.005014997647367108\n",
      "epoch: 73, loss: 0.00500407966723894\n",
      "epoch: 74, loss: 0.0049920470333381884\n",
      "epoch: 75, loss: 0.004978840363003674\n",
      "epoch: 76, loss: 0.004965344761495474\n",
      "epoch: 77, loss: 0.0049535513510880645\n",
      "epoch: 78, loss: 0.004941778754144559\n",
      "epoch: 79, loss: 0.004930475052944441\n",
      "epoch: 80, loss: 0.0049173502082500336\n",
      "epoch: 81, loss: 0.004904738887265498\n",
      "epoch: 82, loss: 0.004891978227423541\n",
      "epoch: 83, loss: 0.004879985688908029\n",
      "epoch: 84, loss: 0.004867931495495349\n",
      "epoch: 85, loss: 0.004856549778285185\n",
      "epoch: 86, loss: 0.0048466396914948065\n",
      "epoch: 87, loss: 0.004842314944363132\n",
      "epoch: 88, loss: 0.004853555842194605\n",
      "epoch: 89, loss: 0.004909309236098618\n",
      "epoch: 90, loss: 0.0050767916958768975\n",
      "epoch: 91, loss: 0.005400141269177413\n",
      "epoch: 92, loss: 0.005570392508342365\n",
      "epoch: 93, loss: 0.005098213675540684\n",
      "epoch: 94, loss: 0.004750411306348415\n",
      "epoch: 95, loss: 0.005098875001498836\n",
      "epoch: 96, loss: 0.005126669658872037\n",
      "epoch: 97, loss: 0.0047532809671649206\n",
      "epoch: 98, loss: 0.0048793404352979845\n",
      "epoch: 99, loss: 0.0049860512473042205\n",
      "epoch: 100, loss: 0.004700823386920686\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "qcn_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = [4, 4],\n",
    "                         dim = [4, 4, 1],\n",
    "                         encoder= Encoder(),\n",
    "                         ansatz = Ansatz(blocks = [\"entangle\", \"ry\"], reps=2),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         shots=0)\n",
    "    \n",
    "    qcn_list.append([qcn, x_train_qcn, y_train, x_test_qcn, y_test, False])\n",
    "\n",
    "qcn_list[0][5] = True    \n",
    "    \n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list)     \n",
    "    \n",
    "saver(qcn_list, data_path(\"boston_qcn\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e57fc8b11a144070a377e577168c4943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "dnn_list = []\n",
    "for i in tqdm(range(10)):\n",
    "    dnn = sequential_dnn(dim = [4, 6, 1])\n",
    "    dnn.train(x_train_dnn, y_train, x_test=x_test_dnn, y_test=y_test, epochs = 100)\n",
    "    dnn_list.append(dnn)\n",
    "    \n",
    "saver(dnn_list, data_path(\"boston_dnn_pca\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston()\n",
    "x = data.data\n",
    "x_scaled = scaler(x, mode=\"standard\")\n",
    "\n",
    "y = data.target.reshape(-1, 1)\n",
    "y = scaler(y, a=0, b=1)\n",
    "\n",
    "np.random.seed(42)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, train_size=100, test_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0ada9f17c2b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mhybrid_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhybrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mhybrid_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "hybrid_list = []\n",
    "for i in range(10):\n",
    "    layer1 = Dense(n_features = 13, \n",
    "                   n_targets = 4,\n",
    "                   activation = Tanh(),\n",
    "                   scale=np.pi)\n",
    "\n",
    "    layer2 = QLayer(n_qubits = 4,\n",
    "                    n_features = 4, \n",
    "                    n_targets = 4, \n",
    "                    encoder = Encoder(), \n",
    "                    ansatz = Ansatz(blocks = [\"entangle\", \"ry\"], reps=2),\n",
    "                    sampler=Parity(),\n",
    "                    shots=0)\n",
    "\n",
    "    layer3 = QLayer(n_qubits = 4,\n",
    "                    n_features = 4, \n",
    "                    n_targets = 1, \n",
    "                    encoder = Encoder(), \n",
    "                    ansatz = Ansatz(blocks = [\"entangle\", \"ry\"], reps=2),\n",
    "                    sampler=Parity(),\n",
    "                    shots=0)\n",
    "\n",
    "    layers = [layer1, layer2, layer3]\n",
    "    hybrid = NeuralNetwork(layers)\n",
    "    \n",
    "    hybrid_list.append([hybrid, x_train, y_train, x_test, y_test, False])\n",
    "\n",
    "hybrid_list[0][5] = True    \n",
    "    \n",
    "with mp.Pool(10) as p:\n",
    "    hybrid_list = p.map(parallel, hybrid_list)     \n",
    "    \n",
    "saver(hybrid_list, data_path(\"boston_hybrid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "dnn_list = []\n",
    "for i in tqdm(range(10)):\n",
    "    dnn = sequential_dnn(dim = [13, 5, 5, 1])\n",
    "    dnn.train(x_train, y_train, x_test=x_test, y_test=y_test, epochs = 100)\n",
    "    dnn_list.append(dnn)\n",
    "    \n",
    "saver(dnn_list, data_path(\"boston_dnn_full\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_qiskit",
   "language": "python",
   "name": "env_qiskit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
