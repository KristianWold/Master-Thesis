{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qiskit as qk\n",
    "import matplotlib.pyplot as plt\n",
    "from qiskit import Aer\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm.notebook import tqdm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import multiprocessing as mp\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../src/')\n",
    "from neuralnetwork import *\n",
    "from analysis import *\n",
    "from utils import *\n",
    "\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_fit(args):\n",
    "    tl = args[0]\n",
    "    x = args[1]\n",
    "    \n",
    "    tl.fit(x)\n",
    "    \n",
    "    return tl\n",
    "\n",
    "def parallel_train(args):\n",
    "    model = args[0]\n",
    "    x = args[1]\n",
    "    y = args[2]\n",
    "    verbose = args[3]\n",
    "    \n",
    "    model.train(x, y, verbose = verbose)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expressivity of QCN vs DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajectory Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.linspace(0, 2*np.pi, 1000)\n",
    "theta = np.append(theta, theta[0:1]).reshape(-1,1)\n",
    "\n",
    "x1 = np.pi*np.cos(theta)/2\n",
    "x2 = np.pi*np.sin(theta)/2\n",
    "x_qcn = np.hstack([x1, x2])\n",
    "x_dnn = scaler(x_qcn, mode=\"standard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_qcn[:,0], x_qcn[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "tl_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = 8*[4],\n",
    "                             dim = [2] + 7*[4],\n",
    "                             scale = 8*[[-np.pi, np.pi]],\n",
    "                             encoder = Encoder(),\n",
    "                             ansatz = Ansatz(blocks=[\"entangle\", \"ry\"], reps=2),\n",
    "                             sampler = Parity(),\n",
    "                             shots = 0)\n",
    "\n",
    "\n",
    "    tl = TrajectoryLength(qcn)\n",
    "    tl_list.append([tl, x_qcn])\n",
    "\n",
    "with mp.Pool(10) as p:\n",
    "    tl_list = p.map(parallel_fit, tl_list)\n",
    "    \n",
    "saver(tl_list, data_path(\"tl_expressivity_width_4_reps_2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "tl_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = 8*[5],\n",
    "                             dim = [5] + 7*[5],\n",
    "                             scale = 8*[[-np.pi, np.pi]],\n",
    "                             encoder = Encoder(),\n",
    "                             ansatz = Ansatz(blocks=[\"entangle\", \"ry\"], reps=2),\n",
    "                             sampler = Parity(),\n",
    "                             shots = 0)\n",
    "\n",
    "\n",
    "    tl = TrajectoryLength(qcn)\n",
    "    tl_list.append([tl, x_qcn])\n",
    "\n",
    "with mp.Pool(10) as p:\n",
    "    tl_list = p.map(parallel_fit, tl_list)\n",
    "    \n",
    "saver(tl_list, data_path(\"tl_expressivity_width_5_reps_2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "tl_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = 8*[6],\n",
    "                             dim = [2] + 7*[6],\n",
    "                             scale = 8*[[-np.pi, np.pi]],\n",
    "                             encoder = Encoder(),\n",
    "                             ansatz = Ansatz(blocks=[\"entangle\", \"ry\"], reps=2),\n",
    "                             sampler = Parity(),\n",
    "                             shots = 0)\n",
    "\n",
    "\n",
    "    tl = TrajectoryLength(qcn)\n",
    "    tl_list.append([tl, x_qcn])\n",
    "\n",
    "with mp.Pool(10) as p:\n",
    "    tl_list = p.map(parallel_fit, tl_list)\n",
    "    \n",
    "saver(tl_list, data_path(\"tl_expressivity_width_6_reps_2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "tl_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = 8*[7],\n",
    "                             dim = [2] + 7*[7],\n",
    "                             scale = 8*[[-np.pi, np.pi]],\n",
    "                             encoder = Encoder(),\n",
    "                             ansatz = Ansatz(blocks=[\"entangle\", \"ry\"], reps=2),\n",
    "                             sampler = Parity(),\n",
    "                             shots = 0)\n",
    "\n",
    "\n",
    "    tl = TrajectoryLength(qcn)\n",
    "    tl_list.append([tl, x_qcn])\n",
    "\n",
    "with mp.Pool(10) as p:\n",
    "    tl_list = p.map(parallel_fit, tl_list)\n",
    "    \n",
    "saver(tl_list, data_path(\"tl_expressivity_width_7_reps_2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "tl_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = 8*[8],\n",
    "                             dim = [2] + 7*[8],\n",
    "                             scale = 8*[[-np.pi, np.pi]],\n",
    "                             encoder = Encoder(),\n",
    "                             ansatz = Ansatz(blocks=[\"entangle\", \"ry\"], reps=2),\n",
    "                             sampler = Parity(),\n",
    "                             shots = 0)\n",
    "\n",
    "\n",
    "    tl = TrajectoryLength(qcn)\n",
    "    tl_list.append([tl, x_qcn])\n",
    "\n",
    "with mp.Pool(10) as p:\n",
    "    tl_list = p.map(parallel_fit, tl_list)\n",
    "    \n",
    "saver(tl_list, data_path(\"tl_expressivity_width_8_reps_2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "tl_list = []\n",
    "for i in range(10):\n",
    "    dnn = sequential_dnn(dim=[2] + 7*[10])\n",
    "\n",
    "\n",
    "    tl = TrajectoryLength(dnn)\n",
    "    tl_list.append([tl, x_qcn])\n",
    "\n",
    "with mp.Pool(10) as p:\n",
    "    tl_list = p.map(parallel_fit, tl_list)\n",
    "\n",
    "saver(tl_list, data_path(\"tl_expressivity_dnn\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n = 12\n",
    "x = np.linspace(0, 1, n)\n",
    "x = generate_meshgrid([x,x])\n",
    "\n",
    "mean1 = np.array([[0.2, 0.8]])\n",
    "var1 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "mean2 = np.array([[0.5, 0.8]])\n",
    "var2 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "mean3 = np.array([[0.8, 0.8]])\n",
    "var3 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "mean4 = np.array([[0.2, 0.5]])\n",
    "var4 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "mean5 = np.array([[0.5, 0.5]])\n",
    "var5 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "mean6 = np.array([[0.8, 0.5]])\n",
    "var6 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "mean7 = np.array([[0.2, 0.2]])\n",
    "var7 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "mean8 = np.array([[0.5, 0.2]])\n",
    "var8 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "mean9 = np.array([[0.8, 0.2]])\n",
    "var9 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "\n",
    "y = gaussian(x, mean1, var1) - gaussian(x, mean2, var2) + gaussian(x, mean3, var3) - gaussian(x, mean4, var4) +\\\n",
    "gaussian(x, mean5, var5) - gaussian(x, mean6, var6) + gaussian(x, mean7, var7) - gaussian(x, mean8, var8) +\\\n",
    "gaussian(x, mean9, var9)\n",
    "\n",
    "\n",
    "x_train_qcn = scaler(x, a=-np.pi/2, b=np.pi/2)\n",
    "x_train_dnn = scaler(x, mode=\"standard\")\n",
    "y = scaler(y, a=0, b=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y.reshape(n,n))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 Qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qcn_list\n",
    "for i in range(10)\n",
    "network = sequential_qnn(n_qubits = [6, 6, 6, 6],\n",
    "                         dim = [2, 6, 6, 6, 1] ,\n",
    "                         scale = 3*[[-np.pi, np.pi]] + [[0,1]],\n",
    "                         encoder = Encoder(),\n",
    "                         ansatz = Ansatz(blocks=[\"entangle\", \"ry\"], reps=2),\n",
    "                         sampler = Parity(),\n",
    "                         shots = 0,\n",
    "                         optimizer=Adam(lr=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = TrajectoryLength(network)\n",
    "tl.fit(x_qcn)\n",
    "saver(tl, data_path(\"tl_expressivity_qubit_6_epochs_0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.train(x_train_qcn, y, epochs = 10, verbose=True)\n",
    "saver(network, data_path(\"network_expressivity_qubit_6_epochs_10\"))\n",
    "\n",
    "tl = TrajectoryLength(network)\n",
    "tl.fit(x_qcn)\n",
    "saver(tl, data_path(\"tl_expressivity_qubit_6_epochs_10\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.train(x_train_qcn, y, epochs = 10, verbose=True)\n",
    "saver(network, data_path(\"network_expressivity_qubit_6_epochs_20\"))\n",
    "\n",
    "tl = TrajectoryLength(network)\n",
    "tl.fit(x_qcn)\n",
    "saver(tl, data_path(\"tl_expressivity_qubit_6_epochs_20\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.train(x_train_qcn, y, epochs = 10, verbose=True)\n",
    "saver(network, data_path(\"network_expressivity_qubit_6_epochs_30\"))\n",
    "\n",
    "tl = TrajectoryLength(network)\n",
    "tl.fit(x_qcn)\n",
    "saver(tl, data_path(\"tl_expressivity_qubit_6_epochs_30\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.train(x_train_qcn, y, epochs = 10, verbose=True)\n",
    "saver(network, data_path(\"network_expressivity_qubit_6_epochs_40\"))\n",
    "\n",
    "tl = TrajectoryLength(network)\n",
    "tl.fit(x_qcn)\n",
    "saver(tl, data_path(\"tl_expressivity_qubit_6_epochs_40\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 Qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(44)\n",
    "network = sequential_qnn(n_qubits = [7, 7, 7, 7],\n",
    "                         dim = [2, 7, 7, 7, 1] ,\n",
    "                         scale = 3*[[-np.pi, np.pi]] + [[0,1]],\n",
    "                         encoder = Encoder(),\n",
    "                         ansatz = Ansatz(blocks=[\"entangle\", \"ry\"], reps=2),\n",
    "                         sampler = Parity(),\n",
    "                         shots = 0,\n",
    "                         optimizer=Adam(lr=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = TrajectoryLength(network)\n",
    "tl.fit(x_qcn)\n",
    "saver(tl, data_path(\"tl_expressivity_qubit_7_epochs_0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.train(x_train_qcn, y, epochs = 5, verbose=True)\n",
    "saver(network, data_path(\"network_expressivity_qubit_7_epochs_5\"))\n",
    "\n",
    "tl = TrajectoryLength(network)\n",
    "tl.fit(x_qcn)\n",
    "saver(tl, data_path(\"tl_expressivity_qubit_7_epochs_5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = loarder(\"network_expressivity_qubit_7_epochs_5\")\n",
    "network.train(x_train_qcn, y, epochs = 5, verbose=True)\n",
    "saver(network, data_path(\"network_expressivity_qubit_7_epochs_10\"))\n",
    "\n",
    "tl = TrajectoryLength(network)\n",
    "tl.fit(x_qcn)\n",
    "saver(tl, data_path(\"tl_expressivity_qubit_7_epochs_10\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.train(x_train_qcn, y, epochs = 5, verbose=True)\n",
    "saver(network, data_path(\"network_expressivity_qubit_7_epochs_15\"))\n",
    "\n",
    "l = TrajectoryLength(network)\n",
    "tl.fit(x_qcn)\n",
    "saver(tl, data_path(\"tl_expressivity_qubit_7_epochs_15\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.train(x_train_qcn, y, epochs = 5, verbose=True)\n",
    "saver(network, data_path(\"network_expressivity_qubit_7_epochs_20\"))\n",
    "\n",
    "tl = TrajectoryLength(network)\n",
    "tl.fit(x_qcn)\n",
    "saver(tl, data_path(\"tl_expressivity_qubit_7_epochs_20\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8 Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "network = sequential_dnn(dim=[2, 8, 8, 8, 1],\n",
    "                         optimizer=Adam(lr=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = TrajectoryLength(network)\n",
    "tl.fit(x_dnn)\n",
    "saver(tl, data_path(\"tl_expressivity_epochs_0_dnn\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.train(x_train_dnn, y, epochs=66)\n",
    "\n",
    "tl = TrajectoryLength(network)\n",
    "tl.fit(x_dnn)\n",
    "saver(tl, data_path(\"tl_expressivity_epochs_66_dnn\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.train(x_train_dnn, y, epochs=46)\n",
    "\n",
    "tl = TrajectoryLength(network)\n",
    "tl.fit(x_dnn)\n",
    "saver(tl, data_path(\"tl_expressivity_epochs_112_dnn\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.train(x_train_dnn, y, epochs=45)\n",
    "\n",
    "tl = TrajectoryLength(network)\n",
    "tl.fit(x_dnn)\n",
    "saver(tl, data_path(\"tl_expressivity_epochs_157_dnn\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.train(x_train_dnn, y, epochs=376)\n",
    "\n",
    "tl = TrajectoryLength(network)\n",
    "tl.fit(x_dnn)\n",
    "saver(tl, data_path(\"tl_expressivity_epochs_533_dnn\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9 Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "network = sequential_dnn(dim=[2, 9, 9, 9, 1],\n",
    "                         activation = 3*[Tanh()] + [Identity()],\n",
    "                         optimizer=Adam(lr=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = TrajectoryLength(network)\n",
    "tl.fit(x_dnn)\n",
    "saver(tl, data_path(\"tl_expressivity_epochs_0_dnn_9_nodes\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.train(x_train_dnn, y, epochs=72)\n",
    "\n",
    "tl = TrajectoryLength(network)\n",
    "tl.fit(x_dnn)\n",
    "saver(tl, data_path(\"tl_expressivity_epochs_72_dnn_9_nodes\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.train(x_train_dnn, y, epochs=122)\n",
    "\n",
    "tl = TrajectoryLength(network)\n",
    "tl.fit(x_dnn)\n",
    "saver(tl, data_path(\"tl_expressivity_epochs_194_dnn_9_nodes\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.train(x_train_dnn, y, epochs=577)\n",
    "\n",
    "tl = TrajectoryLength(network)\n",
    "tl.fit(x_dnn)\n",
    "saver(tl, data_path(\"tl_expressivity_epochs_771_dnn_9_nodes\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.train(x_train_dnn, y, epochs=158)\n",
    "\n",
    "tl = TrajectoryLength(network)\n",
    "tl.fit(x_dnn)\n",
    "saver(tl, data_path(\"tl_expressivity_epochs_929_dnn_9_nodes\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_qiskit",
   "language": "python",
   "name": "env_qiskit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
