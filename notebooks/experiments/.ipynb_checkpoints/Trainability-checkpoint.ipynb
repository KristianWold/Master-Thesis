{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import qiskit as qk\n",
    "import matplotlib.pyplot as plt\n",
    "from qiskit import Aer\n",
    "from tqdm.notebook import tqdm\n",
    "import multiprocessing as mp\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../src/')\n",
    "from neuralnetwork import *\n",
    "from analysis import *\n",
    "from utils import *\n",
    "\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = Aer.get_backend('qasm_simulator')\n",
    "\n",
    "def parallel(args):\n",
    "    model = args[0]\n",
    "    x = args[1]\n",
    "    y = args[2]\n",
    "    verbose = args[3]\n",
    "    \n",
    "    model.train(x, y, verbose = verbose)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainability, Ideal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D, Gaussian Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "x = np.linspace(0, 1, n).reshape(-1,1)\n",
    "y = gaussian(x, 0.2, 0.01) - gaussian(x, 0.5, 0.01) + gaussian(x, 0.8, 0.01)\n",
    "\n",
    "x_qcn = scaler(x, a=-np.pi/2, b=np.pi/2)\n",
    "x_dnn = scaler(x, mode=\"standard\")\n",
    "y = scaler(y, a=0, b=1)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_qcn, y, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.14081725856495322\n",
      "epoch: 1, loss: 0.12218127948324799\n",
      "epoch: 2, loss: 0.11159762924623241\n",
      "epoch: 3, loss: 0.09973295329258035\n",
      "epoch: 4, loss: 0.08788048826130765\n",
      "epoch: 5, loss: 0.07522901969429212\n",
      "epoch: 6, loss: 0.05868457408361196\n",
      "epoch: 7, loss: 0.04256620730947176\n",
      "epoch: 8, loss: 0.03184672966793481\n",
      "epoch: 9, loss: 0.026789651352350917\n",
      "epoch: 10, loss: 0.02300728113781846\n",
      "epoch: 11, loss: 0.01896895766838567\n",
      "epoch: 12, loss: 0.015751098981688513\n",
      "epoch: 13, loss: 0.01315123202034696\n",
      "epoch: 14, loss: 0.010853290109319222\n",
      "epoch: 15, loss: 0.007928079932426108\n",
      "epoch: 16, loss: 0.005262863024656155\n",
      "epoch: 17, loss: 0.004734152317330536\n",
      "epoch: 18, loss: 0.006117339318444033\n",
      "epoch: 19, loss: 0.006659604777229462\n",
      "epoch: 20, loss: 0.005469015714841625\n",
      "epoch: 21, loss: 0.004092134221492467\n",
      "epoch: 22, loss: 0.0036396501292210114\n",
      "epoch: 23, loss: 0.0036018735331683604\n",
      "epoch: 24, loss: 0.0032680459067654165\n",
      "epoch: 25, loss: 0.0028867927659748972\n",
      "epoch: 26, loss: 0.0030097458835733324\n",
      "epoch: 27, loss: 0.0036310962412130473\n",
      "epoch: 28, loss: 0.004260313883518693\n",
      "epoch: 29, loss: 0.004487483372086583\n",
      "epoch: 30, loss: 0.004247732105367181\n",
      "epoch: 31, loss: 0.0037665258591838653\n",
      "epoch: 32, loss: 0.003377521057742446\n",
      "epoch: 33, loss: 0.0032554649146857902\n",
      "epoch: 34, loss: 0.00328820553554998\n",
      "epoch: 35, loss: 0.003269900809948182\n",
      "epoch: 36, loss: 0.003173018013703346\n",
      "epoch: 37, loss: 0.003114729156248279\n",
      "epoch: 38, loss: 0.0031079628555012286\n",
      "epoch: 39, loss: 0.0030057260123090134\n",
      "epoch: 40, loss: 0.002719908254321852\n",
      "epoch: 41, loss: 0.0023682935853359278\n",
      "epoch: 42, loss: 0.002138832353668646\n",
      "epoch: 43, loss: 0.0020782198056963665\n",
      "epoch: 44, loss: 0.0020702700869914734\n",
      "epoch: 45, loss: 0.001983981382004113\n",
      "epoch: 46, loss: 0.00178693900951675\n",
      "epoch: 47, loss: 0.0015410284414721722\n",
      "epoch: 48, loss: 0.0013403519278797629\n",
      "epoch: 49, loss: 0.0012373746099387703\n",
      "epoch: 50, loss: 0.001202804665884271\n",
      "epoch: 51, loss: 0.0011665265487456923\n",
      "epoch: 52, loss: 0.0010897106367072924\n",
      "epoch: 53, loss: 0.000984352834682742\n",
      "epoch: 54, loss: 0.0008813281166845374\n",
      "epoch: 55, loss: 0.000805547762213187\n",
      "epoch: 56, loss: 0.0007732709139275195\n",
      "epoch: 57, loss: 0.0007755856653510814\n",
      "epoch: 58, loss: 0.0007738773013476441\n",
      "epoch: 59, loss: 0.0007401848345614012\n",
      "epoch: 60, loss: 0.0006861055945391802\n",
      "epoch: 61, loss: 0.000645392461452754\n",
      "epoch: 62, loss: 0.0006373040549217615\n",
      "epoch: 63, loss: 0.0006468924692050221\n",
      "epoch: 64, loss: 0.0006479488334871984\n",
      "epoch: 65, loss: 0.000634189344098436\n",
      "epoch: 66, loss: 0.0006145404063468089\n",
      "epoch: 67, loss: 0.000596901302113827\n",
      "epoch: 68, loss: 0.0005845140550508927\n",
      "epoch: 69, loss: 0.0005782298667287303\n",
      "epoch: 70, loss: 0.0005786505476702263\n",
      "epoch: 71, loss: 0.000582501148615198\n",
      "epoch: 72, loss: 0.000582162340817238\n",
      "epoch: 73, loss: 0.0005755630333536512\n",
      "epoch: 74, loss: 0.0005681730039991101\n",
      "epoch: 75, loss: 0.000563872113763558\n",
      "epoch: 76, loss: 0.0005622118337190689\n",
      "epoch: 77, loss: 0.0005622382634431302\n",
      "epoch: 78, loss: 0.0005638452043257866\n",
      "epoch: 79, loss: 0.0005661864679855938\n",
      "epoch: 80, loss: 0.0005668402173238832\n",
      "epoch: 81, loss: 0.0005647790276810137\n",
      "epoch: 82, loss: 0.0005624067040626365\n",
      "epoch: 83, loss: 0.0005617146406560909\n",
      "epoch: 84, loss: 0.0005619236004256894\n",
      "epoch: 85, loss: 0.0005622779706736511\n",
      "epoch: 86, loss: 0.000562929975648865\n",
      "epoch: 87, loss: 0.0005633468554580512\n",
      "epoch: 88, loss: 0.0005625956349070136\n",
      "epoch: 89, loss: 0.000560799142706766\n",
      "epoch: 90, loss: 0.0005592866905884367\n",
      "epoch: 91, loss: 0.0005588198246923486\n",
      "epoch: 92, loss: 0.0005587592157118892\n",
      "epoch: 93, loss: 0.0005586940945420528\n",
      "epoch: 94, loss: 0.00055881535793053\n",
      "epoch: 95, loss: 0.0005588162847597964\n",
      "epoch: 96, loss: 0.0005583385593080314\n",
      "epoch: 97, loss: 0.0005577097234659195\n",
      "epoch: 98, loss: 0.0005574614340915969\n",
      "epoch: 99, loss: 0.0005576006132544121\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qcn_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = [4, 4],\n",
    "                         dim = [1, 4, 1],\n",
    "                         encoder = Encoder(),\n",
    "                         ansatz = Ansatz(blocks = [\"entangle\", \"ry\"], reps=1),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         shots = 0)\n",
    "    \n",
    "    qcn_list.append([qcn, x_qcn, y, False])\n",
    "\n",
    "    \n",
    "qcn_list[0][3] = True\n",
    "\n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list) \n",
    "    \n",
    "    \n",
    "saver(qcn_list, data_path(\"trainability_qcn_1D_reps_1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.1530543579647957\n",
      "epoch: 1, loss: 0.08411293862964309\n",
      "epoch: 2, loss: 0.08695614588945234\n",
      "epoch: 3, loss: 0.06563699784519417\n",
      "epoch: 4, loss: 0.037318441848250346\n",
      "epoch: 5, loss: 0.023841717281163185\n",
      "epoch: 6, loss: 0.02608004525145454\n",
      "epoch: 7, loss: 0.02486742102346641\n",
      "epoch: 8, loss: 0.018464607872809707\n",
      "epoch: 9, loss: 0.015072543956755136\n",
      "epoch: 10, loss: 0.015684929982633503\n",
      "epoch: 11, loss: 0.014439573721482604\n",
      "epoch: 12, loss: 0.01189909051971972\n",
      "epoch: 13, loss: 0.01134299027180258\n",
      "epoch: 14, loss: 0.010896518864616228\n",
      "epoch: 15, loss: 0.010045964490913339\n",
      "epoch: 16, loss: 0.010206294336565131\n",
      "epoch: 17, loss: 0.008853001259006385\n",
      "epoch: 18, loss: 0.006128191247238835\n",
      "epoch: 19, loss: 0.0053361143389323825\n",
      "epoch: 20, loss: 0.006032957207159386\n",
      "epoch: 21, loss: 0.005757641665438011\n",
      "epoch: 22, loss: 0.004872776553348238\n",
      "epoch: 23, loss: 0.004358048374766876\n",
      "epoch: 24, loss: 0.004104977176322313\n",
      "epoch: 25, loss: 0.004238960931233941\n",
      "epoch: 26, loss: 0.004647830810957601\n",
      "epoch: 27, loss: 0.004359106379833867\n",
      "epoch: 28, loss: 0.00334219626017328\n",
      "epoch: 29, loss: 0.002810878866164143\n",
      "epoch: 30, loss: 0.0031353497089855226\n",
      "epoch: 31, loss: 0.0033397830759233573\n",
      "epoch: 32, loss: 0.002977629469640855\n",
      "epoch: 33, loss: 0.0024797849044676757\n",
      "epoch: 34, loss: 0.0022099423348131944\n",
      "epoch: 35, loss: 0.0021742550713117373\n",
      "epoch: 36, loss: 0.0021515173342248613\n",
      "epoch: 37, loss: 0.0019173454795368638\n",
      "epoch: 38, loss: 0.001610910113393643\n",
      "epoch: 39, loss: 0.0015988023637517038\n",
      "epoch: 40, loss: 0.0017357859193577545\n",
      "epoch: 41, loss: 0.001558307215508575\n",
      "epoch: 42, loss: 0.0012391781782478339\n",
      "epoch: 43, loss: 0.001198839550778496\n",
      "epoch: 44, loss: 0.0013105122241875034\n",
      "epoch: 45, loss: 0.0012448435594393816\n",
      "epoch: 46, loss: 0.001071134236150794\n",
      "epoch: 47, loss: 0.0010289562773155496\n",
      "epoch: 48, loss: 0.0010644695994747363\n",
      "epoch: 49, loss: 0.0009888425263565677\n",
      "epoch: 50, loss: 0.0008704279707044039\n",
      "epoch: 51, loss: 0.0008495923096224225\n",
      "epoch: 52, loss: 0.0008694814985960426\n",
      "epoch: 53, loss: 0.0008310452040200053\n",
      "epoch: 54, loss: 0.0007659798270945238\n",
      "epoch: 55, loss: 0.0007438804713442052\n",
      "epoch: 56, loss: 0.0007384750734855291\n",
      "epoch: 57, loss: 0.0006927091816901736\n",
      "epoch: 58, loss: 0.0006425266368248438\n",
      "epoch: 59, loss: 0.0006460759379229622\n",
      "epoch: 60, loss: 0.0006405337349108272\n",
      "epoch: 61, loss: 0.0005908919689852072\n",
      "epoch: 62, loss: 0.0005799316443038489\n",
      "epoch: 63, loss: 0.000582497418311257\n",
      "epoch: 64, loss: 0.0005339079901323491\n",
      "epoch: 65, loss: 0.0005164848569844854\n",
      "epoch: 66, loss: 0.0005259353636386089\n",
      "epoch: 67, loss: 0.0004888021334282328\n",
      "epoch: 68, loss: 0.0004784698574777451\n",
      "epoch: 69, loss: 0.00048601261099832574\n",
      "epoch: 70, loss: 0.00045250793799533743\n",
      "epoch: 71, loss: 0.0004464372354121109\n",
      "epoch: 72, loss: 0.00044520541933199784\n",
      "epoch: 73, loss: 0.00041880026323132014\n",
      "epoch: 74, loss: 0.00042081495306769355\n",
      "epoch: 75, loss: 0.0004149335366121433\n",
      "epoch: 76, loss: 0.0003983907145516785\n",
      "epoch: 77, loss: 0.0004009732492654074\n",
      "epoch: 78, loss: 0.0003898198248847042\n",
      "epoch: 79, loss: 0.00037969727069121306\n",
      "epoch: 80, loss: 0.0003794018926799666\n",
      "epoch: 81, loss: 0.0003685841619299878\n",
      "epoch: 82, loss: 0.0003648415457837697\n",
      "epoch: 83, loss: 0.0003629321167965403\n",
      "epoch: 84, loss: 0.00035405610308208947\n",
      "epoch: 85, loss: 0.0003530159933843051\n",
      "epoch: 86, loss: 0.0003473771149534732\n",
      "epoch: 87, loss: 0.0003412105699152452\n",
      "epoch: 88, loss: 0.000340443279502643\n",
      "epoch: 89, loss: 0.00033335088534244334\n",
      "epoch: 90, loss: 0.00033197451568046563\n",
      "epoch: 91, loss: 0.00032834474564690213\n",
      "epoch: 92, loss: 0.0003234378845126596\n",
      "epoch: 93, loss: 0.0003222638602245858\n",
      "epoch: 94, loss: 0.00031652608919150767\n",
      "epoch: 95, loss: 0.00031492261046964584\n",
      "epoch: 96, loss: 0.0003112512831016104\n",
      "epoch: 97, loss: 0.00030805108185185493\n",
      "epoch: 98, loss: 0.00030614738498880065\n",
      "epoch: 99, loss: 0.0003022677870944786\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qcn_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = [4, 4],\n",
    "                         dim = [1, 4, 1],\n",
    "                         encoder= Encoder(),\n",
    "                         ansatz = Ansatz(blocks = [\"entangle\", \"ry\"], reps=2),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         shots=0)\n",
    "    \n",
    "    qcn_list.append([qcn, x_qcn, y, False])\n",
    "\n",
    "qcn_list[0][3] = True    \n",
    "    \n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list)     \n",
    "    \n",
    "saver(qcn_list, data_path(\"trainability_qcn_1D_reps_2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dnn_list = []\n",
    "for i in range(10):\n",
    "    dnn = sequential_dnn(dim = [1, 5, 1],\n",
    "                         optimizer = Adam(lr=0.1))\n",
    "    \n",
    "    dnn.train(x_dnn, y, epochs=100)\n",
    "    dnn_list.append(dnn)\n",
    "\n",
    "saver(dnn_list, data_path(\"trainability_dnn_1D_epochs_100\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dnn_list = []\n",
    "for i in range(10):\n",
    "    dnn = sequential_dnn(dim = [1, 5, 1],\n",
    "                         optimizer = Adam(lr=0.1))\n",
    "    \n",
    "    dnn.train(x_dnn, y, epochs=10000)\n",
    "    dnn_list.append(dnn)\n",
    "\n",
    "saver(dnn_list, data_path(\"trainability_dnn_1D_epochs_10000\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n = 12\n",
    "x = np.linspace(0, 1, n)\n",
    "x = generate_meshgrid([x,x])\n",
    "\n",
    "mean1 = np.array([[0.2, 0.8]])\n",
    "var1 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "mean2 = np.array([[0.5, 0.8]])\n",
    "var2 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "mean3 = np.array([[0.8, 0.8]])\n",
    "var3 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "mean4 = np.array([[0.2, 0.5]])\n",
    "var4 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "mean5 = np.array([[0.5, 0.5]])\n",
    "var5 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "mean6 = np.array([[0.8, 0.5]])\n",
    "var6 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "mean7 = np.array([[0.2, 0.2]])\n",
    "var7 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "mean8 = np.array([[0.5, 0.2]])\n",
    "var8 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "mean9 = np.array([[0.8, 0.2]])\n",
    "var9 = np.array([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "\n",
    "y = gaussian(x, mean1, var1) - gaussian(x, mean2, var2) + gaussian(x, mean3, var3) - gaussian(x, mean4, var4) +\\\n",
    "gaussian(x, mean5, var5) - gaussian(x, mean6, var6) + gaussian(x, mean7, var7) - gaussian(x, mean8, var8) +\\\n",
    "gaussian(x, mean9, var9)\n",
    "\n",
    "\n",
    "x_qcn = scaler(x, a=0, b=np.pi)\n",
    "x_dnn = scaler(x, mode=\"standard\")\n",
    "y = scaler(y, a=0, b=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y.reshape(n,n))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qcn_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = [4, 4],\n",
    "                         dim = [2, 4, 1],\n",
    "                         encoder= Encoder(),\n",
    "                         ansatz = Ansatz(blocks = [\"entangle\", \"ry\"], reps=1),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         backend=backend,\n",
    "                         shots=0)\n",
    "    qcn_list.append([qcn, x_qcn, y, False])\n",
    "    \n",
    "qcn_list[0][3] = True    \n",
    "    \n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list)   \n",
    "\n",
    "saver(qcn_list, data_path(\"trainability_qcn_2D_reps_1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qcn_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = [4, 4],\n",
    "                         dim = [2, 4, 1],\n",
    "                         encoder= Encoder(),\n",
    "                         ansatz = Ansatz(blocks = [\"entangle\", \"ry\"], reps=2),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         backend=backend,\n",
    "                         shots=0)\n",
    "   \n",
    "    qcn_list.append([qcn, x_qcn, y, False])\n",
    "\n",
    "qcn_list[0][3] = True    \n",
    "    \n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list)   \n",
    "    \n",
    "saver(qcn_list, data_path(\"trainability_qcn_2D_reps_2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dnn_list = []\n",
    "for i in range(5):\n",
    "    dnn = sequential_dnn(dim = [2, 5, 1],\n",
    "                         optimizer = Adam(lr=0.1))\n",
    "    \n",
    "    dnn.train(x_dnn, y, epochs=100)\n",
    "    dnn_list.append(dnn)\n",
    "\n",
    "saver(dnn_list, data_path(\"trainability_dnn_2D_epochs_100\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n = 6\n",
    "x = np.linspace(0, 1, n)\n",
    "x = generate_meshgrid([x, x, x])\n",
    "\n",
    "mean1 = np.array([[0.25, 0.25, 0.25]])\n",
    "mean2 = np.array([[0.25, 0.25, 0.75]])\n",
    "mean3 = np.array([[0.25, 0.75, 0.75]])\n",
    "mean4 = np.array([[0.25, 0.75, 0.25]])\n",
    "\n",
    "mean5 = np.array([[0.75, 0.25, 0.25]])\n",
    "mean6 = np.array([[0.75, 0.25, 0.75]])\n",
    "mean7 = np.array([[0.75, 0.75, 0.75]])\n",
    "mean8 = np.array([[0.75, 0.75, 0.25]])\n",
    "\n",
    "var = np.array([[0.02, 0, 0], [0, 0.02, 0], [0, 0, 0.02]])\n",
    "\n",
    "y = gaussian(x, mean1, var) - gaussian(x, mean2, var) + gaussian(x, mean3, var) - gaussian(x, mean4, var) - gaussian(x, mean5, var) + gaussian(x, mean6, var) - gaussian(x, mean7, var) + gaussian(x, mean8, var)\n",
    "\n",
    "x_qcn = scaler(x, a=0, b=np.pi)\n",
    "x_dnn = scaler(x, mode=\"standard\")\n",
    "y = scaler(y, a=0, b=1)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y.reshape(n,n,n)[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qcn_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = [5, 5, 5],\n",
    "                         dim = [3, 5, 5, 1],\n",
    "                         encoder= Encoder(),\n",
    "                         ansatz = Ansatz(blocks = [\"entangle\", \"ry\"], reps = 1),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         backend = backend,\n",
    "                         shots = 0)\n",
    "\n",
    "    qcn_list.append([qcn, x_qcn, y, False])\n",
    "\n",
    "qcn_list[0][3] = True    \n",
    "    \n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list) \n",
    "    \n",
    "saver(qcn_list, data_path(\"trainability_qnn_3D_reps_1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qcn_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = [5, 5, 5],\n",
    "                         dim = [3, 5, 5, 1],\n",
    "                         encoder= Encoder(),\n",
    "                         ansatz = Ansatz(blocks = [\"entangle\", \"ry\"], reps = 2),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         backend = backend,\n",
    "                         shots = 0)\n",
    "\n",
    "    qcn_list.append([qcn, x_qcn, y, False])\n",
    "\n",
    "qcn_list[0][3] = True    \n",
    "    \n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list) \n",
    "    \n",
    "saver(qcn_list, data_path(\"trainability_qnn_3D_reps_2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dnn_list = []\n",
    "for i in range(10):\n",
    "    dnn = sequential_dnn(dim = [3, 8, 8, 1],\n",
    "                         optimizer = Adam(lr=0.1))\n",
    "    \n",
    "    dnn.train(x_dnn, y, epochs=100)\n",
    "    dnn_list.append(dnn)\n",
    "\n",
    "saver(dnn_list, data_path(\"trainability_dnn_3D_epochs_100\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dnn_list = []\n",
    "for i in range(10):\n",
    "    dnn = sequential_dnn(dim = [3, 8, 8, 1],\n",
    "                         optimizer = Adam(lr=0.1))\n",
    "    \n",
    "    dnn.train(x_dnn, y, epochs=10000)\n",
    "    dnn_list.append(dnn)\n",
    "\n",
    "saver(dnn_list, data_path(\"trainability_dnn_3D_epochs_10000\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainability, Noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend_santiago = pickle.load(open(\"backend_santiago\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D, Gaussian Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "x = np.linspace(0, 1, n).reshape(-1,1)\n",
    "y = gaussian(x, 0.2, 0.01) - gaussian(x, 0.5, 0.01) + gaussian(x, 0.8, 0.01)\n",
    "\n",
    "x_qcn = scaler(x, a=-np.pi/2, b=np.pi/2)\n",
    "x_dnn = scaler(x, mode=\"standard\")\n",
    "y = scaler(y, a=0, b=1)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_qcn, y, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.14116189887302164\n",
      "epoch: 1, loss: 0.12248295090363229\n",
      "epoch: 2, loss: 0.11250269420402588\n",
      "epoch: 3, loss: 0.10616333798002887\n",
      "epoch: 4, loss: 0.09757624753238513\n",
      "epoch: 5, loss: 0.08794267603754535\n",
      "epoch: 6, loss: 0.07417260759845884\n",
      "epoch: 7, loss: 0.06135294878786685\n",
      "epoch: 8, loss: 0.05328782649160126\n",
      "epoch: 9, loss: 0.051034924512023044\n",
      "epoch: 10, loss: 0.04366365807739563\n",
      "epoch: 11, loss: 0.03823363828391696\n",
      "epoch: 12, loss: 0.03501960160647086\n",
      "epoch: 13, loss: 0.031219152603103706\n",
      "epoch: 14, loss: 0.027083290694734953\n",
      "epoch: 15, loss: 0.02477528380217088\n",
      "epoch: 16, loss: 0.02061730770744847\n",
      "epoch: 17, loss: 0.021600236265254362\n",
      "epoch: 18, loss: 0.019057734434734595\n",
      "epoch: 19, loss: 0.01751063972223564\n",
      "epoch: 20, loss: 0.015742868180815876\n",
      "epoch: 21, loss: 0.015080866122253676\n",
      "epoch: 22, loss: 0.013625957879584592\n",
      "epoch: 23, loss: 0.013987704328860928\n",
      "epoch: 24, loss: 0.013565494380335705\n",
      "epoch: 25, loss: 0.012478381957743444\n",
      "epoch: 26, loss: 0.011875328189383099\n",
      "epoch: 27, loss: 0.011242423373787383\n",
      "epoch: 28, loss: 0.011672386574982279\n",
      "epoch: 29, loss: 0.011258001510883155\n",
      "epoch: 30, loss: 0.01155517976386075\n",
      "epoch: 31, loss: 0.010655369377733178\n",
      "epoch: 32, loss: 0.008668508960752113\n",
      "epoch: 33, loss: 0.010595598531105392\n",
      "epoch: 34, loss: 0.009439531735937262\n",
      "epoch: 35, loss: 0.010494820601344854\n",
      "epoch: 36, loss: 0.010315044203472307\n",
      "epoch: 37, loss: 0.009370288650422024\n",
      "epoch: 38, loss: 0.008221532588692926\n",
      "epoch: 39, loss: 0.007583557991065259\n",
      "epoch: 40, loss: 0.008164776134815796\n",
      "epoch: 41, loss: 0.008356540366018574\n",
      "epoch: 42, loss: 0.00860108811855395\n",
      "epoch: 43, loss: 0.008041591158257762\n",
      "epoch: 44, loss: 0.007695049089477725\n",
      "epoch: 45, loss: 0.008114051263031264\n",
      "epoch: 46, loss: 0.007771733417786395\n",
      "epoch: 47, loss: 0.0072941423087852465\n",
      "epoch: 48, loss: 0.00807026507465029\n",
      "epoch: 49, loss: 0.007608636694606582\n",
      "epoch: 50, loss: 0.007520139680969666\n",
      "epoch: 51, loss: 0.00829254938326082\n",
      "epoch: 52, loss: 0.007674993802930149\n",
      "epoch: 53, loss: 0.007530112505439953\n",
      "epoch: 54, loss: 0.007408229895511365\n",
      "epoch: 55, loss: 0.006888892407713878\n",
      "epoch: 56, loss: 0.007832967888758112\n",
      "epoch: 57, loss: 0.007891389559798189\n",
      "epoch: 58, loss: 0.007576860534595073\n",
      "epoch: 59, loss: 0.007221113892288038\n",
      "epoch: 60, loss: 0.007560664686289424\n",
      "epoch: 61, loss: 0.0076533379681644476\n",
      "epoch: 62, loss: 0.007782562680891665\n",
      "epoch: 63, loss: 0.007408321458853231\n",
      "epoch: 64, loss: 0.008610431703781089\n",
      "epoch: 65, loss: 0.008302160167077221\n",
      "epoch: 66, loss: 0.008598382168972253\n",
      "epoch: 67, loss: 0.007868625289143704\n",
      "epoch: 68, loss: 0.007588379978167029\n",
      "epoch: 69, loss: 0.007491887376689421\n",
      "epoch: 70, loss: 0.007405156682407107\n",
      "epoch: 71, loss: 0.007177979130234805\n",
      "epoch: 72, loss: 0.0074186489571560045\n",
      "epoch: 73, loss: 0.006720539941659645\n",
      "epoch: 74, loss: 0.006716317477111961\n",
      "epoch: 75, loss: 0.007030797260994375\n",
      "epoch: 76, loss: 0.007125102107679436\n",
      "epoch: 77, loss: 0.007537981027500786\n",
      "epoch: 78, loss: 0.007243062112702476\n",
      "epoch: 79, loss: 0.006917835481977329\n",
      "epoch: 80, loss: 0.007329562776751846\n",
      "epoch: 81, loss: 0.006898063070144671\n",
      "epoch: 82, loss: 0.007255603611870046\n",
      "epoch: 83, loss: 0.007504685997293932\n",
      "epoch: 84, loss: 0.007374804527291095\n",
      "epoch: 85, loss: 0.007998251792853177\n",
      "epoch: 86, loss: 0.007132681817017899\n",
      "epoch: 87, loss: 0.007116907207915893\n",
      "epoch: 88, loss: 0.007415600563845145\n",
      "epoch: 89, loss: 0.006947692739009919\n",
      "epoch: 90, loss: 0.00775618794683732\n",
      "epoch: 91, loss: 0.006996828261409067\n",
      "epoch: 92, loss: 0.008037452034604238\n",
      "epoch: 93, loss: 0.007457919361385622\n",
      "epoch: 94, loss: 0.007024393550941315\n",
      "epoch: 95, loss: 0.008225898846610721\n",
      "epoch: 96, loss: 0.0072590893443956386\n",
      "epoch: 97, loss: 0.007151049734946308\n",
      "epoch: 98, loss: 0.008043681640700864\n",
      "epoch: 99, loss: 0.007960275370788344\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "qcn_list = []\n",
    "for i in range(10):\n",
    "    qcn = sequential_qnn(n_qubits = [4, 4],\n",
    "                         dim = [1, 4, 1],\n",
    "                         encoder = Encoder(),\n",
    "                         ansatz = Ansatz(blocks = [\"entangle\", \"ry\"], reps=1),\n",
    "                         sampler = Parity(),\n",
    "                         cost = MSE(),\n",
    "                         optimizer = Adam(lr=0.1),\n",
    "                         backend = backend_santiago,\n",
    "                         shots = 8192)\n",
    "    \n",
    "    qcn_list.append([qcn, x_qcn, y, False])\n",
    "\n",
    "    \n",
    "qcn_list[0][3] = True\n",
    "\n",
    "with mp.Pool(10) as p:\n",
    "    qcn_list = p.map(parallel, qcn_list) \n",
    "    \n",
    "saver(qcn_list, data_path(\"trainability_qcn_1D_reps_1_noisy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "22:32"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_qiskit",
   "language": "python",
   "name": "env_qiskit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
