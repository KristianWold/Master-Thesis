{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qiskit as qk\n",
    "import matplotlib.pyplot as plt\n",
    "from qiskit import Aer\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../src/')\n",
    "from neuralnetwork import *\n",
    "from analysis import *\n",
    "from utils import *\n",
    "\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = Aer.get_backend('qasm_simulator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized Feature Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n = 200\n",
    "n_features = 4\n",
    "epochs = 100\n",
    "x = np.random.uniform(0, np.pi, (n, n_features))\n",
    "\n",
    "y = np.sin(2*x[:,2])\n",
    "y = scaler(y, a=0.1, b=0.9).reshape(-1, 1)\n",
    "\n",
    "x_train, y_train = x[:100,:], y[:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_train[:,2], y_train,\"o\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c908730c892b42899d843806a926b8d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a72bd617fd34d2196f85582250b1807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.09138601454219712\n",
      "epoch: 1, loss: 0.07412890229727098\n",
      "epoch: 2, loss: 0.07308813987854881\n",
      "epoch: 3, loss: 0.07210081925861814\n",
      "epoch: 4, loss: 0.06869263676824285\n",
      "epoch: 5, loss: 0.0626464003480534\n",
      "epoch: 6, loss: 0.05737644954548731\n",
      "epoch: 7, loss: 0.051912753065810203\n",
      "epoch: 8, loss: 0.04642565990559767\n",
      "epoch: 9, loss: 0.04134601354370838\n",
      "epoch: 10, loss: 0.03826831296481133\n",
      "epoch: 11, loss: 0.035407312865711804\n",
      "epoch: 12, loss: 0.03407475630776921\n",
      "epoch: 13, loss: 0.03226816891696616\n",
      "epoch: 14, loss: 0.03077835913779596\n",
      "epoch: 15, loss: 0.028660245002737034\n",
      "epoch: 16, loss: 0.026756283161953207\n",
      "epoch: 17, loss: 0.02544573673682764\n",
      "epoch: 18, loss: 0.024497279122335774\n",
      "epoch: 19, loss: 0.023741035864832755\n",
      "epoch: 20, loss: 0.023012098657432273\n",
      "epoch: 21, loss: 0.023208484497091217\n",
      "epoch: 22, loss: 0.022707553458304046\n",
      "epoch: 23, loss: 0.02255540649552537\n",
      "epoch: 24, loss: 0.022121150104210438\n",
      "epoch: 25, loss: 0.02183383150262536\n",
      "epoch: 26, loss: 0.021442398381498185\n",
      "epoch: 27, loss: 0.020949414716402086\n",
      "epoch: 28, loss: 0.01991961190913035\n",
      "epoch: 29, loss: 0.018905438196979766\n",
      "epoch: 30, loss: 0.017741312838961486\n",
      "epoch: 31, loss: 0.016482920602744165\n",
      "epoch: 32, loss: 0.0153524996955412\n",
      "epoch: 33, loss: 0.014531954501986572\n",
      "epoch: 34, loss: 0.013733831059039709\n",
      "epoch: 35, loss: 0.013063546186832285\n",
      "epoch: 36, loss: 0.012168490246820918\n",
      "epoch: 37, loss: 0.011600550705702149\n",
      "epoch: 38, loss: 0.010752526714930268\n",
      "epoch: 39, loss: 0.010216095359533701\n",
      "epoch: 40, loss: 0.010139456164353005\n",
      "epoch: 41, loss: 0.010125732344853896\n",
      "epoch: 42, loss: 0.01017515974020199\n",
      "epoch: 43, loss: 0.01002313328569438\n",
      "epoch: 44, loss: 0.009443409381298527\n",
      "epoch: 45, loss: 0.008908734145965434\n",
      "epoch: 46, loss: 0.008670237019459577\n",
      "epoch: 47, loss: 0.008753152380512242\n",
      "epoch: 48, loss: 0.008573715768922996\n",
      "epoch: 49, loss: 0.008817752252189521\n",
      "epoch: 50, loss: 0.008758100884046662\n",
      "epoch: 51, loss: 0.008346821646903984\n",
      "epoch: 52, loss: 0.008214472481678286\n",
      "epoch: 53, loss: 0.008089054556570698\n",
      "epoch: 54, loss: 0.008210646351021453\n",
      "epoch: 55, loss: 0.008299731774875693\n",
      "epoch: 56, loss: 0.008283996343286118\n",
      "epoch: 57, loss: 0.00829480633473595\n",
      "epoch: 58, loss: 0.008319732048921493\n",
      "epoch: 59, loss: 0.008223959572551846\n",
      "epoch: 60, loss: 0.008172733061075488\n",
      "epoch: 61, loss: 0.007998754628265027\n",
      "epoch: 62, loss: 0.007995225699773248\n",
      "epoch: 63, loss: 0.007865002761716046\n",
      "epoch: 64, loss: 0.007895404903627999\n",
      "epoch: 65, loss: 0.007976391614523452\n",
      "epoch: 66, loss: 0.008013770527212638\n",
      "epoch: 67, loss: 0.007806079349169416\n",
      "epoch: 68, loss: 0.007880142632543967\n",
      "epoch: 69, loss: 0.007836544697007666\n",
      "epoch: 70, loss: 0.007822554257238719\n",
      "epoch: 71, loss: 0.007851945984091257\n",
      "epoch: 72, loss: 0.007868531883124742\n",
      "epoch: 73, loss: 0.007932107803590865\n",
      "epoch: 74, loss: 0.00775233617735897\n",
      "epoch: 75, loss: 0.007776797726210648\n",
      "epoch: 76, loss: 0.007966002410433227\n",
      "epoch: 77, loss: 0.007718309190401578\n",
      "epoch: 78, loss: 0.00778840119133136\n",
      "epoch: 79, loss: 0.007654014166011686\n",
      "epoch: 80, loss: 0.007809663226130581\n",
      "epoch: 81, loss: 0.007792593871848365\n",
      "epoch: 82, loss: 0.007679664770999288\n",
      "epoch: 83, loss: 0.007715273140258719\n",
      "epoch: 84, loss: 0.007694792593799607\n",
      "epoch: 85, loss: 0.007925125829448466\n",
      "epoch: 86, loss: 0.007806803412892861\n",
      "epoch: 87, loss: 0.007675980125981011\n",
      "epoch: 88, loss: 0.007663139070473778\n",
      "epoch: 89, loss: 0.007648926893177063\n",
      "epoch: 90, loss: 0.007599005099103089\n",
      "epoch: 91, loss: 0.007771304982551718\n",
      "epoch: 92, loss: 0.007756417755158252\n",
      "epoch: 93, loss: 0.007692109735960479\n",
      "epoch: 94, loss: 0.007650217049938231\n",
      "epoch: 95, loss: 0.007674569699616362\n",
      "epoch: 96, loss: 0.007586450396176724\n",
      "epoch: 97, loss: 0.007752740899265375\n",
      "epoch: 98, loss: 0.0076186650059454995\n",
      "epoch: 99, loss: 0.007814423912016923\n",
      "0.007714032634556097\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "590553886dd04dfd95707d3e95be9170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.07755543521250739\n",
      "epoch: 1, loss: 0.07898924592430542\n",
      "epoch: 2, loss: 0.07803508074456654\n",
      "epoch: 3, loss: 0.07835827615154481\n",
      "epoch: 4, loss: 0.07829733047011203\n",
      "epoch: 5, loss: 0.0783832058349037\n",
      "epoch: 6, loss: 0.07765203373565781\n",
      "epoch: 7, loss: 0.07756572621246166\n",
      "epoch: 8, loss: 0.07658880170928024\n",
      "epoch: 9, loss: 0.07544957331119095\n",
      "epoch: 10, loss: 0.07283552417966328\n",
      "epoch: 11, loss: 0.0671170156274058\n",
      "epoch: 12, loss: 0.059900998431559785\n",
      "epoch: 13, loss: 0.05071515182348048\n",
      "epoch: 14, loss: 0.04080730434314634\n",
      "epoch: 15, loss: 0.032171762073475885\n",
      "epoch: 16, loss: 0.026153195989372956\n",
      "epoch: 17, loss: 0.023698469980999906\n",
      "epoch: 18, loss: 0.024000004766151054\n",
      "epoch: 19, loss: 0.02449901879406543\n",
      "epoch: 20, loss: 0.024620815056843295\n",
      "epoch: 21, loss: 0.02397441067531845\n",
      "epoch: 22, loss: 0.024250675121481016\n",
      "epoch: 23, loss: 0.024108978138576483\n",
      "epoch: 24, loss: 0.023774518205438903\n",
      "epoch: 25, loss: 0.023858910547586314\n",
      "epoch: 26, loss: 0.02381781381348391\n",
      "epoch: 27, loss: 0.023447366813416304\n",
      "epoch: 28, loss: 0.024052131289406885\n",
      "epoch: 29, loss: 0.02374507497450344\n",
      "epoch: 30, loss: 0.022941415491681286\n",
      "epoch: 31, loss: 0.022757257951521025\n",
      "epoch: 32, loss: 0.022242990952911504\n",
      "epoch: 33, loss: 0.021334054116364812\n",
      "epoch: 34, loss: 0.02033334430333988\n",
      "epoch: 35, loss: 0.019310341810005557\n",
      "epoch: 36, loss: 0.017655808249161208\n",
      "epoch: 37, loss: 0.015893721922469937\n",
      "epoch: 38, loss: 0.014207784133423907\n",
      "epoch: 39, loss: 0.011822019041642508\n",
      "epoch: 40, loss: 0.009799032967252735\n",
      "epoch: 41, loss: 0.008119302529967789\n",
      "epoch: 42, loss: 0.007127232994112229\n",
      "epoch: 43, loss: 0.006337927342622367\n",
      "epoch: 44, loss: 0.005112544980593178\n",
      "epoch: 45, loss: 0.00373035160625492\n",
      "epoch: 46, loss: 0.0022560696176016654\n",
      "epoch: 47, loss: 0.001290715730779226\n",
      "epoch: 48, loss: 0.0011278276532444818\n",
      "epoch: 49, loss: 0.0014171366761254966\n",
      "epoch: 50, loss: 0.0016238934201506573\n",
      "epoch: 51, loss: 0.0011083700341426577\n",
      "epoch: 52, loss: 0.00048158141635386666\n",
      "epoch: 53, loss: 0.000160553237800801\n",
      "epoch: 54, loss: 0.00027538296156797435\n",
      "epoch: 55, loss: 0.0005597145626604997\n",
      "epoch: 56, loss: 0.0008256236290761303\n",
      "epoch: 57, loss: 0.0008791376635584122\n",
      "epoch: 58, loss: 0.0007760129650858515\n",
      "epoch: 59, loss: 0.0006256046988450742\n",
      "epoch: 60, loss: 0.0005080523960112528\n",
      "epoch: 61, loss: 0.00046738847458916116\n",
      "epoch: 62, loss: 0.0005080456702217505\n",
      "epoch: 63, loss: 0.000534705292674271\n",
      "epoch: 64, loss: 0.0005809424168790175\n",
      "epoch: 65, loss: 0.0005802738349823345\n",
      "epoch: 66, loss: 0.0005370799846094792\n",
      "epoch: 67, loss: 0.00036096697593000256\n",
      "epoch: 68, loss: 0.0002511282890562856\n",
      "epoch: 69, loss: 0.00019747188031304783\n",
      "epoch: 70, loss: 0.0001753373734597923\n",
      "epoch: 71, loss: 0.0001504948273089632\n",
      "epoch: 72, loss: 0.00015662795130101502\n",
      "epoch: 73, loss: 0.00018309028889910091\n",
      "epoch: 74, loss: 0.00014042763759277333\n",
      "epoch: 75, loss: 5.486257321644574e-05\n",
      "epoch: 76, loss: 4.707805207707745e-05\n",
      "epoch: 77, loss: 5.697431018378109e-05\n",
      "epoch: 78, loss: 3.598960958822288e-05\n",
      "epoch: 79, loss: 7.704737035164843e-05\n",
      "epoch: 80, loss: 9.068232968059947e-05\n",
      "epoch: 81, loss: 0.00010981247947169042\n",
      "epoch: 82, loss: 6.922251450404331e-05\n",
      "epoch: 83, loss: 7.393967317081293e-05\n",
      "epoch: 84, loss: 7.417960157517961e-05\n",
      "epoch: 85, loss: 5.4225461699533535e-05\n",
      "epoch: 86, loss: 5.7052601173480926e-05\n",
      "epoch: 87, loss: 5.1032934259576544e-05\n",
      "epoch: 88, loss: 6.27131085624331e-05\n",
      "epoch: 89, loss: 6.929949158251474e-05\n",
      "epoch: 90, loss: 5.330827231314151e-05\n",
      "epoch: 91, loss: 3.73686635433428e-05\n",
      "epoch: 92, loss: 3.017448740338992e-05\n",
      "epoch: 93, loss: 2.430784316216055e-05\n",
      "epoch: 94, loss: 3.385932820232812e-05\n",
      "epoch: 95, loss: 2.3229391167943764e-05\n",
      "epoch: 96, loss: 2.501759731527454e-05\n",
      "epoch: 97, loss: 3.0226131310303988e-05\n",
      "epoch: 98, loss: 2.6072389995844115e-05\n",
      "epoch: 99, loss: 1.906301925406485e-05\n",
      "2.5558673415614072e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea1f6543545d4de190e679c7c6d93de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.07839340368613873\n",
      "epoch: 1, loss: 0.07844311323160079\n",
      "epoch: 2, loss: 0.07794091631755601\n",
      "epoch: 3, loss: 0.07452737460390661\n",
      "epoch: 4, loss: 0.06745184190338976\n",
      "epoch: 5, loss: 0.05915808880854817\n",
      "epoch: 6, loss: 0.049973018514992945\n",
      "epoch: 7, loss: 0.04024581163799439\n",
      "epoch: 8, loss: 0.031614167874071966\n",
      "epoch: 9, loss: 0.02688833201261381\n",
      "epoch: 10, loss: 0.024980325945665217\n",
      "epoch: 11, loss: 0.024386278864638986\n",
      "epoch: 12, loss: 0.02446428423125502\n",
      "epoch: 13, loss: 0.02484726426556413\n",
      "epoch: 14, loss: 0.02487897920542357\n",
      "epoch: 15, loss: 0.025167758892147295\n",
      "epoch: 16, loss: 0.02492297294506501\n",
      "epoch: 17, loss: 0.024982348676629833\n",
      "epoch: 18, loss: 0.024180391993616882\n",
      "epoch: 19, loss: 0.02335215564247154\n",
      "epoch: 20, loss: 0.02213205857075222\n",
      "epoch: 21, loss: 0.020997409111074505\n",
      "epoch: 22, loss: 0.01929400207573055\n",
      "epoch: 23, loss: 0.017999109448537318\n",
      "epoch: 24, loss: 0.016707523455849912\n",
      "epoch: 25, loss: 0.015547844565509226\n",
      "epoch: 26, loss: 0.014243545823583217\n",
      "epoch: 27, loss: 0.013650833828967021\n",
      "epoch: 28, loss: 0.013000842760147997\n",
      "epoch: 29, loss: 0.01170242143713108\n",
      "epoch: 30, loss: 0.010148192197905965\n",
      "epoch: 31, loss: 0.008606349148631221\n",
      "epoch: 32, loss: 0.007865718924395412\n",
      "epoch: 33, loss: 0.00741343312366873\n",
      "epoch: 34, loss: 0.007156502406905153\n",
      "epoch: 35, loss: 0.006333378329279434\n",
      "epoch: 36, loss: 0.0057434941150145994\n",
      "epoch: 37, loss: 0.004959809631211828\n",
      "epoch: 38, loss: 0.004301197099993233\n",
      "epoch: 39, loss: 0.003996749649685824\n",
      "epoch: 40, loss: 0.0038328544472139765\n",
      "epoch: 41, loss: 0.003540251728051026\n",
      "epoch: 42, loss: 0.0032196532964278626\n",
      "epoch: 43, loss: 0.0030541590479960306\n",
      "epoch: 44, loss: 0.0031509202303777665\n",
      "epoch: 45, loss: 0.0031509352011756474\n",
      "epoch: 46, loss: 0.0031168680489123803\n",
      "epoch: 47, loss: 0.003159663063856679\n",
      "epoch: 48, loss: 0.0030116902599381305\n",
      "epoch: 49, loss: 0.0029748925547430226\n",
      "epoch: 50, loss: 0.0029782344427733217\n",
      "epoch: 51, loss: 0.002949656945114955\n",
      "epoch: 52, loss: 0.002938570918314698\n",
      "epoch: 53, loss: 0.002913455721259304\n",
      "epoch: 54, loss: 0.0029792340090306585\n",
      "epoch: 55, loss: 0.002933841783300996\n",
      "epoch: 56, loss: 0.002934357100154003\n",
      "epoch: 57, loss: 0.0029243467969305094\n",
      "epoch: 58, loss: 0.002896636734889404\n",
      "epoch: 59, loss: 0.0029099129861600266\n",
      "epoch: 60, loss: 0.0029168616852402237\n",
      "epoch: 61, loss: 0.0029334660131462424\n",
      "epoch: 62, loss: 0.0029733057803731865\n",
      "epoch: 63, loss: 0.0029313154900138367\n",
      "epoch: 64, loss: 0.00288276500209208\n",
      "epoch: 65, loss: 0.0029406433648921687\n",
      "epoch: 66, loss: 0.002952706253146667\n",
      "epoch: 67, loss: 0.002833692264583031\n",
      "epoch: 68, loss: 0.002867444090401651\n",
      "epoch: 69, loss: 0.002806615207253879\n",
      "epoch: 70, loss: 0.002848343632319372\n",
      "epoch: 71, loss: 0.002785914312957411\n",
      "epoch: 72, loss: 0.0027565620118693585\n",
      "epoch: 73, loss: 0.0028528585503084358\n",
      "epoch: 74, loss: 0.0027564470074725174\n",
      "epoch: 75, loss: 0.0027069167685870076\n",
      "epoch: 76, loss: 0.00269167078973199\n",
      "epoch: 77, loss: 0.0026204967273274838\n",
      "epoch: 78, loss: 0.0026324729284460864\n",
      "epoch: 79, loss: 0.0025721885034656845\n",
      "epoch: 80, loss: 0.0025439471812142025\n",
      "epoch: 81, loss: 0.0024353429218774555\n",
      "epoch: 82, loss: 0.0023678498640576575\n",
      "epoch: 83, loss: 0.0022282574010869067\n",
      "epoch: 84, loss: 0.0021443525935081796\n",
      "epoch: 85, loss: 0.0019623335657334012\n",
      "epoch: 86, loss: 0.0018000184567589998\n",
      "epoch: 87, loss: 0.0016176189505959437\n",
      "epoch: 88, loss: 0.0013931761278422503\n",
      "epoch: 89, loss: 0.001168598242629956\n",
      "epoch: 90, loss: 0.0009360855331095838\n",
      "epoch: 91, loss: 0.0007262334913319322\n",
      "epoch: 92, loss: 0.0005139304263033523\n",
      "epoch: 93, loss: 0.00031609726515453396\n",
      "epoch: 94, loss: 0.00019368006648256894\n",
      "epoch: 95, loss: 0.00011131078221005103\n",
      "epoch: 96, loss: 5.7756255477995354e-05\n",
      "epoch: 97, loss: 4.8928859722405106e-05\n",
      "epoch: 98, loss: 5.137889627905175e-05\n",
      "epoch: 99, loss: 6.315659477783454e-05\n",
      "5.722509407051198e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ba2dc9c62c499db1f744a1447996b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.08408147940983962\n",
      "epoch: 1, loss: 0.07413200625817244\n",
      "epoch: 2, loss: 0.07136427544672286\n",
      "epoch: 3, loss: 0.06578555845535275\n",
      "epoch: 4, loss: 0.056282911148642215\n",
      "epoch: 5, loss: 0.04567182190918926\n",
      "epoch: 6, loss: 0.036412579849136414\n",
      "epoch: 7, loss: 0.02926508955499073\n",
      "epoch: 8, loss: 0.02529381721688789\n",
      "epoch: 9, loss: 0.02331955267455863\n",
      "epoch: 10, loss: 0.023377489793691884\n",
      "epoch: 11, loss: 0.024035940077145764\n",
      "epoch: 12, loss: 0.02402158849617017\n",
      "epoch: 13, loss: 0.023590363253986793\n",
      "epoch: 14, loss: 0.023145459791411402\n",
      "epoch: 15, loss: 0.023185479765079432\n",
      "epoch: 16, loss: 0.02340042389474609\n",
      "epoch: 17, loss: 0.0231727355810321\n",
      "epoch: 18, loss: 0.0221131742737612\n",
      "epoch: 19, loss: 0.02114937569791745\n",
      "epoch: 20, loss: 0.020099703405119147\n",
      "epoch: 21, loss: 0.01894440148152402\n",
      "epoch: 22, loss: 0.01778782120660192\n",
      "epoch: 23, loss: 0.01673184845344175\n",
      "epoch: 24, loss: 0.015404185177462624\n",
      "epoch: 25, loss: 0.014809571561541182\n",
      "epoch: 26, loss: 0.014552518803951187\n",
      "epoch: 27, loss: 0.013944892747036017\n",
      "epoch: 28, loss: 0.013795916069703033\n",
      "epoch: 29, loss: 0.013155161507915156\n",
      "epoch: 30, loss: 0.012754934518531049\n",
      "epoch: 31, loss: 0.012579562796645771\n",
      "epoch: 32, loss: 0.012265447465026504\n",
      "epoch: 33, loss: 0.011910082694811414\n",
      "epoch: 34, loss: 0.011278469293064107\n",
      "epoch: 35, loss: 0.010750750885480616\n",
      "epoch: 36, loss: 0.010361961262338232\n",
      "epoch: 37, loss: 0.010182575053725775\n",
      "epoch: 38, loss: 0.010057027232487034\n",
      "epoch: 39, loss: 0.01001947581651461\n",
      "epoch: 40, loss: 0.009994563790523124\n",
      "epoch: 41, loss: 0.00969595236669523\n",
      "epoch: 42, loss: 0.009557091801259188\n",
      "epoch: 43, loss: 0.009517888746721286\n",
      "epoch: 44, loss: 0.009400383990163573\n",
      "epoch: 45, loss: 0.009320013254914659\n",
      "epoch: 46, loss: 0.00951846217271363\n",
      "epoch: 47, loss: 0.00954043122332481\n",
      "epoch: 48, loss: 0.00943756373646134\n",
      "epoch: 49, loss: 0.009422541167405317\n",
      "epoch: 50, loss: 0.009366314597886189\n",
      "epoch: 51, loss: 0.00940231915269543\n",
      "epoch: 52, loss: 0.009560337414418519\n",
      "epoch: 53, loss: 0.009620867327365876\n",
      "epoch: 54, loss: 0.009492971738242442\n",
      "epoch: 55, loss: 0.009647360544265564\n",
      "epoch: 56, loss: 0.009373818547609044\n",
      "epoch: 57, loss: 0.009499070760865836\n",
      "epoch: 58, loss: 0.00948831498281393\n",
      "epoch: 59, loss: 0.009388432293283675\n",
      "epoch: 60, loss: 0.009326493196961301\n",
      "epoch: 61, loss: 0.00934065635982707\n",
      "epoch: 62, loss: 0.009308344354322788\n",
      "epoch: 63, loss: 0.009471559990890903\n",
      "epoch: 64, loss: 0.009510407530978288\n",
      "epoch: 65, loss: 0.009326768558138741\n",
      "epoch: 66, loss: 0.009134771031531607\n",
      "epoch: 67, loss: 0.00930354485194861\n",
      "epoch: 68, loss: 0.009419394019180218\n",
      "epoch: 69, loss: 0.009228665446211945\n",
      "epoch: 70, loss: 0.009263285221330913\n",
      "epoch: 71, loss: 0.009284601280519708\n",
      "epoch: 72, loss: 0.009313341408132106\n",
      "epoch: 73, loss: 0.009234600564114853\n",
      "epoch: 74, loss: 0.009321984427949627\n",
      "epoch: 75, loss: 0.009448499999568065\n",
      "epoch: 76, loss: 0.009273368794568247\n",
      "epoch: 77, loss: 0.009240558204419986\n",
      "epoch: 78, loss: 0.00928422359869673\n",
      "epoch: 79, loss: 0.009310057383953949\n",
      "epoch: 80, loss: 0.009365003972882216\n",
      "epoch: 81, loss: 0.009132979218472835\n",
      "epoch: 82, loss: 0.009173071696573307\n",
      "epoch: 83, loss: 0.009307293665414346\n",
      "epoch: 84, loss: 0.009345743056000505\n",
      "epoch: 85, loss: 0.00913840161426752\n",
      "epoch: 86, loss: 0.009225319629252911\n",
      "epoch: 87, loss: 0.00930872554807437\n",
      "epoch: 88, loss: 0.009261601220915171\n",
      "epoch: 89, loss: 0.009284493196778192\n",
      "epoch: 90, loss: 0.009215148478009838\n",
      "epoch: 91, loss: 0.009286662465807808\n",
      "epoch: 92, loss: 0.009186940309036494\n",
      "epoch: 93, loss: 0.0092748023378948\n",
      "epoch: 94, loss: 0.009112030025443519\n",
      "epoch: 95, loss: 0.009266601721623765\n",
      "epoch: 96, loss: 0.009272242459475024\n",
      "epoch: 97, loss: 0.00917801388450548\n",
      "epoch: 98, loss: 0.009067748411645482\n",
      "epoch: 99, loss: 0.009380531021169435\n",
      "0.00918598822524679\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd2bf84500049cc916b6cd385c5681e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.08011645599504766\n",
      "epoch: 1, loss: 0.08014336718875478\n",
      "epoch: 2, loss: 0.07935787845678549\n",
      "epoch: 3, loss: 0.07807768955010472\n",
      "epoch: 4, loss: 0.07681893275422026\n",
      "epoch: 5, loss: 0.07677067653465927\n",
      "epoch: 6, loss: 0.07464385839767308\n",
      "epoch: 7, loss: 0.07155063601271286\n",
      "epoch: 8, loss: 0.06515763748152342\n",
      "epoch: 9, loss: 0.05745304591532841\n",
      "epoch: 10, loss: 0.04809503039936795\n",
      "epoch: 11, loss: 0.04019860959760609\n",
      "epoch: 12, loss: 0.03304263296481841\n",
      "epoch: 13, loss: 0.027981772509075614\n",
      "epoch: 14, loss: 0.02577022233974173\n",
      "epoch: 15, loss: 0.025004215474637236\n",
      "epoch: 16, loss: 0.025342991503219787\n",
      "epoch: 17, loss: 0.025933939158074338\n",
      "epoch: 18, loss: 0.025896414403674402\n",
      "epoch: 19, loss: 0.02473954722251437\n",
      "epoch: 20, loss: 0.023273172666428844\n",
      "epoch: 21, loss: 0.02365461666300797\n",
      "epoch: 22, loss: 0.024281842734839083\n",
      "epoch: 23, loss: 0.023923428267733478\n",
      "epoch: 24, loss: 0.02247282480462841\n",
      "epoch: 25, loss: 0.020922741004237952\n",
      "epoch: 26, loss: 0.02087951141922459\n",
      "epoch: 27, loss: 0.020211062071928756\n",
      "epoch: 28, loss: 0.018796468671693444\n",
      "epoch: 29, loss: 0.017076440473508606\n",
      "epoch: 30, loss: 0.015234802458848838\n",
      "epoch: 31, loss: 0.01424794701780422\n",
      "epoch: 32, loss: 0.012794825183795955\n",
      "epoch: 33, loss: 0.011157905917071144\n",
      "epoch: 34, loss: 0.009590607812398988\n",
      "epoch: 35, loss: 0.008097709447122917\n",
      "epoch: 36, loss: 0.0069903542605788994\n",
      "epoch: 37, loss: 0.006156191153261366\n",
      "epoch: 38, loss: 0.005003102354786505\n",
      "epoch: 39, loss: 0.0042769254520444\n",
      "epoch: 40, loss: 0.00343180322335253\n",
      "epoch: 41, loss: 0.00295167344597238\n",
      "epoch: 42, loss: 0.002322513890994363\n",
      "epoch: 43, loss: 0.0018440061591090962\n",
      "epoch: 44, loss: 0.0014507441435073307\n",
      "epoch: 45, loss: 0.001128484829326797\n",
      "epoch: 46, loss: 0.0008620148994235883\n",
      "epoch: 47, loss: 0.0007684934101590659\n",
      "epoch: 48, loss: 0.0006306838700880374\n",
      "epoch: 49, loss: 0.0005190177435192714\n",
      "epoch: 50, loss: 0.00037256338527715547\n",
      "epoch: 51, loss: 0.0002934412111585279\n",
      "epoch: 52, loss: 0.00016654898171555358\n",
      "epoch: 53, loss: 0.00015413682271368188\n",
      "epoch: 54, loss: 0.00015612824659038627\n",
      "epoch: 55, loss: 0.0001442145849861671\n",
      "epoch: 56, loss: 0.00011662165973155302\n",
      "epoch: 57, loss: 8.156523913953778e-05\n",
      "epoch: 58, loss: 8.572938464996079e-05\n",
      "epoch: 59, loss: 9.732377174666332e-05\n",
      "epoch: 60, loss: 8.919710955367508e-05\n",
      "epoch: 61, loss: 6.400874566969495e-05\n",
      "epoch: 62, loss: 5.3975062743234074e-05\n",
      "epoch: 63, loss: 5.180204279586451e-05\n",
      "epoch: 64, loss: 6.448817717627678e-05\n",
      "epoch: 65, loss: 7.23344223878709e-05\n",
      "epoch: 66, loss: 5.493348009967441e-05\n",
      "epoch: 67, loss: 3.80009219237294e-05\n",
      "epoch: 68, loss: 3.86211587075944e-05\n",
      "epoch: 69, loss: 3.105824252844568e-05\n",
      "epoch: 70, loss: 4.741934894705217e-05\n",
      "epoch: 71, loss: 3.897745794902533e-05\n",
      "epoch: 72, loss: 2.350316516195858e-05\n",
      "epoch: 73, loss: 2.4476960143494652e-05\n",
      "epoch: 74, loss: 2.9100360954090885e-05\n",
      "epoch: 75, loss: 3.499823952975945e-05\n",
      "epoch: 76, loss: 2.8470734995729203e-05\n",
      "epoch: 77, loss: 2.940533965495373e-05\n",
      "epoch: 78, loss: 2.620666564938408e-05\n",
      "epoch: 79, loss: 2.80768446802192e-05\n",
      "epoch: 80, loss: 2.2435871729401752e-05\n",
      "epoch: 81, loss: 2.2520097162949867e-05\n",
      "epoch: 82, loss: 2.552313869048774e-05\n",
      "epoch: 83, loss: 2.5546706252241885e-05\n",
      "epoch: 84, loss: 2.844165920437442e-05\n",
      "epoch: 85, loss: 2.7767530771727876e-05\n",
      "epoch: 86, loss: 2.7440214239490116e-05\n",
      "epoch: 87, loss: 2.261868021072308e-05\n",
      "epoch: 88, loss: 2.0066952116506537e-05\n",
      "epoch: 89, loss: 2.2817358363784118e-05\n",
      "epoch: 90, loss: 2.2566979082240545e-05\n",
      "epoch: 91, loss: 1.6266627746763984e-05\n",
      "epoch: 92, loss: 1.5251344627601743e-05\n",
      "epoch: 93, loss: 2.1927204652217846e-05\n",
      "epoch: 94, loss: 1.849973591904698e-05\n",
      "epoch: 95, loss: 2.2348275204784017e-05\n",
      "epoch: 96, loss: 1.72274127735669e-05\n",
      "epoch: 97, loss: 2.1630922734543397e-05\n",
      "epoch: 98, loss: 1.856660927898441e-05\n",
      "epoch: 99, loss: 2.2832564272792758e-05\n",
      "1.5966639863756973e-05\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "model_list = []\n",
    "for i in tqdm(range(5)):\n",
    "    optimizer = Adam(lr=0.1)\n",
    "    model = RegularizedModel(n_features=n_features, \n",
    "                             n_targets=1, \n",
    "                             reps=2,\n",
    "                             alpha=0.00,\n",
    "                             backend=backend, \n",
    "                             shots=10000, \n",
    "                             optimizer=optimizer)\n",
    "    \n",
    "    model.train(x_train, y_train, epochs=epochs, verbose=True) \n",
    "    model_list.append(model)\n",
    "    print(model.loss[-1])\n",
    "\n",
    "saver(model_list, data_path(\"sparse_reg_model_no_penalty\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6013897b0b2845d0985057431904d999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea4416c3d4d4965a90a97f225466aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.0912111809862965\n",
      "epoch: 1, loss: 0.0736207689582723\n",
      "epoch: 2, loss: 0.07270909046177425\n",
      "epoch: 3, loss: 0.07194822105512512\n",
      "epoch: 4, loss: 0.06815248917462827\n",
      "epoch: 5, loss: 0.06294284469467866\n",
      "epoch: 6, loss: 0.05720395906901414\n",
      "epoch: 7, loss: 0.051666950725747104\n",
      "epoch: 8, loss: 0.046848182464445776\n",
      "epoch: 9, loss: 0.041960730025917325\n",
      "epoch: 10, loss: 0.03815544879078301\n",
      "epoch: 11, loss: 0.036436188634337355\n",
      "epoch: 12, loss: 0.03437704302116006\n",
      "epoch: 13, loss: 0.03283523146909727\n",
      "epoch: 14, loss: 0.03022467866415468\n",
      "epoch: 15, loss: 0.028812512708924223\n",
      "epoch: 16, loss: 0.02762698230303138\n",
      "epoch: 17, loss: 0.025818157636144402\n",
      "epoch: 18, loss: 0.02470180729315303\n",
      "epoch: 19, loss: 0.023437685861888834\n",
      "epoch: 20, loss: 0.02289734933122251\n",
      "epoch: 21, loss: 0.022615581568303136\n",
      "epoch: 22, loss: 0.022485885888361007\n",
      "epoch: 23, loss: 0.021904360122739476\n",
      "epoch: 24, loss: 0.021622181110506844\n",
      "epoch: 25, loss: 0.021439750463868718\n",
      "epoch: 26, loss: 0.0209147956199401\n",
      "epoch: 27, loss: 0.020239125264120826\n",
      "epoch: 28, loss: 0.01949224522784307\n",
      "epoch: 29, loss: 0.018656054956364652\n",
      "epoch: 30, loss: 0.018302643819236564\n",
      "epoch: 31, loss: 0.018067878654281843\n",
      "epoch: 32, loss: 0.017989034364903962\n",
      "epoch: 33, loss: 0.0171756549676204\n",
      "epoch: 34, loss: 0.016765284313275716\n",
      "epoch: 35, loss: 0.015790994395979183\n",
      "epoch: 36, loss: 0.01504660490431219\n",
      "epoch: 37, loss: 0.014371085026408407\n",
      "epoch: 38, loss: 0.013324099456463305\n",
      "epoch: 39, loss: 0.012610675891990785\n",
      "epoch: 40, loss: 0.011816113570100342\n",
      "epoch: 41, loss: 0.010808862489852663\n",
      "epoch: 42, loss: 0.009600776396702615\n",
      "epoch: 43, loss: 0.008482547905930593\n",
      "epoch: 44, loss: 0.007231024686827415\n",
      "epoch: 45, loss: 0.006002694799532392\n",
      "epoch: 46, loss: 0.00499891451332505\n",
      "epoch: 47, loss: 0.004011701242383833\n",
      "epoch: 48, loss: 0.002976714896515452\n",
      "epoch: 49, loss: 0.002059616527193874\n",
      "epoch: 50, loss: 0.0013321105181232343\n",
      "epoch: 51, loss: 0.0009203675040755189\n",
      "epoch: 52, loss: 0.0007937428229569525\n",
      "epoch: 53, loss: 0.0005570862843719674\n",
      "epoch: 54, loss: 0.0003522053976599846\n",
      "epoch: 55, loss: 0.0001997535340977593\n",
      "epoch: 56, loss: 0.00017989293966286877\n",
      "epoch: 57, loss: 0.00014660670829131872\n",
      "epoch: 58, loss: 0.00010899686789159591\n",
      "epoch: 59, loss: 4.108958965800184e-05\n",
      "epoch: 60, loss: 4.1358978945364394e-05\n",
      "epoch: 61, loss: 6.80106603145373e-05\n",
      "epoch: 62, loss: 9.380302437468861e-05\n",
      "epoch: 63, loss: 9.218258023141723e-05\n",
      "epoch: 64, loss: 0.00010845712707480205\n",
      "epoch: 65, loss: 0.00012240816395975139\n",
      "epoch: 66, loss: 0.00016531988719488535\n",
      "epoch: 67, loss: 0.00021502191137517417\n",
      "epoch: 68, loss: 0.00018211005969943022\n",
      "epoch: 69, loss: 0.00019168097548697056\n",
      "epoch: 70, loss: 0.00019369890232408574\n",
      "epoch: 71, loss: 0.00022442865150038087\n",
      "epoch: 72, loss: 0.00022309654574776647\n",
      "epoch: 73, loss: 0.00018344342484649532\n",
      "epoch: 74, loss: 0.00019069209771398264\n",
      "epoch: 75, loss: 0.00018533224185204262\n",
      "epoch: 76, loss: 0.00015595433877445104\n",
      "epoch: 77, loss: 0.00014054563752539378\n",
      "epoch: 78, loss: 0.0001342039231908028\n",
      "epoch: 79, loss: 0.00012411346767252936\n",
      "epoch: 80, loss: 0.00012125284241344592\n",
      "epoch: 81, loss: 0.00012616286349229164\n",
      "epoch: 82, loss: 0.00011145843543235234\n",
      "epoch: 83, loss: 0.0001243040352601931\n",
      "epoch: 84, loss: 0.00012602877466493992\n",
      "epoch: 85, loss: 0.00010841650039921149\n",
      "epoch: 86, loss: 0.00010491451937424701\n",
      "epoch: 87, loss: 9.485225000177856e-05\n",
      "epoch: 88, loss: 0.00010512998712341226\n",
      "epoch: 89, loss: 0.00010785098608769871\n",
      "epoch: 90, loss: 9.469470516515179e-05\n",
      "epoch: 91, loss: 9.199448745238168e-05\n",
      "epoch: 92, loss: 8.183606910134785e-05\n",
      "epoch: 93, loss: 7.776768372402805e-05\n",
      "epoch: 94, loss: 9.566351647303926e-05\n",
      "epoch: 95, loss: 8.432069891195425e-05\n",
      "epoch: 96, loss: 9.830755356410056e-05\n",
      "epoch: 97, loss: 8.007901328182456e-05\n",
      "epoch: 98, loss: 7.534229500971307e-05\n",
      "epoch: 99, loss: 7.639834870172184e-05\n",
      "8.926723530605627e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dbb020720c74aabaa67a91c648178cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.07801883071123084\n",
      "epoch: 1, loss: 0.07969688101738953\n",
      "epoch: 2, loss: 0.07801790151658698\n",
      "epoch: 3, loss: 0.07836712479732359\n",
      "epoch: 4, loss: 0.07810029950533587\n",
      "epoch: 5, loss: 0.0784370544343546\n",
      "epoch: 6, loss: 0.0771768162876865\n",
      "epoch: 7, loss: 0.07557907225636006\n",
      "epoch: 8, loss: 0.07309882593787094\n",
      "epoch: 9, loss: 0.0687861336627529\n",
      "epoch: 10, loss: 0.061601913619995355\n",
      "epoch: 11, loss: 0.05330773495973371\n",
      "epoch: 12, loss: 0.04388221159514983\n",
      "epoch: 13, loss: 0.03429018556098216\n",
      "epoch: 14, loss: 0.02806542896036278\n",
      "epoch: 15, loss: 0.025010583611541386\n",
      "epoch: 16, loss: 0.023584784321567492\n",
      "epoch: 17, loss: 0.024343246147641037\n",
      "epoch: 18, loss: 0.024472703517924976\n",
      "epoch: 19, loss: 0.023512695428409357\n",
      "epoch: 20, loss: 0.02317100807525331\n",
      "epoch: 21, loss: 0.024647568071516184\n",
      "epoch: 22, loss: 0.024282050625837923\n",
      "epoch: 23, loss: 0.02307259936408263\n",
      "epoch: 24, loss: 0.021519856248981336\n",
      "epoch: 25, loss: 0.020732415610910195\n",
      "epoch: 26, loss: 0.020233680213818946\n",
      "epoch: 27, loss: 0.019139987773608112\n",
      "epoch: 28, loss: 0.018305722692091214\n",
      "epoch: 29, loss: 0.017361972523130712\n",
      "epoch: 30, loss: 0.016335441064951536\n",
      "epoch: 31, loss: 0.014596024042823284\n",
      "epoch: 32, loss: 0.012681076002605969\n",
      "epoch: 33, loss: 0.010384748919919931\n",
      "epoch: 34, loss: 0.008699274423710619\n",
      "epoch: 35, loss: 0.007413847680556596\n",
      "epoch: 36, loss: 0.005755341082733088\n",
      "epoch: 37, loss: 0.004313407837855177\n",
      "epoch: 38, loss: 0.0032175292614710417\n",
      "epoch: 39, loss: 0.0025522582261990967\n",
      "epoch: 40, loss: 0.0019719197435566676\n",
      "epoch: 41, loss: 0.0014751422659257897\n",
      "epoch: 42, loss: 0.0010386352312403396\n",
      "epoch: 43, loss: 0.00079462384658793\n",
      "epoch: 44, loss: 0.0005929398862065716\n",
      "epoch: 45, loss: 0.00045923381693930995\n",
      "epoch: 46, loss: 0.0003382659251682181\n",
      "epoch: 47, loss: 0.00027636834809568024\n",
      "epoch: 48, loss: 0.0002159039968354641\n",
      "epoch: 49, loss: 0.0001923526529213936\n",
      "epoch: 50, loss: 0.00018377369752612912\n",
      "epoch: 51, loss: 0.00015142779399433663\n",
      "epoch: 52, loss: 0.00016952418628823316\n",
      "epoch: 53, loss: 0.00014704805312744718\n",
      "epoch: 54, loss: 0.00015712447234847535\n",
      "epoch: 55, loss: 0.00016775463348335352\n",
      "epoch: 56, loss: 0.0001733371348838724\n",
      "epoch: 57, loss: 0.0001618397331107457\n",
      "epoch: 58, loss: 0.00014067599432170875\n",
      "epoch: 59, loss: 0.0001379723934300436\n",
      "epoch: 60, loss: 0.0001435163679322622\n",
      "epoch: 61, loss: 0.00012632298689919336\n",
      "epoch: 62, loss: 0.0001264450649621812\n",
      "epoch: 63, loss: 0.00013319587654713182\n",
      "epoch: 64, loss: 0.00012270925606417584\n",
      "epoch: 65, loss: 0.00013371167065342267\n",
      "epoch: 66, loss: 0.00012141924483777273\n",
      "epoch: 67, loss: 0.00013033581147928045\n",
      "epoch: 68, loss: 0.00013364976908566194\n",
      "epoch: 69, loss: 0.0001353728573462767\n",
      "epoch: 70, loss: 0.00013002323432937486\n",
      "epoch: 71, loss: 0.00014218956776609673\n",
      "epoch: 72, loss: 0.00013488531672733528\n",
      "epoch: 73, loss: 0.00013811385983959117\n",
      "epoch: 74, loss: 0.00013858057022151185\n",
      "epoch: 75, loss: 0.0001385024448106545\n",
      "epoch: 76, loss: 0.00013763885702323806\n",
      "epoch: 77, loss: 0.00014832449516633393\n",
      "epoch: 78, loss: 0.0001358958878820713\n",
      "epoch: 79, loss: 0.0001337273953778504\n",
      "epoch: 80, loss: 0.00016097375148926192\n",
      "epoch: 81, loss: 0.00014449227858481898\n",
      "epoch: 82, loss: 0.00015517502553310042\n",
      "epoch: 83, loss: 0.0001487763206976753\n",
      "epoch: 84, loss: 0.00012146218891305107\n",
      "epoch: 85, loss: 0.00015399485433278634\n",
      "epoch: 86, loss: 0.00013437240606198195\n",
      "epoch: 87, loss: 0.00015174021760364683\n",
      "epoch: 88, loss: 0.00015378891570351301\n",
      "epoch: 89, loss: 0.0001564544763453587\n",
      "epoch: 90, loss: 0.000147669075549194\n",
      "epoch: 91, loss: 0.00014926325724094974\n",
      "epoch: 92, loss: 0.00013569098905558108\n",
      "epoch: 93, loss: 0.00012282636548809127\n",
      "epoch: 94, loss: 0.00013082729219331455\n",
      "epoch: 95, loss: 0.00014487697098926515\n",
      "epoch: 96, loss: 0.00012666176038725758\n",
      "epoch: 97, loss: 0.00011728695279632967\n",
      "epoch: 98, loss: 0.00011288542894979596\n",
      "epoch: 99, loss: 9.635070476362747e-05\n",
      "9.66414774507789e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c8ee9af01c42a4acf539443bf4b8ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.07788342382714773\n",
      "epoch: 1, loss: 0.07859366314037336\n",
      "epoch: 2, loss: 0.0776270702161868\n",
      "epoch: 3, loss: 0.07430525522563305\n",
      "epoch: 4, loss: 0.06903320951139345\n",
      "epoch: 5, loss: 0.06125133012348804\n",
      "epoch: 6, loss: 0.05232205288962175\n",
      "epoch: 7, loss: 0.04206238321744569\n",
      "epoch: 8, loss: 0.034137033507541215\n",
      "epoch: 9, loss: 0.027744431759097972\n",
      "epoch: 10, loss: 0.024810006466561254\n",
      "epoch: 11, loss: 0.02315493933893976\n",
      "epoch: 12, loss: 0.02334593687566978\n",
      "epoch: 13, loss: 0.02365859178627828\n",
      "epoch: 14, loss: 0.023920854989017828\n",
      "epoch: 15, loss: 0.023676053765957848\n",
      "epoch: 16, loss: 0.022635114945966272\n",
      "epoch: 17, loss: 0.021887025593406984\n",
      "epoch: 18, loss: 0.02050936965958566\n",
      "epoch: 19, loss: 0.01934279107245255\n",
      "epoch: 20, loss: 0.01778681010278033\n",
      "epoch: 21, loss: 0.016531539962411315\n",
      "epoch: 22, loss: 0.015053194289602816\n",
      "epoch: 23, loss: 0.013695216260011224\n",
      "epoch: 24, loss: 0.012004363127650882\n",
      "epoch: 25, loss: 0.010969857050999144\n",
      "epoch: 26, loss: 0.010004943544518793\n",
      "epoch: 27, loss: 0.008720378660202872\n",
      "epoch: 28, loss: 0.0074877892216089655\n",
      "epoch: 29, loss: 0.00659065445515598\n",
      "epoch: 30, loss: 0.00586276748835015\n",
      "epoch: 31, loss: 0.0049944662708758\n",
      "epoch: 32, loss: 0.004346164939514438\n",
      "epoch: 33, loss: 0.003532568402593052\n",
      "epoch: 34, loss: 0.003121164688665119\n",
      "epoch: 35, loss: 0.0025285882519978813\n",
      "epoch: 36, loss: 0.002017927160368495\n",
      "epoch: 37, loss: 0.0016115517989717656\n",
      "epoch: 38, loss: 0.0013114494663471873\n",
      "epoch: 39, loss: 0.0009278576273287501\n",
      "epoch: 40, loss: 0.0006662349163919203\n",
      "epoch: 41, loss: 0.00045468321018512164\n",
      "epoch: 42, loss: 0.0003355093104461072\n",
      "epoch: 43, loss: 0.0002862154668479683\n",
      "epoch: 44, loss: 0.00027176021550502584\n",
      "epoch: 45, loss: 0.0002760488101750817\n",
      "epoch: 46, loss: 0.0002905268597239078\n",
      "epoch: 47, loss: 0.00035212477418516594\n",
      "epoch: 48, loss: 0.0003913501866569723\n",
      "epoch: 49, loss: 0.0003751304475129598\n",
      "epoch: 50, loss: 0.00040827742258690624\n",
      "epoch: 51, loss: 0.000371138758996792\n",
      "epoch: 52, loss: 0.00037412177149962145\n",
      "epoch: 53, loss: 0.0003242226261005824\n",
      "epoch: 54, loss: 0.00031289521365407397\n",
      "epoch: 55, loss: 0.00024929117037809706\n",
      "epoch: 56, loss: 0.00021591802009790219\n",
      "epoch: 57, loss: 0.00016834841585610622\n",
      "epoch: 58, loss: 0.0001369212515624865\n",
      "epoch: 59, loss: 9.645814223924423e-05\n",
      "epoch: 60, loss: 0.00010556691617282437\n",
      "epoch: 61, loss: 0.00011724058421799693\n",
      "epoch: 62, loss: 0.0001314129119727507\n",
      "epoch: 63, loss: 0.00015259068940961832\n",
      "epoch: 64, loss: 0.00016128444571532523\n",
      "epoch: 65, loss: 0.0001833384170338793\n",
      "epoch: 66, loss: 0.00020657173179026024\n",
      "epoch: 67, loss: 0.00021423376350072177\n",
      "epoch: 68, loss: 0.00023599997224907427\n",
      "epoch: 69, loss: 0.0002503019601643996\n",
      "epoch: 70, loss: 0.0002722456197670066\n",
      "epoch: 71, loss: 0.00024984559945254484\n",
      "epoch: 72, loss: 0.00025152238909081215\n",
      "epoch: 73, loss: 0.00026837894061076066\n",
      "epoch: 74, loss: 0.00027809972696628515\n",
      "epoch: 75, loss: 0.0002792655307626875\n",
      "epoch: 76, loss: 0.0002825168553290719\n",
      "epoch: 77, loss: 0.0002619835399878282\n",
      "epoch: 78, loss: 0.0002601955987206277\n",
      "epoch: 79, loss: 0.0002777755490045381\n",
      "epoch: 80, loss: 0.00031762642945024815\n",
      "epoch: 81, loss: 0.00026986779584236203\n",
      "epoch: 82, loss: 0.00025594862404154016\n",
      "epoch: 83, loss: 0.00026488642365412376\n",
      "epoch: 84, loss: 0.00028091051554642716\n",
      "epoch: 85, loss: 0.0002754016447603592\n",
      "epoch: 86, loss: 0.00025493919093856913\n",
      "epoch: 87, loss: 0.0002650389390243199\n",
      "epoch: 88, loss: 0.00024791355371508024\n",
      "epoch: 89, loss: 0.00025581602977553324\n",
      "epoch: 90, loss: 0.00023914321153171438\n",
      "epoch: 91, loss: 0.0002298927964961328\n",
      "epoch: 92, loss: 0.00022096577616451045\n",
      "epoch: 93, loss: 0.00022437056176389524\n",
      "epoch: 94, loss: 0.00022228963043362154\n",
      "epoch: 95, loss: 0.0001943641194760675\n",
      "epoch: 96, loss: 0.00021317696066696707\n",
      "epoch: 97, loss: 0.00019173373551413292\n",
      "epoch: 98, loss: 0.00019591631863347673\n",
      "epoch: 99, loss: 0.00021864360014456976\n",
      "0.000183182694395813\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93934d93072546108fc9973eb92db66d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.08413782933919756\n",
      "epoch: 1, loss: 0.07370087779587146\n",
      "epoch: 2, loss: 0.07080879778600453\n",
      "epoch: 3, loss: 0.06514399239428584\n",
      "epoch: 4, loss: 0.05527034348655549\n",
      "epoch: 5, loss: 0.04510897599755755\n",
      "epoch: 6, loss: 0.037078715774539445\n",
      "epoch: 7, loss: 0.02980741297446123\n",
      "epoch: 8, loss: 0.025165516748476783\n",
      "epoch: 9, loss: 0.02320349751316677\n",
      "epoch: 10, loss: 0.023267934692269385\n",
      "epoch: 11, loss: 0.02377337002954813\n",
      "epoch: 12, loss: 0.024576587574536752\n",
      "epoch: 13, loss: 0.02463562334108752\n",
      "epoch: 14, loss: 0.02465308471434887\n",
      "epoch: 15, loss: 0.024775996804107324\n",
      "epoch: 16, loss: 0.02498580523768531\n",
      "epoch: 17, loss: 0.025165963533120946\n",
      "epoch: 18, loss: 0.02443753481035102\n",
      "epoch: 19, loss: 0.023976322074991323\n",
      "epoch: 20, loss: 0.023850429740219607\n",
      "epoch: 21, loss: 0.02359836237929438\n",
      "epoch: 22, loss: 0.023218765701409145\n",
      "epoch: 23, loss: 0.022946943553071048\n",
      "epoch: 24, loss: 0.0223994124012513\n",
      "epoch: 25, loss: 0.022022224576726396\n",
      "epoch: 26, loss: 0.021649326140072422\n",
      "epoch: 27, loss: 0.02108828225572338\n",
      "epoch: 28, loss: 0.020665406490102366\n",
      "epoch: 29, loss: 0.02011006159758119\n",
      "epoch: 30, loss: 0.019160898784328514\n",
      "epoch: 31, loss: 0.01873218052499507\n",
      "epoch: 32, loss: 0.01786754495599008\n",
      "epoch: 33, loss: 0.017544541711961823\n",
      "epoch: 34, loss: 0.01726918190018718\n",
      "epoch: 35, loss: 0.016951882591598372\n",
      "epoch: 36, loss: 0.016520071193579542\n",
      "epoch: 37, loss: 0.01624491147590568\n",
      "epoch: 38, loss: 0.01607999038429708\n",
      "epoch: 39, loss: 0.015585134507891753\n",
      "epoch: 40, loss: 0.015075481498488384\n",
      "epoch: 41, loss: 0.014539320494757051\n",
      "epoch: 42, loss: 0.014175125475291279\n",
      "epoch: 43, loss: 0.013554160005189745\n",
      "epoch: 44, loss: 0.013359129224299866\n",
      "epoch: 45, loss: 0.013065240414225512\n",
      "epoch: 46, loss: 0.012519427297312926\n",
      "epoch: 47, loss: 0.012437178635154969\n",
      "epoch: 48, loss: 0.012182529661718284\n",
      "epoch: 49, loss: 0.01184837577688951\n",
      "epoch: 50, loss: 0.011442750224846714\n",
      "epoch: 51, loss: 0.011315628867591323\n",
      "epoch: 52, loss: 0.011119669197031617\n",
      "epoch: 53, loss: 0.01087409378721445\n",
      "epoch: 54, loss: 0.01047606386057556\n",
      "epoch: 55, loss: 0.010478036190471895\n",
      "epoch: 56, loss: 0.010391953255106175\n",
      "epoch: 57, loss: 0.010250381955043669\n",
      "epoch: 58, loss: 0.01032325009772704\n",
      "epoch: 59, loss: 0.010020917065676961\n",
      "epoch: 60, loss: 0.009767350298236235\n",
      "epoch: 61, loss: 0.009703711997284401\n",
      "epoch: 62, loss: 0.009697136755764831\n",
      "epoch: 63, loss: 0.009641445336423145\n",
      "epoch: 64, loss: 0.009653849354878716\n",
      "epoch: 65, loss: 0.009575055141115583\n",
      "epoch: 66, loss: 0.009498419312529913\n",
      "epoch: 67, loss: 0.009455397405579763\n",
      "epoch: 68, loss: 0.0094802553460554\n",
      "epoch: 69, loss: 0.009617954783773279\n",
      "epoch: 70, loss: 0.009456812860946606\n",
      "epoch: 71, loss: 0.009666041804396364\n",
      "epoch: 72, loss: 0.009428574166031567\n",
      "epoch: 73, loss: 0.009486017323159375\n",
      "epoch: 74, loss: 0.009509222619536793\n",
      "epoch: 75, loss: 0.009347795898027665\n",
      "epoch: 76, loss: 0.009561624588311503\n",
      "epoch: 77, loss: 0.009508224537548628\n",
      "epoch: 78, loss: 0.009373119759113598\n",
      "epoch: 79, loss: 0.0094119021428848\n",
      "epoch: 80, loss: 0.009340728567638342\n",
      "epoch: 81, loss: 0.009479916250312415\n",
      "epoch: 82, loss: 0.009379865011648628\n",
      "epoch: 83, loss: 0.009509391884677415\n",
      "epoch: 84, loss: 0.009353547950241287\n",
      "epoch: 85, loss: 0.009455886519175448\n",
      "epoch: 86, loss: 0.009436090018411902\n",
      "epoch: 87, loss: 0.009484343655068879\n",
      "epoch: 88, loss: 0.009533794819051646\n",
      "epoch: 89, loss: 0.00947116079486664\n",
      "epoch: 90, loss: 0.00939916268739483\n",
      "epoch: 91, loss: 0.00956473937075223\n",
      "epoch: 92, loss: 0.009510601834012354\n",
      "epoch: 93, loss: 0.009644943989710804\n",
      "epoch: 94, loss: 0.009572146895326532\n",
      "epoch: 95, loss: 0.009561113642217239\n",
      "epoch: 96, loss: 0.009389560238871423\n",
      "epoch: 97, loss: 0.0094716143101802\n",
      "epoch: 98, loss: 0.009705607799099304\n",
      "epoch: 99, loss: 0.009623156461987194\n",
      "0.009616645888096402\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf7b834b16d4fc19c43e6736c8f0eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.07952015766715566\n",
      "epoch: 1, loss: 0.07966027421085005\n",
      "epoch: 2, loss: 0.07859029930408797\n",
      "epoch: 3, loss: 0.07768706285747237\n",
      "epoch: 4, loss: 0.07723647242639121\n",
      "epoch: 5, loss: 0.07620496109677653\n",
      "epoch: 6, loss: 0.07545790154602078\n",
      "epoch: 7, loss: 0.07173567409677782\n",
      "epoch: 8, loss: 0.06616428004069552\n",
      "epoch: 9, loss: 0.058751247124333016\n",
      "epoch: 10, loss: 0.05058402060049065\n",
      "epoch: 11, loss: 0.041538733162568856\n",
      "epoch: 12, loss: 0.03430282919585444\n",
      "epoch: 13, loss: 0.029235764002144338\n",
      "epoch: 14, loss: 0.026187810294410845\n",
      "epoch: 15, loss: 0.02486130611097334\n",
      "epoch: 16, loss: 0.024676980161625638\n",
      "epoch: 17, loss: 0.025279860992129744\n",
      "epoch: 18, loss: 0.025040150356834406\n",
      "epoch: 19, loss: 0.024204280189545516\n",
      "epoch: 20, loss: 0.022696489640032253\n",
      "epoch: 21, loss: 0.022052128127944815\n",
      "epoch: 22, loss: 0.022773438810359745\n",
      "epoch: 23, loss: 0.022110027990737056\n",
      "epoch: 24, loss: 0.020229044636223485\n",
      "epoch: 25, loss: 0.018455034514237065\n",
      "epoch: 26, loss: 0.017721304646991117\n",
      "epoch: 27, loss: 0.016884803034459092\n",
      "epoch: 28, loss: 0.015207683890357664\n",
      "epoch: 29, loss: 0.013750783061894\n",
      "epoch: 30, loss: 0.01293634015147665\n",
      "epoch: 31, loss: 0.01275298019151448\n",
      "epoch: 32, loss: 0.011453277817362334\n",
      "epoch: 33, loss: 0.010121260967063818\n",
      "epoch: 34, loss: 0.009102084415806051\n",
      "epoch: 35, loss: 0.00831586587790661\n",
      "epoch: 36, loss: 0.007517660953895714\n",
      "epoch: 37, loss: 0.00640132092687097\n",
      "epoch: 38, loss: 0.005210132715348135\n",
      "epoch: 39, loss: 0.004440410286125449\n",
      "epoch: 40, loss: 0.0035732590097439605\n",
      "epoch: 41, loss: 0.0029171887675423476\n",
      "epoch: 42, loss: 0.002349142943663906\n",
      "epoch: 43, loss: 0.001950123995291817\n",
      "epoch: 44, loss: 0.0016463427613369042\n",
      "epoch: 45, loss: 0.0014785968581228284\n",
      "epoch: 46, loss: 0.0013279340579210696\n",
      "epoch: 47, loss: 0.001123493787659173\n",
      "epoch: 48, loss: 0.0010275045507099042\n",
      "epoch: 49, loss: 0.0009126990358764854\n",
      "epoch: 50, loss: 0.0007578437770976319\n",
      "epoch: 51, loss: 0.0006712355986599877\n",
      "epoch: 52, loss: 0.0005773721490964432\n",
      "epoch: 53, loss: 0.0005107362808575724\n",
      "epoch: 54, loss: 0.0004435000427598472\n",
      "epoch: 55, loss: 0.0004124452720842835\n",
      "epoch: 56, loss: 0.00036597079856698697\n",
      "epoch: 57, loss: 0.0002843852163820125\n",
      "epoch: 58, loss: 0.0002490916303022988\n",
      "epoch: 59, loss: 0.00024136684368083298\n",
      "epoch: 60, loss: 0.00021553958018829316\n",
      "epoch: 61, loss: 0.00019332777448750557\n",
      "epoch: 62, loss: 0.00015526762202333047\n",
      "epoch: 63, loss: 0.00016739972295799703\n",
      "epoch: 64, loss: 0.00013686624899211428\n",
      "epoch: 65, loss: 0.00015183641262751888\n",
      "epoch: 66, loss: 0.0001262000137828131\n",
      "epoch: 67, loss: 0.0001196495057983534\n",
      "epoch: 68, loss: 0.0001341999007042143\n",
      "epoch: 69, loss: 0.00012191844363177962\n",
      "epoch: 70, loss: 0.00010511790209107121\n",
      "epoch: 71, loss: 0.00010891397877281153\n",
      "epoch: 72, loss: 0.00013478115636299622\n",
      "epoch: 73, loss: 0.00011790956887194831\n",
      "epoch: 74, loss: 0.00012568544634428234\n",
      "epoch: 75, loss: 0.00013491442590044938\n",
      "epoch: 76, loss: 0.00015835781915569936\n",
      "epoch: 77, loss: 0.00016052103595866278\n",
      "epoch: 78, loss: 0.00016455657801854777\n",
      "epoch: 79, loss: 0.00017816231440866893\n",
      "epoch: 80, loss: 0.00019718117631570503\n",
      "epoch: 81, loss: 0.00020344101171623712\n",
      "epoch: 82, loss: 0.00022255975131769525\n",
      "epoch: 83, loss: 0.00021823989926241912\n",
      "epoch: 84, loss: 0.00024601832106539755\n",
      "epoch: 85, loss: 0.00024938043447070166\n",
      "epoch: 86, loss: 0.00027439839609455437\n",
      "epoch: 87, loss: 0.00031198454850126016\n",
      "epoch: 88, loss: 0.0002748944813836599\n",
      "epoch: 89, loss: 0.0003002995452987342\n",
      "epoch: 90, loss: 0.0003001262097709117\n",
      "epoch: 91, loss: 0.00032494613984914935\n",
      "epoch: 92, loss: 0.0003183790838008575\n",
      "epoch: 93, loss: 0.00031995592008379065\n",
      "epoch: 94, loss: 0.0003292323571506062\n",
      "epoch: 95, loss: 0.0003268907534972237\n",
      "epoch: 96, loss: 0.00033653794484672607\n",
      "epoch: 97, loss: 0.0003157269761306865\n",
      "epoch: 98, loss: 0.0003541175586968187\n",
      "epoch: 99, loss: 0.00030861425538716836\n",
      "0.00033924403597878646\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "model_list = []\n",
    "for i in tqdm(range(5)):\n",
    "    optimizer = Adam(lr=0.1)\n",
    "    model = RegularizedModel(n_features=n_features, \n",
    "                             n_targets=1, \n",
    "                             reps=2,\n",
    "                             alpha=0.01,\n",
    "                             backend=backend, \n",
    "                             shots=10000, \n",
    "                             optimizer=optimizer)\n",
    "    \n",
    "    model.train(x_train, y_train, epochs=epochs, verbose=True) \n",
    "    model_list.append(model)\n",
    "    print(model.loss[-1])\n",
    "\n",
    "saver(model_list, data_path(\"sparse_reg_model_low_penalty\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No-Regularized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbd0c0b18fa144d38899f47d133717a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f77a41971c9b4069962c7e5f0dafb9fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.10211732280895763\n",
      "epoch: 1, loss: 0.09183818569966797\n",
      "epoch: 2, loss: 0.0868851096325999\n",
      "epoch: 3, loss: 0.08326088738501085\n",
      "epoch: 4, loss: 0.08189231057026441\n",
      "epoch: 5, loss: 0.07987453197541204\n",
      "epoch: 6, loss: 0.07821337210679151\n",
      "epoch: 7, loss: 0.07736914646216435\n",
      "epoch: 8, loss: 0.0768827270114978\n",
      "epoch: 9, loss: 0.07630719012933743\n",
      "epoch: 10, loss: 0.07589670648474041\n",
      "epoch: 11, loss: 0.07423415561679562\n",
      "epoch: 12, loss: 0.07268630096325174\n",
      "epoch: 13, loss: 0.06984031799367191\n",
      "epoch: 14, loss: 0.06620846399253966\n",
      "epoch: 15, loss: 0.0616987979463965\n",
      "epoch: 16, loss: 0.0566351863829571\n",
      "epoch: 17, loss: 0.04936988377876094\n",
      "epoch: 18, loss: 0.04288857138643023\n",
      "epoch: 19, loss: 0.03627198322260481\n",
      "epoch: 20, loss: 0.031914371706206424\n",
      "epoch: 21, loss: 0.029525483446038666\n",
      "epoch: 22, loss: 0.028624862778655735\n",
      "epoch: 23, loss: 0.0284355053458452\n",
      "epoch: 24, loss: 0.028025898331686946\n",
      "epoch: 25, loss: 0.02683070973565359\n",
      "epoch: 26, loss: 0.025566075550554315\n",
      "epoch: 27, loss: 0.024907866460965006\n",
      "epoch: 28, loss: 0.02565282865283649\n",
      "epoch: 29, loss: 0.026776553066625578\n",
      "epoch: 30, loss: 0.027238274061412292\n",
      "epoch: 31, loss: 0.02687026412108812\n",
      "epoch: 32, loss: 0.025974971420639422\n",
      "epoch: 33, loss: 0.024826551496557273\n",
      "epoch: 34, loss: 0.02418225496663345\n",
      "epoch: 35, loss: 0.023371148683421765\n",
      "epoch: 36, loss: 0.02324034145358311\n",
      "epoch: 37, loss: 0.02325565771193735\n",
      "epoch: 38, loss: 0.02352354427950023\n",
      "epoch: 39, loss: 0.023748922055241133\n",
      "epoch: 40, loss: 0.023789438827844\n",
      "epoch: 41, loss: 0.023575447921346387\n",
      "epoch: 42, loss: 0.02345526468494109\n",
      "epoch: 43, loss: 0.023589362526262977\n",
      "epoch: 44, loss: 0.023544483395991366\n",
      "epoch: 45, loss: 0.02327224179038735\n",
      "epoch: 46, loss: 0.023364345962008634\n",
      "epoch: 47, loss: 0.023405879430170952\n",
      "epoch: 48, loss: 0.023155397217767274\n",
      "epoch: 49, loss: 0.023057022150095897\n",
      "epoch: 50, loss: 0.02297713416480873\n",
      "epoch: 51, loss: 0.022973165550472865\n",
      "epoch: 52, loss: 0.022823365913274184\n",
      "epoch: 53, loss: 0.02284035444585093\n",
      "epoch: 54, loss: 0.022702601455403756\n",
      "epoch: 55, loss: 0.022624172765563055\n",
      "epoch: 56, loss: 0.02247760216923689\n",
      "epoch: 57, loss: 0.022794839206473613\n",
      "epoch: 58, loss: 0.02266405154292315\n",
      "epoch: 59, loss: 0.022739008428772\n",
      "epoch: 60, loss: 0.02269604311318901\n",
      "epoch: 61, loss: 0.02251320478064395\n",
      "epoch: 62, loss: 0.02250929385949936\n",
      "epoch: 63, loss: 0.02241937218161605\n",
      "epoch: 64, loss: 0.022237210972070712\n",
      "epoch: 65, loss: 0.022479216000038903\n",
      "epoch: 66, loss: 0.022216055356662507\n",
      "epoch: 67, loss: 0.022525636409052183\n",
      "epoch: 68, loss: 0.02243958942830222\n",
      "epoch: 69, loss: 0.02248357449565858\n",
      "epoch: 70, loss: 0.022084474231984688\n",
      "epoch: 71, loss: 0.022223601932877726\n",
      "epoch: 72, loss: 0.022221241099552334\n",
      "epoch: 73, loss: 0.0223698602297191\n",
      "epoch: 74, loss: 0.02219179184644877\n",
      "epoch: 75, loss: 0.0222117913463585\n",
      "epoch: 76, loss: 0.022163022281496643\n",
      "epoch: 77, loss: 0.021816059092428827\n",
      "epoch: 78, loss: 0.022155146880096236\n",
      "epoch: 79, loss: 0.022161958547751236\n",
      "epoch: 80, loss: 0.022019131173379784\n",
      "epoch: 81, loss: 0.021922983867103084\n",
      "epoch: 82, loss: 0.02172615157594756\n",
      "epoch: 83, loss: 0.021877564974169088\n",
      "epoch: 84, loss: 0.021655329047546825\n",
      "epoch: 85, loss: 0.0218773900249296\n",
      "epoch: 86, loss: 0.021627912462946475\n",
      "epoch: 87, loss: 0.021856450172821833\n",
      "epoch: 88, loss: 0.021806571839417466\n",
      "epoch: 89, loss: 0.021817553911597957\n",
      "epoch: 90, loss: 0.021660386115346774\n",
      "epoch: 91, loss: 0.021951863787180413\n",
      "epoch: 92, loss: 0.021759490216059326\n",
      "epoch: 93, loss: 0.021577982845343388\n",
      "epoch: 94, loss: 0.021619606187201823\n",
      "epoch: 95, loss: 0.021598503511905544\n",
      "epoch: 96, loss: 0.02169194689724883\n",
      "epoch: 97, loss: 0.021575755124393022\n",
      "epoch: 98, loss: 0.021454454077409747\n",
      "epoch: 99, loss: 0.021403534645414155\n",
      "0.02151858412771203\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d71972243b3a4dd0a5ccfaf2b6354644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.08893594816299412\n",
      "epoch: 1, loss: 0.08310969246705327\n",
      "epoch: 2, loss: 0.07924603901807357\n",
      "epoch: 3, loss: 0.07586534803765563\n",
      "epoch: 4, loss: 0.07335117145678222\n",
      "epoch: 5, loss: 0.0717449419853136\n",
      "epoch: 6, loss: 0.0703588730857601\n",
      "epoch: 7, loss: 0.07011628161083434\n",
      "epoch: 8, loss: 0.0694887943028496\n",
      "epoch: 9, loss: 0.06902504559196732\n",
      "epoch: 10, loss: 0.06818332798202141\n",
      "epoch: 11, loss: 0.06794884719639241\n",
      "epoch: 12, loss: 0.0684339154200663\n",
      "epoch: 13, loss: 0.0669608303365667\n",
      "epoch: 14, loss: 0.06708641914144992\n",
      "epoch: 15, loss: 0.06622019977862963\n",
      "epoch: 16, loss: 0.06546252860062389\n",
      "epoch: 17, loss: 0.06569418079024147\n",
      "epoch: 18, loss: 0.06539230178007417\n",
      "epoch: 19, loss: 0.06512229906522421\n",
      "epoch: 20, loss: 0.0643860626577199\n",
      "epoch: 21, loss: 0.0644740234163529\n",
      "epoch: 22, loss: 0.06352997241875351\n",
      "epoch: 23, loss: 0.06346258177154822\n",
      "epoch: 24, loss: 0.06362133178249085\n",
      "epoch: 25, loss: 0.06384421790051407\n",
      "epoch: 26, loss: 0.06362235053740141\n",
      "epoch: 27, loss: 0.06359631324254945\n",
      "epoch: 28, loss: 0.0634216854581502\n",
      "epoch: 29, loss: 0.06345029201907584\n",
      "epoch: 30, loss: 0.06268645043449947\n",
      "epoch: 31, loss: 0.062108676684211064\n",
      "epoch: 32, loss: 0.062273095394381396\n",
      "epoch: 33, loss: 0.06194938433466356\n",
      "epoch: 34, loss: 0.061803943246816206\n",
      "epoch: 35, loss: 0.06146800720800199\n",
      "epoch: 36, loss: 0.06130749599472853\n",
      "epoch: 37, loss: 0.06076283278354553\n",
      "epoch: 38, loss: 0.060247137202313616\n",
      "epoch: 39, loss: 0.06044712618860262\n",
      "epoch: 40, loss: 0.060243642033530706\n",
      "epoch: 41, loss: 0.059934433120296\n",
      "epoch: 42, loss: 0.059667168062808695\n",
      "epoch: 43, loss: 0.05992024681245356\n",
      "epoch: 44, loss: 0.05968020061918104\n",
      "epoch: 45, loss: 0.06027106335513669\n",
      "epoch: 46, loss: 0.0599927298256909\n",
      "epoch: 47, loss: 0.05979685803426626\n",
      "epoch: 48, loss: 0.05887784118179857\n",
      "epoch: 49, loss: 0.05877481973562714\n",
      "epoch: 50, loss: 0.05922322352998606\n",
      "epoch: 51, loss: 0.05906469622147981\n",
      "epoch: 52, loss: 0.05926913772177084\n",
      "epoch: 53, loss: 0.059123832424037806\n",
      "epoch: 54, loss: 0.05863419248571938\n",
      "epoch: 55, loss: 0.05818468834349773\n",
      "epoch: 56, loss: 0.057648078482703015\n",
      "epoch: 57, loss: 0.05676789884515531\n",
      "epoch: 58, loss: 0.0551723384649236\n",
      "epoch: 59, loss: 0.05156316545105891\n",
      "epoch: 60, loss: 0.04649214055181886\n",
      "epoch: 61, loss: 0.03777057080187369\n",
      "epoch: 62, loss: 0.027782297351121792\n",
      "epoch: 63, loss: 0.018564582467476335\n",
      "epoch: 64, loss: 0.014450489410782285\n",
      "epoch: 65, loss: 0.015505944625017592\n",
      "epoch: 66, loss: 0.01633059208329547\n",
      "epoch: 67, loss: 0.016320245372952173\n",
      "epoch: 68, loss: 0.016189251171592547\n",
      "epoch: 69, loss: 0.016543823287669953\n",
      "epoch: 70, loss: 0.015824638778967098\n",
      "epoch: 71, loss: 0.015184517949844592\n",
      "epoch: 72, loss: 0.014162649738158152\n",
      "epoch: 73, loss: 0.013788870926943742\n",
      "epoch: 74, loss: 0.013311173158573782\n",
      "epoch: 75, loss: 0.013227188885628169\n",
      "epoch: 76, loss: 0.012818590288215486\n",
      "epoch: 77, loss: 0.013031641185632641\n",
      "epoch: 78, loss: 0.013290993949538105\n",
      "epoch: 79, loss: 0.013072562261222826\n",
      "epoch: 80, loss: 0.01282711799979547\n",
      "epoch: 81, loss: 0.012422753534442738\n",
      "epoch: 82, loss: 0.012235878945812724\n",
      "epoch: 83, loss: 0.011729240069302583\n",
      "epoch: 84, loss: 0.011452811021604493\n",
      "epoch: 85, loss: 0.011401199886490075\n",
      "epoch: 86, loss: 0.011301076020500227\n",
      "epoch: 87, loss: 0.011550314307856325\n",
      "epoch: 88, loss: 0.011792458920939174\n",
      "epoch: 89, loss: 0.011712456498903208\n",
      "epoch: 90, loss: 0.011525679816550274\n",
      "epoch: 91, loss: 0.011407864568459982\n",
      "epoch: 92, loss: 0.011406177117756471\n",
      "epoch: 93, loss: 0.011392467729314404\n",
      "epoch: 94, loss: 0.011082268718204516\n",
      "epoch: 95, loss: 0.011279132087898807\n",
      "epoch: 96, loss: 0.010985004472764728\n",
      "epoch: 97, loss: 0.011152832870736018\n",
      "epoch: 98, loss: 0.011124782854678637\n",
      "epoch: 99, loss: 0.01113861081214259\n",
      "0.011051301149121874\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e635cc54704dd8a3f64f119793f391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.09010663418384732\n",
      "epoch: 1, loss: 0.08288304763505983\n",
      "epoch: 2, loss: 0.07800506299696745\n",
      "epoch: 3, loss: 0.07502186037271341\n",
      "epoch: 4, loss: 0.07426967660691274\n",
      "epoch: 5, loss: 0.07381004328500512\n",
      "epoch: 6, loss: 0.07461329372960096\n",
      "epoch: 7, loss: 0.07384237250254118\n",
      "epoch: 8, loss: 0.07445386685160987\n",
      "epoch: 9, loss: 0.07400249699563653\n",
      "epoch: 10, loss: 0.07371927543327883\n",
      "epoch: 11, loss: 0.07349227650235657\n",
      "epoch: 12, loss: 0.07340825992716182\n",
      "epoch: 13, loss: 0.07286668479441595\n",
      "epoch: 14, loss: 0.07150218581792675\n",
      "epoch: 15, loss: 0.0704627549839958\n",
      "epoch: 16, loss: 0.06938034081895336\n",
      "epoch: 17, loss: 0.06812266973839208\n",
      "epoch: 18, loss: 0.06659679039824976\n",
      "epoch: 19, loss: 0.06421322802345171\n",
      "epoch: 20, loss: 0.0609186412016254\n",
      "epoch: 21, loss: 0.05468786055867631\n",
      "epoch: 22, loss: 0.04547753235182649\n",
      "epoch: 23, loss: 0.035058567817469403\n",
      "epoch: 24, loss: 0.02730088457275023\n",
      "epoch: 25, loss: 0.02571747928172591\n",
      "epoch: 26, loss: 0.02831496818635911\n",
      "epoch: 27, loss: 0.031069853745569552\n",
      "epoch: 28, loss: 0.03141582867542207\n",
      "epoch: 29, loss: 0.030370831691132166\n",
      "epoch: 30, loss: 0.029735864850650797\n",
      "epoch: 31, loss: 0.029598220498815594\n",
      "epoch: 32, loss: 0.0303155979287684\n",
      "epoch: 33, loss: 0.031063806046304508\n",
      "epoch: 34, loss: 0.030254313995505055\n",
      "epoch: 35, loss: 0.029463829066926895\n",
      "epoch: 36, loss: 0.028080917300673493\n",
      "epoch: 37, loss: 0.02695826028281746\n",
      "epoch: 38, loss: 0.026121820602915263\n",
      "epoch: 39, loss: 0.025732917280554532\n",
      "epoch: 40, loss: 0.02528597108991704\n",
      "epoch: 41, loss: 0.025007848117585628\n",
      "epoch: 42, loss: 0.024936393877098527\n",
      "epoch: 43, loss: 0.024785105122173738\n",
      "epoch: 44, loss: 0.02481619910072554\n",
      "epoch: 45, loss: 0.02466881027661589\n",
      "epoch: 46, loss: 0.024234621992125605\n",
      "epoch: 47, loss: 0.02377223045508473\n",
      "epoch: 48, loss: 0.023749245983405092\n",
      "epoch: 49, loss: 0.023442752479182392\n",
      "epoch: 50, loss: 0.023372995910089442\n",
      "epoch: 51, loss: 0.023511776394419072\n",
      "epoch: 52, loss: 0.023537223098798105\n",
      "epoch: 53, loss: 0.02375282533676991\n",
      "epoch: 54, loss: 0.02372547701711479\n",
      "epoch: 55, loss: 0.02360733520954513\n",
      "epoch: 56, loss: 0.023397175732817677\n",
      "epoch: 57, loss: 0.023369678526351068\n",
      "epoch: 58, loss: 0.02308273273243497\n",
      "epoch: 59, loss: 0.022938871220439895\n",
      "epoch: 60, loss: 0.02305681506563034\n",
      "epoch: 61, loss: 0.02286446111338448\n",
      "epoch: 62, loss: 0.022827993964570553\n",
      "epoch: 63, loss: 0.022642026980614332\n",
      "epoch: 64, loss: 0.022955188949814444\n",
      "epoch: 65, loss: 0.022749677867254993\n",
      "epoch: 66, loss: 0.022410586864171935\n",
      "epoch: 67, loss: 0.02252030071968988\n",
      "epoch: 68, loss: 0.02272968775734002\n",
      "epoch: 69, loss: 0.022447365118529947\n",
      "epoch: 70, loss: 0.022514454718917203\n",
      "epoch: 71, loss: 0.022732286288209634\n",
      "epoch: 72, loss: 0.022409590201406874\n",
      "epoch: 73, loss: 0.022728638804155807\n",
      "epoch: 74, loss: 0.022595432162226082\n",
      "epoch: 75, loss: 0.022368546848929086\n",
      "epoch: 76, loss: 0.022354123032750563\n",
      "epoch: 77, loss: 0.02237882515072879\n",
      "epoch: 78, loss: 0.02227573241059049\n",
      "epoch: 79, loss: 0.022435208709744147\n",
      "epoch: 80, loss: 0.022253108679724874\n",
      "epoch: 81, loss: 0.02254055525779443\n",
      "epoch: 82, loss: 0.02229062410100253\n",
      "epoch: 83, loss: 0.022248598985851936\n",
      "epoch: 84, loss: 0.022147754074357637\n",
      "epoch: 85, loss: 0.02213427328058475\n",
      "epoch: 86, loss: 0.02188908269322912\n",
      "epoch: 87, loss: 0.02219793421986565\n",
      "epoch: 88, loss: 0.02206658107211549\n",
      "epoch: 89, loss: 0.022060984209166263\n",
      "epoch: 90, loss: 0.022121053197341433\n",
      "epoch: 91, loss: 0.022140675823817058\n",
      "epoch: 92, loss: 0.021965249046193968\n",
      "epoch: 93, loss: 0.02207932822081277\n",
      "epoch: 94, loss: 0.022404246568656642\n",
      "epoch: 95, loss: 0.022331776670818208\n",
      "epoch: 96, loss: 0.022114174903423614\n",
      "epoch: 97, loss: 0.0220057494542979\n",
      "epoch: 98, loss: 0.022068589777187113\n",
      "epoch: 99, loss: 0.022227912623987635\n",
      "0.021923470315511163\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae2f98144a6405b838d18243b8f378c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.09877541505689265\n",
      "epoch: 1, loss: 0.0927218663251023\n",
      "epoch: 2, loss: 0.0882350951705636\n",
      "epoch: 3, loss: 0.08510672406893162\n",
      "epoch: 4, loss: 0.08189067139774293\n",
      "epoch: 5, loss: 0.07783844790988519\n",
      "epoch: 6, loss: 0.0730511004677237\n",
      "epoch: 7, loss: 0.06901769298026439\n",
      "epoch: 8, loss: 0.064803219091191\n",
      "epoch: 9, loss: 0.05921212822016106\n",
      "epoch: 10, loss: 0.05309263266185876\n",
      "epoch: 11, loss: 0.045230181516873774\n",
      "epoch: 12, loss: 0.036723819102454563\n",
      "epoch: 13, loss: 0.028686470860414075\n",
      "epoch: 14, loss: 0.021510526847503687\n",
      "epoch: 15, loss: 0.017470240126721718\n",
      "epoch: 16, loss: 0.01607234580447906\n",
      "epoch: 17, loss: 0.015373437936424534\n",
      "epoch: 18, loss: 0.014438700915970305\n",
      "epoch: 19, loss: 0.013224491246264085\n",
      "epoch: 20, loss: 0.012224679052719258\n",
      "epoch: 21, loss: 0.012049116152827288\n",
      "epoch: 22, loss: 0.012529991766193323\n",
      "epoch: 23, loss: 0.013120398120207108\n",
      "epoch: 24, loss: 0.01328306133338099\n",
      "epoch: 25, loss: 0.01314497692445576\n",
      "epoch: 26, loss: 0.01295116063277761\n",
      "epoch: 27, loss: 0.013161094734686275\n",
      "epoch: 28, loss: 0.013169835811395239\n",
      "epoch: 29, loss: 0.013314182933192151\n",
      "epoch: 30, loss: 0.013054384230622641\n",
      "epoch: 31, loss: 0.01276910383019364\n",
      "epoch: 32, loss: 0.012410162130409762\n",
      "epoch: 33, loss: 0.01175963216266233\n",
      "epoch: 34, loss: 0.011440332759874631\n",
      "epoch: 35, loss: 0.011344026992040113\n",
      "epoch: 36, loss: 0.011427385436451734\n",
      "epoch: 37, loss: 0.011520990149615142\n",
      "epoch: 38, loss: 0.011522901538211928\n",
      "epoch: 39, loss: 0.01105035739386849\n",
      "epoch: 40, loss: 0.011058336589590649\n",
      "epoch: 41, loss: 0.011285087789898214\n",
      "epoch: 42, loss: 0.0112833245563306\n",
      "epoch: 43, loss: 0.011371239786053183\n",
      "epoch: 44, loss: 0.011323198506182831\n",
      "epoch: 45, loss: 0.011356845678812632\n",
      "epoch: 46, loss: 0.011028894806925663\n",
      "epoch: 47, loss: 0.011105365368188453\n",
      "epoch: 48, loss: 0.011033738710718187\n",
      "epoch: 49, loss: 0.011087680817354647\n",
      "epoch: 50, loss: 0.010988277011336938\n",
      "epoch: 51, loss: 0.011014730623367988\n",
      "epoch: 52, loss: 0.011008065430498848\n",
      "epoch: 53, loss: 0.010884129322018756\n",
      "epoch: 54, loss: 0.01086537879830183\n",
      "epoch: 55, loss: 0.011028455012653576\n",
      "epoch: 56, loss: 0.011184728449661183\n",
      "epoch: 57, loss: 0.01084301237596384\n",
      "epoch: 58, loss: 0.011036935028929265\n",
      "epoch: 59, loss: 0.010882891780825908\n",
      "epoch: 60, loss: 0.010868858228248018\n",
      "epoch: 61, loss: 0.011088126303932942\n",
      "epoch: 62, loss: 0.010981627212281637\n",
      "epoch: 63, loss: 0.010887761342628659\n",
      "epoch: 64, loss: 0.011029114237428748\n",
      "epoch: 65, loss: 0.010889054518289818\n",
      "epoch: 66, loss: 0.010958980859111463\n",
      "epoch: 67, loss: 0.01083794800750082\n",
      "epoch: 68, loss: 0.01087065300621058\n",
      "epoch: 69, loss: 0.011034159557091267\n",
      "epoch: 70, loss: 0.010830963377611337\n",
      "epoch: 71, loss: 0.010918640770021814\n",
      "epoch: 72, loss: 0.010765673542360672\n",
      "epoch: 73, loss: 0.010846237807727834\n",
      "epoch: 74, loss: 0.010663716202064815\n",
      "epoch: 75, loss: 0.010885744996521984\n",
      "epoch: 76, loss: 0.010830671650296986\n",
      "epoch: 77, loss: 0.010789335322478048\n",
      "epoch: 78, loss: 0.010887614529643663\n",
      "epoch: 79, loss: 0.010865320856556367\n",
      "epoch: 80, loss: 0.010858838143435266\n",
      "epoch: 81, loss: 0.010811041736949738\n",
      "epoch: 82, loss: 0.010730762648564604\n",
      "epoch: 83, loss: 0.010678292020045823\n",
      "epoch: 84, loss: 0.010642770635410772\n",
      "epoch: 85, loss: 0.010730505026531063\n",
      "epoch: 86, loss: 0.010685908676263093\n",
      "epoch: 87, loss: 0.01051717662628193\n",
      "epoch: 88, loss: 0.010692082737832427\n",
      "epoch: 89, loss: 0.010633251143577195\n",
      "epoch: 90, loss: 0.010584732792656305\n",
      "epoch: 91, loss: 0.010621991368502351\n",
      "epoch: 92, loss: 0.010667161747994139\n",
      "epoch: 93, loss: 0.010515270502795777\n",
      "epoch: 94, loss: 0.010806839745076765\n",
      "epoch: 95, loss: 0.010717782511737635\n",
      "epoch: 96, loss: 0.010619605115237287\n",
      "epoch: 97, loss: 0.010602976333235122\n",
      "epoch: 98, loss: 0.01060984318076016\n",
      "epoch: 99, loss: 0.010480847821469541\n",
      "0.010864516204031883\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2293860c0e54776a6b7d5e0c9d7b082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.09283242855306549\n",
      "epoch: 1, loss: 0.08255263122718726\n",
      "epoch: 2, loss: 0.07670552266566895\n",
      "epoch: 3, loss: 0.07391493292913077\n",
      "epoch: 4, loss: 0.07365880171104096\n",
      "epoch: 5, loss: 0.07346112409099653\n",
      "epoch: 6, loss: 0.07220803099985097\n",
      "epoch: 7, loss: 0.07080596665061019\n",
      "epoch: 8, loss: 0.06851332004157647\n",
      "epoch: 9, loss: 0.06659785391273472\n",
      "epoch: 10, loss: 0.06427372494168782\n",
      "epoch: 11, loss: 0.060366996373449784\n",
      "epoch: 12, loss: 0.055355799451166136\n",
      "epoch: 13, loss: 0.05070019035512103\n",
      "epoch: 14, loss: 0.044447572174383075\n",
      "epoch: 15, loss: 0.037662148403059204\n",
      "epoch: 16, loss: 0.0312839841740844\n",
      "epoch: 17, loss: 0.025538544178492276\n",
      "epoch: 18, loss: 0.021280252374386674\n",
      "epoch: 19, loss: 0.019089370193905227\n",
      "epoch: 20, loss: 0.017748304826834094\n",
      "epoch: 21, loss: 0.017445447532387887\n",
      "epoch: 22, loss: 0.01617256082709907\n",
      "epoch: 23, loss: 0.01568731382151334\n",
      "epoch: 24, loss: 0.014864787478995375\n",
      "epoch: 25, loss: 0.013944919552301155\n",
      "epoch: 26, loss: 0.013189796294951778\n",
      "epoch: 27, loss: 0.012966952331238825\n",
      "epoch: 28, loss: 0.01294874520699166\n",
      "epoch: 29, loss: 0.013153254717376089\n",
      "epoch: 30, loss: 0.013356663280520152\n",
      "epoch: 31, loss: 0.013172207104608234\n",
      "epoch: 32, loss: 0.012952206700818694\n",
      "epoch: 33, loss: 0.011737185847804763\n",
      "epoch: 34, loss: 0.01141851218551934\n",
      "epoch: 35, loss: 0.01118168084852998\n",
      "epoch: 36, loss: 0.011068907209092038\n",
      "epoch: 37, loss: 0.01086647770680681\n",
      "epoch: 38, loss: 0.010849078836392145\n",
      "epoch: 39, loss: 0.010968875973598342\n",
      "epoch: 40, loss: 0.011010782200125708\n",
      "epoch: 41, loss: 0.0108483079558733\n",
      "epoch: 42, loss: 0.010742180210255104\n",
      "epoch: 43, loss: 0.010773478069426688\n",
      "epoch: 44, loss: 0.010705857012878966\n",
      "epoch: 45, loss: 0.010725495156449091\n",
      "epoch: 46, loss: 0.010367522148914352\n",
      "epoch: 47, loss: 0.010561142255904479\n",
      "epoch: 48, loss: 0.010548543033296111\n",
      "epoch: 49, loss: 0.010482531477803182\n",
      "epoch: 50, loss: 0.01064562630906979\n",
      "epoch: 51, loss: 0.010530123013199005\n",
      "epoch: 52, loss: 0.010558584223477805\n",
      "epoch: 53, loss: 0.01054767752282351\n",
      "epoch: 54, loss: 0.010546878190989708\n",
      "epoch: 55, loss: 0.010400570633405978\n",
      "epoch: 56, loss: 0.010211793766461873\n",
      "epoch: 57, loss: 0.01029587046138451\n",
      "epoch: 58, loss: 0.010346016523782219\n",
      "epoch: 59, loss: 0.010322757752288273\n",
      "epoch: 60, loss: 0.010289683419465637\n",
      "epoch: 61, loss: 0.010297453399857059\n",
      "epoch: 62, loss: 0.010022745035923009\n",
      "epoch: 63, loss: 0.010174416776992021\n",
      "epoch: 64, loss: 0.010166644453762171\n",
      "epoch: 65, loss: 0.010082791989489597\n",
      "epoch: 66, loss: 0.010320435047896277\n",
      "epoch: 67, loss: 0.010351624994569248\n",
      "epoch: 68, loss: 0.010263655445509102\n",
      "epoch: 69, loss: 0.010417120515404919\n",
      "epoch: 70, loss: 0.010253886599803908\n",
      "epoch: 71, loss: 0.01026393698739337\n",
      "epoch: 72, loss: 0.010235688896148551\n",
      "epoch: 73, loss: 0.01013103121636976\n",
      "epoch: 74, loss: 0.010272439050924419\n",
      "epoch: 75, loss: 0.010181355611995686\n",
      "epoch: 76, loss: 0.010410175346121285\n",
      "epoch: 77, loss: 0.010215298092781383\n",
      "epoch: 78, loss: 0.010096856143938031\n",
      "epoch: 79, loss: 0.010182031122252076\n",
      "epoch: 80, loss: 0.010088695819944253\n",
      "epoch: 81, loss: 0.01006960755605795\n",
      "epoch: 82, loss: 0.010185911633761906\n",
      "epoch: 83, loss: 0.010338161346504568\n",
      "epoch: 84, loss: 0.010137486080326713\n",
      "epoch: 85, loss: 0.010320909799715079\n",
      "epoch: 86, loss: 0.010030268420755278\n",
      "epoch: 87, loss: 0.010230654626225948\n",
      "epoch: 88, loss: 0.010174884842081053\n",
      "epoch: 89, loss: 0.009982820298972891\n",
      "epoch: 90, loss: 0.010242756847147611\n",
      "epoch: 91, loss: 0.01019192139775327\n",
      "epoch: 92, loss: 0.010350321454070882\n",
      "epoch: 93, loss: 0.010124150998323136\n",
      "epoch: 94, loss: 0.01022790039489641\n",
      "epoch: 95, loss: 0.010270235259526998\n",
      "epoch: 96, loss: 0.0101161045073914\n",
      "epoch: 97, loss: 0.0102246889086983\n",
      "epoch: 98, loss: 0.010177564099368415\n",
      "epoch: 99, loss: 0.01026727768760228\n",
      "0.0103842651663573\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "model_list = []\n",
    "for i in tqdm(range(5)):\n",
    "    optimizer = Adam(lr=0.1)\n",
    "    model = RegularizedModel(n_features=n_features, \n",
    "                             n_targets=1, \n",
    "                             reps=2,\n",
    "                             alpha=0.00,\n",
    "                             backend=backend, \n",
    "                             shots=10000, \n",
    "                             optimizer=optimizer)\n",
    "    \n",
    "    model.encoder.reg = False\n",
    "    model.train(x_train, y_train, epochs=epochs, verbose=True) \n",
    "    model_list.append(model)\n",
    "    print(model.loss[-1])\n",
    "\n",
    "saver(model_list, data_path(\"sparse_no_reg_model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca7f7254ac324aebb0602c2995ad2813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b6cdd3d7594906bfef5ada8738a4d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.10768445764328853\n",
      "epoch: 1, loss: 0.07275653584351174\n",
      "epoch: 2, loss: 0.05503904011586421\n",
      "epoch: 3, loss: 0.042727240368448875\n",
      "epoch: 4, loss: 0.030504287830210988\n",
      "epoch: 5, loss: 0.019739248766056466\n",
      "epoch: 6, loss: 0.012513278424168764\n",
      "epoch: 7, loss: 0.00806092260661267\n",
      "epoch: 8, loss: 0.005433507571530303\n",
      "epoch: 9, loss: 0.004325742017592506\n",
      "epoch: 10, loss: 0.003470964286259513\n",
      "epoch: 11, loss: 0.002871360221724063\n",
      "epoch: 12, loss: 0.0023123500198791317\n",
      "epoch: 13, loss: 0.0018537771556348143\n",
      "epoch: 14, loss: 0.0016727679200081484\n",
      "epoch: 15, loss: 0.0018650429771288465\n",
      "epoch: 16, loss: 0.0020359104879063643\n",
      "epoch: 17, loss: 0.0020930731307492447\n",
      "epoch: 18, loss: 0.0019529470004306495\n",
      "epoch: 19, loss: 0.0017700573941558276\n",
      "epoch: 20, loss: 0.0017171917864471486\n",
      "epoch: 21, loss: 0.0017113342603668278\n",
      "epoch: 22, loss: 0.0016695241183468448\n",
      "epoch: 23, loss: 0.0014259033771052635\n",
      "epoch: 24, loss: 0.0009753969723934896\n",
      "epoch: 25, loss: 0.0006757335646261843\n",
      "epoch: 26, loss: 0.00043575494551426704\n",
      "epoch: 27, loss: 0.0004128604749393715\n",
      "epoch: 28, loss: 0.00044683371227711733\n",
      "epoch: 29, loss: 0.00039166890081791957\n",
      "epoch: 30, loss: 0.00030321827853662964\n",
      "epoch: 31, loss: 0.00020342226001139114\n",
      "epoch: 32, loss: 0.0001456651916389227\n",
      "epoch: 33, loss: 0.00015207025291313583\n",
      "epoch: 34, loss: 0.00018515504146681162\n",
      "epoch: 35, loss: 0.00017535523017204806\n",
      "epoch: 36, loss: 0.00013979861666698427\n",
      "epoch: 37, loss: 7.279741223435783e-05\n",
      "epoch: 38, loss: 4.788242438161466e-05\n",
      "epoch: 39, loss: 6.172612563733285e-05\n",
      "epoch: 40, loss: 7.606282213663746e-05\n",
      "epoch: 41, loss: 8.461085734881543e-05\n",
      "epoch: 42, loss: 7.275061822829482e-05\n",
      "epoch: 43, loss: 3.8611532225719226e-05\n",
      "epoch: 44, loss: 2.9785354573971774e-05\n",
      "epoch: 45, loss: 5.033595989156597e-05\n",
      "epoch: 46, loss: 7.586596664858242e-05\n",
      "epoch: 47, loss: 8.924808565198537e-05\n",
      "epoch: 48, loss: 5.240514014224043e-05\n",
      "epoch: 49, loss: 3.108480062770669e-05\n",
      "epoch: 50, loss: 3.1726537740991005e-05\n",
      "epoch: 51, loss: 3.6147837550660545e-05\n",
      "epoch: 52, loss: 4.4190149846956805e-05\n",
      "epoch: 53, loss: 5.147197006640958e-05\n",
      "epoch: 54, loss: 3.2316970935566566e-05\n",
      "epoch: 55, loss: 2.3209760267230153e-05\n",
      "epoch: 56, loss: 3.242062578498244e-05\n",
      "epoch: 57, loss: 4.562354369197996e-05\n",
      "epoch: 58, loss: 3.753335473006421e-05\n",
      "epoch: 59, loss: 2.9475781390673586e-05\n",
      "epoch: 60, loss: 2.03549699494515e-05\n",
      "epoch: 61, loss: 1.8022836007555583e-05\n",
      "epoch: 62, loss: 3.599043733278441e-05\n",
      "epoch: 63, loss: 3.30545588243805e-05\n",
      "epoch: 64, loss: 3.025367895057836e-05\n",
      "epoch: 65, loss: 1.9381424615690244e-05\n",
      "epoch: 66, loss: 2.1019100170936768e-05\n",
      "epoch: 67, loss: 2.0669583835089345e-05\n",
      "epoch: 68, loss: 1.8220017158086656e-05\n",
      "epoch: 69, loss: 1.645180090475098e-05\n",
      "epoch: 70, loss: 1.8056068031105483e-05\n",
      "epoch: 71, loss: 1.7887361167498584e-05\n",
      "epoch: 72, loss: 1.9465944008209108e-05\n",
      "epoch: 73, loss: 2.0964857075615345e-05\n",
      "epoch: 74, loss: 2.2281316634264166e-05\n",
      "epoch: 75, loss: 1.5364747612453712e-05\n",
      "epoch: 76, loss: 2.1019931288249696e-05\n",
      "epoch: 77, loss: 2.0696083034414773e-05\n",
      "epoch: 78, loss: 2.00757582215786e-05\n",
      "epoch: 79, loss: 2.2087085688448142e-05\n",
      "epoch: 80, loss: 2.1471461950928914e-05\n",
      "epoch: 81, loss: 1.7552725827581138e-05\n",
      "epoch: 82, loss: 1.940337182974719e-05\n",
      "epoch: 83, loss: 1.4960792277265123e-05\n",
      "epoch: 84, loss: 1.9337664239770417e-05\n",
      "epoch: 85, loss: 1.7386794628167123e-05\n",
      "epoch: 86, loss: 1.8405457361514913e-05\n",
      "epoch: 87, loss: 1.5065649584741724e-05\n",
      "epoch: 88, loss: 1.9325405843421693e-05\n",
      "epoch: 89, loss: 1.7261342370931393e-05\n",
      "epoch: 90, loss: 1.9838758324638414e-05\n",
      "epoch: 91, loss: 1.6344798589141316e-05\n",
      "epoch: 92, loss: 1.7552943168576745e-05\n",
      "epoch: 93, loss: 2.175606863264337e-05\n",
      "epoch: 94, loss: 1.7783029639353132e-05\n",
      "epoch: 95, loss: 1.960909470189489e-05\n",
      "epoch: 96, loss: 2.1610134148685515e-05\n",
      "epoch: 97, loss: 1.6043348057590174e-05\n",
      "epoch: 98, loss: 1.8392024069498642e-05\n",
      "epoch: 99, loss: 1.618674271743199e-05\n",
      "1.6040711835577115e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29655e6253094361bb03b8e3a9c7877d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.12776272125686203\n",
      "epoch: 1, loss: 0.09047255492145151\n",
      "epoch: 2, loss: 0.06877528463900046\n",
      "epoch: 3, loss: 0.05648955913516123\n",
      "epoch: 4, loss: 0.045362091414223274\n",
      "epoch: 5, loss: 0.03336079748451856\n",
      "epoch: 6, loss: 0.021677709535084157\n",
      "epoch: 7, loss: 0.013084023644144993\n",
      "epoch: 8, loss: 0.007700821893016966\n",
      "epoch: 9, loss: 0.0061740997823628765\n",
      "epoch: 10, loss: 0.006884157281181647\n",
      "epoch: 11, loss: 0.007786245992172591\n",
      "epoch: 12, loss: 0.006942165219423963\n",
      "epoch: 13, loss: 0.005113895918619954\n",
      "epoch: 14, loss: 0.0025607986514978526\n",
      "epoch: 15, loss: 0.0006621032529558218\n",
      "epoch: 16, loss: 5.209822395599787e-05\n",
      "epoch: 17, loss: 0.0008153798183187653\n",
      "epoch: 18, loss: 0.0021823356553514225\n",
      "epoch: 19, loss: 0.003028492113773602\n",
      "epoch: 20, loss: 0.002964134751152146\n",
      "epoch: 21, loss: 0.002242062956778287\n",
      "epoch: 22, loss: 0.0011648043774351296\n",
      "epoch: 23, loss: 0.00038411281740788485\n",
      "epoch: 24, loss: 9.203485101642205e-05\n",
      "epoch: 25, loss: 0.0003404083346075308\n",
      "epoch: 26, loss: 0.000811970764275284\n",
      "epoch: 27, loss: 0.001186148044575598\n",
      "epoch: 28, loss: 0.001334762082950762\n",
      "epoch: 29, loss: 0.0010865994986443467\n",
      "epoch: 30, loss: 0.0007389256108856638\n",
      "epoch: 31, loss: 0.00036028654041435413\n",
      "epoch: 32, loss: 0.00014010985647428835\n",
      "epoch: 33, loss: 7.446835752880949e-05\n",
      "epoch: 34, loss: 0.00019367793770789035\n",
      "epoch: 35, loss: 0.0003269193568425241\n",
      "epoch: 36, loss: 0.0004958100499215154\n",
      "epoch: 37, loss: 0.0005203184914290562\n",
      "epoch: 38, loss: 0.0004091553429862509\n",
      "epoch: 39, loss: 0.0002606998900866544\n",
      "epoch: 40, loss: 0.00012178569375250194\n",
      "epoch: 41, loss: 6.526198795231078e-05\n",
      "epoch: 42, loss: 6.877263433493878e-05\n",
      "epoch: 43, loss: 0.00011516537078152758\n",
      "epoch: 44, loss: 0.0001673622438583418\n",
      "epoch: 45, loss: 0.0002300090112799365\n",
      "epoch: 46, loss: 0.00021453290372287277\n",
      "epoch: 47, loss: 0.0001820560005196367\n",
      "epoch: 48, loss: 0.00010360296739542767\n",
      "epoch: 49, loss: 6.542978075041714e-05\n",
      "epoch: 50, loss: 4.124245299000592e-05\n",
      "epoch: 51, loss: 3.954484097549029e-05\n",
      "epoch: 52, loss: 5.810836488895749e-05\n",
      "epoch: 53, loss: 8.680589097551733e-05\n",
      "epoch: 54, loss: 0.0001073833881641636\n",
      "epoch: 55, loss: 8.86470495067474e-05\n",
      "epoch: 56, loss: 6.359347411519445e-05\n",
      "epoch: 57, loss: 4.821270460263456e-05\n",
      "epoch: 58, loss: 3.083698101749009e-05\n",
      "epoch: 59, loss: 2.2549831807633898e-05\n",
      "epoch: 60, loss: 3.229315187448678e-05\n",
      "epoch: 61, loss: 3.980487919332818e-05\n",
      "epoch: 62, loss: 3.707137325521458e-05\n",
      "epoch: 63, loss: 4.369143436189373e-05\n",
      "epoch: 64, loss: 4.213313318008523e-05\n",
      "epoch: 65, loss: 2.43407439630721e-05\n",
      "epoch: 66, loss: 2.7882868104663517e-05\n",
      "epoch: 67, loss: 1.766265680028913e-05\n",
      "epoch: 68, loss: 2.6141048329625776e-05\n",
      "epoch: 69, loss: 3.2999053765671345e-05\n",
      "epoch: 70, loss: 2.145771369508781e-05\n",
      "epoch: 71, loss: 2.8917999136023666e-05\n",
      "epoch: 72, loss: 2.4632809394650357e-05\n",
      "epoch: 73, loss: 2.1405370135798492e-05\n",
      "epoch: 74, loss: 2.164531938606902e-05\n",
      "epoch: 75, loss: 1.8208633765851918e-05\n",
      "epoch: 76, loss: 2.8048572276039846e-05\n",
      "epoch: 77, loss: 2.553437614750338e-05\n",
      "epoch: 78, loss: 2.3040097224379568e-05\n",
      "epoch: 79, loss: 1.9414511342771983e-05\n",
      "epoch: 80, loss: 1.6505190562065743e-05\n",
      "epoch: 81, loss: 1.8586123876785218e-05\n",
      "epoch: 82, loss: 1.3064030676764559e-05\n",
      "epoch: 83, loss: 2.046891669501285e-05\n",
      "epoch: 84, loss: 2.208580785065649e-05\n",
      "epoch: 85, loss: 1.796696582291884e-05\n",
      "epoch: 86, loss: 2.6021564107665287e-05\n",
      "epoch: 87, loss: 1.760538764798228e-05\n",
      "epoch: 88, loss: 1.792938340926559e-05\n",
      "epoch: 89, loss: 1.5095070823317077e-05\n",
      "epoch: 90, loss: 1.6527145414071534e-05\n",
      "epoch: 91, loss: 1.8868269110339525e-05\n",
      "epoch: 92, loss: 1.919558912058333e-05\n",
      "epoch: 93, loss: 2.0433870881559395e-05\n",
      "epoch: 94, loss: 1.4857519871700952e-05\n",
      "epoch: 95, loss: 2.2715580667228217e-05\n",
      "epoch: 96, loss: 1.6514777392239982e-05\n",
      "epoch: 97, loss: 1.6938292173372077e-05\n",
      "epoch: 98, loss: 1.8230010158819783e-05\n",
      "epoch: 99, loss: 1.9439622491821837e-05\n",
      "1.7521032457861377e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c915173db2894aa28f2b3c199dc0db5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.05161216541507968\n",
      "epoch: 1, loss: 0.02550141830457466\n",
      "epoch: 2, loss: 0.010536772891062259\n",
      "epoch: 3, loss: 0.002778467865350839\n",
      "epoch: 4, loss: 0.0002625146623551137\n",
      "epoch: 5, loss: 0.0004381635180700302\n",
      "epoch: 6, loss: 0.0011850197111501926\n",
      "epoch: 7, loss: 0.0012127911709195127\n",
      "epoch: 8, loss: 0.0008789875110498573\n",
      "epoch: 9, loss: 0.0007959226591689408\n",
      "epoch: 10, loss: 0.0010746262649939846\n",
      "epoch: 11, loss: 0.0010316386109123193\n",
      "epoch: 12, loss: 0.0006623006568821093\n",
      "epoch: 13, loss: 0.00039518061323825577\n",
      "epoch: 14, loss: 0.0004532642749829232\n",
      "epoch: 15, loss: 0.0007025562174335792\n",
      "epoch: 16, loss: 0.0007409444131065576\n",
      "epoch: 17, loss: 0.0004326510504288205\n",
      "epoch: 18, loss: 0.00015680983678382728\n",
      "epoch: 19, loss: 3.29833861033767e-05\n",
      "epoch: 20, loss: 0.00011866453401419966\n",
      "epoch: 21, loss: 0.0002546787440086091\n",
      "epoch: 22, loss: 0.00032847670761799617\n",
      "epoch: 23, loss: 0.00025879247331138177\n",
      "epoch: 24, loss: 0.00013092772963359532\n",
      "epoch: 25, loss: 7.112178314450474e-05\n",
      "epoch: 26, loss: 8.313689579940336e-05\n",
      "epoch: 27, loss: 0.00012121560571449005\n",
      "epoch: 28, loss: 0.00014719749859084402\n",
      "epoch: 29, loss: 0.0001295761188617919\n",
      "epoch: 30, loss: 8.32860265404938e-05\n",
      "epoch: 31, loss: 7.604311208259448e-05\n",
      "epoch: 32, loss: 6.762604062279264e-05\n",
      "epoch: 33, loss: 6.488765315957172e-05\n",
      "epoch: 34, loss: 5.454552169622897e-05\n",
      "epoch: 35, loss: 4.9572643198652074e-05\n",
      "epoch: 36, loss: 6.568323596909294e-05\n",
      "epoch: 37, loss: 6.130633202807798e-05\n",
      "epoch: 38, loss: 5.4048273827638456e-05\n",
      "epoch: 39, loss: 3.4787024725670287e-05\n",
      "epoch: 40, loss: 2.7216912030351677e-05\n",
      "epoch: 41, loss: 3.490492770990135e-05\n",
      "epoch: 42, loss: 5.238089560645442e-05\n",
      "epoch: 43, loss: 3.2813474161323506e-05\n",
      "epoch: 44, loss: 2.4970206951363032e-05\n",
      "epoch: 45, loss: 1.944184732964652e-05\n",
      "epoch: 46, loss: 3.492612164912702e-05\n",
      "epoch: 47, loss: 3.118871042596716e-05\n",
      "epoch: 48, loss: 3.1959272267014554e-05\n",
      "epoch: 49, loss: 2.2673593513569944e-05\n",
      "epoch: 50, loss: 1.6819897435721253e-05\n",
      "epoch: 51, loss: 2.074468277422126e-05\n",
      "epoch: 52, loss: 2.745510188870069e-05\n",
      "epoch: 53, loss: 3.7512443261244e-05\n",
      "epoch: 54, loss: 2.4204666770611455e-05\n",
      "epoch: 55, loss: 2.9192020968256023e-05\n",
      "epoch: 56, loss: 2.469373672015932e-05\n",
      "epoch: 57, loss: 2.2693158304734404e-05\n",
      "epoch: 58, loss: 2.4318429765313628e-05\n",
      "epoch: 59, loss: 2.2252382723915954e-05\n",
      "epoch: 60, loss: 2.6544071966667877e-05\n",
      "epoch: 61, loss: 1.846177924479771e-05\n",
      "epoch: 62, loss: 1.294677687455928e-05\n",
      "epoch: 63, loss: 1.9575183601142558e-05\n",
      "epoch: 64, loss: 2.6413734692519627e-05\n",
      "epoch: 65, loss: 2.9740458656644867e-05\n",
      "epoch: 66, loss: 1.8705835873209757e-05\n",
      "epoch: 67, loss: 1.5274626725641873e-05\n",
      "epoch: 68, loss: 1.837584053890117e-05\n",
      "epoch: 69, loss: 1.6309747224920474e-05\n",
      "epoch: 70, loss: 1.614587769026538e-05\n",
      "epoch: 71, loss: 2.202162895110725e-05\n",
      "epoch: 72, loss: 2.0927767480491636e-05\n",
      "epoch: 73, loss: 1.8308051131224988e-05\n",
      "epoch: 74, loss: 1.5303916329749118e-05\n",
      "epoch: 75, loss: 2.2163686735091974e-05\n",
      "epoch: 76, loss: 2.083540164956051e-05\n",
      "epoch: 77, loss: 2.340741849590351e-05\n",
      "epoch: 78, loss: 2.0501573135317603e-05\n",
      "epoch: 79, loss: 1.3645338948345467e-05\n",
      "epoch: 80, loss: 1.703039666051347e-05\n",
      "epoch: 81, loss: 2.189762593669517e-05\n",
      "epoch: 82, loss: 2.0307838122413757e-05\n",
      "epoch: 83, loss: 2.280521104555039e-05\n",
      "epoch: 84, loss: 1.6521945394151947e-05\n",
      "epoch: 85, loss: 1.7503183101443097e-05\n",
      "epoch: 86, loss: 2.0062231427097276e-05\n",
      "epoch: 87, loss: 2.198474572536888e-05\n",
      "epoch: 88, loss: 2.5054710583374257e-05\n",
      "epoch: 89, loss: 2.3339538611494484e-05\n",
      "epoch: 90, loss: 2.261843565009854e-05\n",
      "epoch: 91, loss: 2.1561543068274445e-05\n"
     ]
    }
   ],
   "source": [
    "x_train[:,0] = np.pi/2\n",
    "x_train[:,1] = np.pi/2\n",
    "x_train[:,3] = np.pi/2\n",
    "\n",
    "np.random.seed(42)\n",
    "model_list = []\n",
    "for i in tqdm(range(5)):\n",
    "    optimizer = Adam(lr=0.1)\n",
    "    model = RegularizedModel(n_features=n_features, \n",
    "                             n_targets=1, \n",
    "                             reps=2,\n",
    "                             alpha=0.00,\n",
    "                             backend=backend, \n",
    "                             shots=10000, \n",
    "                             optimizer=optimizer)\n",
    "    \n",
    "    model.encoder.reg = False\n",
    "    model.train(x_train, y_train, epochs=epochs, verbose=True) \n",
    "    model_list.append(model)\n",
    "    print(model.loss[-1])\n",
    "\n",
    "saver(model_list, data_path(\"dense_no_reg_model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n = 200\n",
    "n_features = 4\n",
    "epochs = 100\n",
    "x = np.random.uniform(0, 1, (n, n_features))\n",
    "\n",
    "y = -gaussian(x[:,2].reshape(-1,1), 0.2, 0.01) + gaussian(x[:,2].reshape(-1,1), 0.5, 0.02) - gaussian(x[:,2].reshape(-1,1), 0.8, 0.01) \n",
    "\n",
    "x = scaler(x, a=0, b=np.pi)\n",
    "y = scaler(y, a=0.1, b=0.9)\n",
    "\n",
    "x_train, y_train = x[:100,:], y[:100,:]\n",
    "\n",
    "x_train[:,0] = np.pi/2\n",
    "x_train[:,1] = np.pi/2\n",
    "x_train[:,3] = np.pi/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f57f0d9ea00>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAfBklEQVR4nO3df5Dc9X3f8edby8o+4cQniiY2KwkpVIFKVaQjF0FGbePg2gha0EGIkXDjqZOORm5p4wyjsWgZEA0erqNQm07waDSEpBk8CLDJRgQ5Sidy4g6tqA6fZHGAPIpcS7dK68PooEJnczq9+8fuitXe97v73b398f1+9/WY0Yz2+/1q77P63r73s5/P+/P+mLsjIiLJN6/bDRARkdZQQBcRSQkFdBGRlFBAFxFJCQV0EZGUuKxbP/jKK6/0ZcuWdevHi4gk0quvvvqWuy8KOte1gL5s2TJGRka69eNFRBLJzH4Ydk5DLiIiKaGALiKSEgroIiIpoYAuIpISCugiIikRKcvFzDYAjwMZ4El3H646vxB4CrgG+AnwW+7+WovbKtIW+dECO/cfozA5RcaMGXdy/X1su/lahgZy3W6eSGRWr9qimWWA7wOfAsaBQ8Bmd3+94pqdwFl3f9jMrgOecPdP1nrewcFBV9qidFt+tMD9Lxxlanom8LwBDgrwEhtm9qq7DwadizLksg447u4n3P19YA+wseqalcBfAbj7m8AyM/u5ObRZpCN27j8WGsyhGMwBCpNT3P/CUfKjhc40TKQJUQJ6DjhV8Xi8dKzSEeBOADNbB1wNLK5+IjPbYmYjZjYyMTHRXItFmpAfLbB++ADLt7/E+uEDFwPz6cmpyM8xNT3Dzv3H2tVEkTmLMoZuAceqx2mGgcfN7DBwFBgFzs/6R+67gd1QHHJpqKUiDaocGy8PncAHvW2Aq/r7KDQQ1Bv5ABDptCg99HFgScXjxcDpygvc/V13/7y7rwU+BywCftCqRoo0qjw2Xg7W1b2Hcm97283X0pfNRH7eq/r7WthKkdaK0kM/BKwws+VAAdgE3FN5gZn1A+dKY+z/CviOu7/b4raKRJIfLXDfc0eYqTPhf3py6uIk58WevEHYP+vLZth287WX/Jyd+49xenKKqzRpKjFQN6C7+3kzuxfYTzFt8Sl3HzOzraXzu4B/APyJmc0ArwO/3cY2i4Qq98zrBXP4oLc9NJC7JBBHSWOszo6pHMZRUJduqZu22C5KW5R2WD98INKYeF82w6N3rm46+Ib9nFx/Hy9vv6mp5xSJYq5piyKJUWvSsjy7n+vvm1Mwr/VzCpNTSm2UrulaPXSRdgjLWsmY8dhn1rRsOKRWdoyGXqRb1EOXVAnKWunLZloazMN+TtnU9Az3PXdEPXXpOPXQJVUqs1bamX1Sfr4vPns48PyMu3rq0nGaFJXEikPaYL1JWE2SSqtpUlRSp3LhkNO9Wiv1FiZpZal0kgK6JFJQUa1u1FoZGsjx6J2ryVhQhQytLJXOUkCXRArr+XajRzw0kOOxz6wJnIytXFkq0m6aFJXEyY8WmFdawVmtWz3iTk3GitSigC6JkR8t8PCLY5w5Nx14vts94uoSAhCPiVvpHQrokgj1dhbKmM159Werqd6LdJrG0CUR6u0sdME9dkEyLhO30jsU0CUR6k12xjGbJE4Tt9IbFNAlEWoF7G6PnYcJa3McP3wkHRTQJRHCFvD092VjN3ZeFlZXJo4fPpIOmhSVWKvMEvloX5YPZ+cxeW46ERkjSmWUTosU0M1sA/A4xR2LnnT34arzHwWeBpaWnvP33f2PWtxW6THVWSKTU9P0ZTN85e61iQmKQamMIu1Sd8jFzDLAE8AtwEpgs5mtrLrs3wCvu/sa4BPAY2Y2v8VtlR6jLBGRxkQZQ18HHHf3E6VNoPcAG6uuceBnzMyAjwBvA+db2lLpOcoSEWlMlICeA05VPB4vHav0BxQ3ij4NHAV+x90vVD+RmW0xsxEzG5mYmGiyydIrlCUi0pgoAT2ojFx1EY2bgcPAVcBa4A/M7Gdn/SP33e4+6O6DixYtarCp0kvyowXe++nsL3nKEhEJFyWgjwNLKh4vptgTr/R54AUvOg78ALiuNU2UXlOeDJ2curRmy8IF8U1RFImDKAH9ELDCzJaXJjo3AXurrjkJfBLAzH4OuBY40cqGSu8IW+a/YP5lCuYiNdRNW3T382Z2L7CfYtriU+4+ZmZbS+d3Ab8H/LGZHaU4RPMld3+rje2WFNNkqEhzIuWhu/s+YF/VsV0Vfz8NfLq1TZNedVV/X+A+nZoMFalNS/8ldnptyXx+tMD64QMs3/4S64cPdHxfVEkPLf2X2OmlJfOqmS6tpIAusdQrS+ZrrYbthdcvraUhF5Eu0gSwtJICukgXaTWstJICukgX9doEsLSXxtBFuqiXJoCl/cy9uixLZwwODvrIyEhXfrZIXFVu6KHgLkHM7FV3Hww6px66SEzkRwtse/4I0xeKnazC5BTbnj8CKIVRotEYukhM7Ng7djGYl01fcHbsHetSiyRpFNBFYqK6umS94yLVFNBFRFJCAV0kJhYuyDZ0XKSaArpITDx02yqymUs3CMtmjIduW9WlFknSKMtFJCaUky5zpYAuEiO9UpRM2iPSkIuZbTCzY2Z23My2B5zfZmaHS39eM7MZM7ui9c0VEZEwdQO6mWWAJ4BbgJXAZjNbWXmNu+9097Xuvha4H/gbd3+7De0VEZEQUXro64Dj7n7C3d8H9gAba1y/GXimFY0TEZHoooyh54BTFY/HgRuCLjSzBcAG4N6Q81uALQBLly5tqKEivUi1XaQRUQK6BRwLq+h1G/By2HCLu+8GdkOxOFekFkpqKDg1RtvTSaOiDLmMA0sqHi8GTodcuwkNt0iAcnAqTE7hfBCctCFyuFrb04kEiRLQDwErzGy5mc2nGLT3Vl9kZh8FfhX4s9Y2UdJAwalx2p5OGlU3oLv7eYpj4vuBN4Dn3H3MzLaa2daKS+8A/tLd32tPUyXJFJwap+3ppFGR8tDdfZ+7/4K7X+PuXy4d2+Xuuyqu+WN339SuhkqyKTg1Lmh7OoBz75/XUJUEUi0X6Qjtndm4oYEcj965mv6+S4tznTk3rfkHCaSALh1RDk65/j4MyPX38eidq5WtUcfQQI7LPzQ7GU3zDxJEtVykY1SnpDmaf5Co1EMXibmweQYHHsgf7WxjJNYU0EViLmxyFODpgycV1OUiBXRpm/xogfXDB1i+/SXWDx/QJF6TyvMPYb5+8GQHWyNxpoAubaGVoa1Va+5BNTSkTAFd2kIrQ0U6TwFd2kKZGa13+fzgcfSw49J7FNClLbQytPW+fMdqMvMuLX6amWd8+Y7w8XXpLcpDl5bLjxZ476fnZx3XytC50SbSUo8CurRUdQ3vsoULsjx02yoFnznS4iypRUMu0lJBk6EAC+ZfpkAk0mYK6NJShZBJz7DjItI6GnKRlsqYMeOzM6MzFrSTocxFfrTAjr1jTE5NAxrWkog9dDPbYGbHzOy4mW0PueYTZnbYzMbM7G9a20xJiqBgXuu4NCc/WmDb80cuBnMoltXd9o0jWrzVw+oGdDPLAE8AtwArgc1mtrLqmn7ga8Dt7r4K+I3WN1WSIBeSlhh2XJqzc/8xpi/M/pCcnnEt3uphUXro64Dj7n7C3d8H9gAbq665B3jB3U8CuPuPWttMSQptZNEZtRZoafFW74oS0HPAqYrH46VjlX4BWGhmf21mr5rZ54KeyMy2mNmImY1MTEw012KJNW1k0Rm1Fmj1L8iGnpN0izIpGjSbVf1d7zLgl4BPAn3A/zSzg+7+/Uv+kftuYDfA4OCgBlVTSrnS7bft5mvZ9vyRwGGXsz8p7jmqe9B7ovTQx4ElFY8XA6cDrvkLd3/P3d8CvgOsaU0TRaTa0ECOnb+xJrC3NX1B4+i9KkpAPwSsMLPlZjYf2ATsrbrmz4B/bGaXmdkC4AbgjdY2VUQq1eqBaxy9N9UdcnH382Z2L7AfyABPufuYmW0tnd/l7m+Y2V8A3wMuAE+6+2vtbLiIFMfSgxZtqQhab4q0sMjd9wH7qo7tqnq8E9jZuqaJSD3bbr52Vu0cZRX1Lq0UFUkwVWCUSgroIgmnrCIpU3EuEZGUUA9d5iQ/WtDXfZGYUECXplVvZlGYnOL+F44CtVPqpH30AdvbNOQiTXv4xbFZm1lMTc9oUUuXlD9gC5NTOB98wKr6Yu9QQJem5EcLnDk3HXhOi1q6I2i3KH3A9hYFdGlKrSChRS3dEfZBqg/Y3qGALk2pFSS0qKU7wj5I9QHbOxTQpSlhQaK/L6tJuC5RLXpRQJemhAWPHbev6lKLRLXoRWmL0hQtOY8nrRrtbQro0jQFD5F4UUCXhmnxikg8KaBLQ7Q6VCS+NCkqDdHiFZH4ihTQzWyDmR0zs+Nmtj3g/CfM7B0zO1z682DrmypxoMUrIvFVd8jFzDLAE8CnKG4GfcjM9rr761WX/nd3/+dtaKPEiLY8E4mvKD30dcBxdz/h7u8De4CN7W2WxJUWr4jEV5SAngNOVTweLx2r9itmdsTMvmVmgatLzGyLmY2Y2cjExEQTzZVu0+IVkfiKkuViAce86vF3gavd/ayZ3QrkgRWz/pH7bmA3wODgYPVzSEIo/1wknqL00MeBJRWPFwOnKy9w93fd/Wzp7/uArJld2bJWiohIXVF66IeAFWa2HCgAm4B7Ki8ws48B/9fd3czWUfyg+HGrGysizdFisN5QN6C7+3kzuxfYD2SAp9x9zMy2ls7vAu4CvmBm54EpYJO7a0glRRQQkkuLwXqHdSvuDg4O+sjISFd+tjSmOiBAMbNFk6HJsH74QGCqaa6/j5e339SFFslcmNmr7j4YdE4rRaUurQ5NNi0G6x0K6FJXUO8OFBCSQjsZ9Q4FdKkpP1oIzFsFBYSk0GKw3qFqi1LTzv3HZi06gOLiBAWEZNBmJL1DPXSpKWxYxVGGRJIMDeR4eftNfOXutQD87rOHWT98gPxoobsNk5ZSD11q6l+Q5cy56VnHcxpuSRylL6afeugSKj9a4OxPzs86ns2YhlsSSNlK6aeALqF27j/G9IXZI+iXz79MPboEUvpi+imgS6iwdMV3pmYPwUj8KX0x/RTQJZDSFdNH6Yvpp0lRCaR0xfRR+mL6KaBLIKUrppNq2aebAroECts7VOmKIs1rd9VSBXQJtO3mawMrLGq4RaRx+dECO/aOMVmRUNCOdQCaFJVA2jtUpDXKC7omA7LDWr0OQD10CaXxVpG5C1rQVamV6wAi9dDNbIOZHTOz42a2vcZ1v2xmM2Z2V8taWCE/WmD98AGWb39JdShEJBHqBexWpgHXDehmlgGeAG4BVgKbzWxlyHX/ieJWdS1X/tpSmJzCKY4/ffHZwwz8x79UYBdpkjpJ7VcrYLd6XirKkMs64Li7nwAwsz3ARuD1quv+LfBN4Jdb1roKYV9bzpybVoEhkSaoWFf7VGaz9C/Ikp1ns8poLFyQ5aHbVnU8yyUHnKp4PA7cUHmBmeWAO4CbqBHQzWwLsAVg6dKlDTW01teWqekZ7nvuCKBfRJGoahXr0vuoeQ/kj/L1gycvLsw7c26abMbo78vyztR0Wxd0RQnoQSvAqxcRfhX4krvPmIUtGAd33w3shuIm0RHbCITnRZfNuKt3IdIAFetqvfxo4ZJgXjY941z+ocs4/NCn2/rzo0yKjgNLKh4vBk5XXTMI7DGz/w3cBXzNzIZa0cCyoDoU1aamZ3j4xbFW/liR1FKxrtZ7+MWxwJIZ0JkPyigB/RCwwsyWm9l8YBOwt/ICd1/u7svcfRnwDeBfu3u+lQ0t50X392VrXnfm3LQmdkQiCOokGfBr1y3qToMSLj9aCNwMpqwTH5R1A7q7nwfupZi98gbwnLuPmdlWM9va7gZWGhrIcfihT/PVu9eSqTG0o4L9IvUNDeT49V/KXTKm6sA3Xy2oU9SEHXvDRwc6VdQu0sIid98H7Ks6tivk2n8592bVVh4j/+KzhwPPawxQJJpvvzkxa4hAE6ONy48WAleCln32xqUd+f9M7NL/oYFc6PCLxgBFotHEaGvUGhXo78vyyNDqjrQjsQEdYMftqwInSguTU1xz/z4eyB/tQquSR4tLepcmRluj1gfgjttXdawdiQ7olQWkqs248/TBkwrqdQStwL3/haMK6j0iLHvsvZ+e1+9AA8I+ABcuyHZ06CrRAR2KQf3l7TeFTpI+88qpwONSpJ3ge1u5U7RwwaXDl5NT0/pgb0DY9n4P3da53jmkIKCXzXhw9mfYcSkKW6xVaxGXpMvQQI4F82fnR+iDPbq4lJtOTfncjFlg8K6V3ihgBkGfefp/6y2aHJ27OJSbTk0PffMNSxo6LsXx87AvMPpm01s0OZoOqQnojwyt5l/cuPRizzJjxvprruDbb04oeyNEra/T2ju0t2jVaHRxzgpLzZALFIN6Od9TpUHrq/V1WnuH9pahgRwjP3z7ksJS5VWjg1dfofdMSXUlxbjFldT00Kspe6O+uKRaSTzUWjUq4ZUU4/R/lNqArkme+uKSaiXxoPdMbd2upBhFagO6Jnnqi0uqlcSD3jPh4lBJMYpUjaFX2nbztZeMoUPr9+9LgzikWkk86D0TrtaQSqcqKUaR2oBeDlLlff3aue1T0lTud6j/FynTeyZcrSGVTlVSjMK8S/nGg4ODPjIy0tGfqUA2O/sHir0wDbWIhFs/fCBw9XR/X7bt28pVM7NX3X0w6FykMXQz22Bmx8zsuJltDzi/0cy+Z2aHzWzEzP7RXBvdavnRAtueP3JJEaptzx+JVQ5pJyj7R6RxYQkEnaykGEXdgG5mGeAJ4BZgJbDZzFZWXfZXwBp3Xwv8FvBki9s5Zzv2jjF94dJvI9MXvOYuI2mkTAaRxiUlgSDKGPo64Li7nwAwsz3ARuD18gXufrbi+sshNLuna8J2E6m1y0gaXdXfF/jVMS6z9CJxETRE+/L2m7rdrJqiDLnkgMoatOOlY5cwszvM7E3gJYq9dImhsK+OcZmlF4mDpO4TECWgB5Xdm9UDd/c/dffrgCHg9wKfyGxLaYx9ZGJioqGGzlV1ved6x9MqKV8dRbopqXNNUYZcxoHKkoWLgdNhF7v7d8zsGjO70t3fqjq3G9gNxSyXJtrbtIduW8W2bxxheuaDH5vNWE+uilTuuUhtSZ1ritJDPwSsMLPlZjYf2ATsrbzAzP6+WbHMoZldD8wHftzqxs7F0ECOnXetuaRnuvOuNQpsIjJLUlfN1u2hu/t5M7sX2A9kgKfcfczMtpbO7wJ+HficmU0DU8Dd3q0E9xrUMxWRKJK6aranFhaJiNRSmdnSvyCLO7wzNR2rhYi1Fhaldum/iLROL6yyrl5FfebcNH3ZDF+5e21iXmtqqy2KSGskNYWvUUnNbKmkgC4iNYUFuodfTNcq66RmtlRSQBeRmsIC2plz06nppedHC8yzoCU38c9sqaQx9JIH8kd55pVTzLiTMWPzDUsu7k8q0svCykVAsfeelPHlMOUhpZmABJEkZLZUUg+dYjB/+uDJizd0xp2nD57kgfzRLrdMpPtqBbQkDUeECRpSAsiYJW4VtQI68Mwrpxo6LtJLhgZy9PcFl8hI0nBEmLAPpQvuiQrmoIAOEPhVq9ZxkV6z4/ZVqS3qltRVoUEU0Cl+tQqzfvhAaiZ+RJqV5qJuaapAqklRYPMNS3j64MnAc4XJKbZ94whAKn55RZqV1tIZadpLVUv/SyqzXIIsXJBl9MHO7h0oIlJtznuK9oJHhlbzt4/eGnr+zLne2tlIRJJHQy4i0lPSXJdGAb1Kf182cJ/RsLQtEUmO6gJc5bo0kI45Mg25VNlx+yqy8y7NesnOM3bc3ns7G4mkTRoKcNWiHnqVNM14i8gH8qOF0BIGaVjxChEDupltAB6nuGPRk+4+XHX+s8CXSg/PAl9w9yOtbGgnpTU9S6RXlYdawiRxEVGQugHdzDLAE8CnKG4YfcjM9rr76xWX/QD4VXc/Y2a3UNwI+oZ2NFhE4iUJk4xh9VoguYuIgkTpoa8Djrv7CQAz2wNsBC4GdHf/HxXXHwQWt7KRIhJPSZlkrDWkkpYVrxBtUjQHVFapGi8dC/PbwLeCTpjZFjMbMbORiYmJ6K2MgfxogfXDB1i+/SWVAxApScokY9iQSq6/LzXBHKIF9KBCJ4HLKc3s1ygG9C8FnXf33e4+6O6DixYtit7KLuuVLbhEGpWUXX7SVK+lligBfRxYUvF4MXC6+iIz+0XgSWCju/+4Nc2Lh6T0QkQ6LSmVCtNcXKxSlDH0Q8AKM1sOFIBNwD2VF5jZUuAF4Dfd/fstb2WXJaUXItJp226+9pIxdIhvz7cXstfq9tDd/TxwL7AfeAN4zt3HzGyrmW0tXfYg8PeAr5nZYTOLT9WtFgjrbTgqryu9rVd6vkmhaosRVM/kV+vLZvRLLCIdUavaolaKRlC5ejRopVl5PL0bAT0JOcAi0hmq5RLR0ECOl7ffFJjyA90ZT1f2jYhUUkBvUJxm9ZV9IyKVFNAbFKd8VmXfiEglBfQGxWlWP07fFkSk+zQp2oTqfNYH8ke577kjzLiTMWPzDUt4ZGh129uRpBxg6T2V+/R28n3RyxTQ5+iB/FGePnjy4uMZ94uP2/3Lq9rtElfdfF/0MuWhz9E19+9jJuD/MGNWc9NpkTTT+6J9auWhawx9joJ+aWsdF+kFel90hwL6HGUsODM97LhIL9D7ojsU0Odo8w1LGjou0gv0vugOTYrOUXmCp3o2f/DqK1g/fECTldKTwt4XmhBtL02KtkFYMa/+viw7bl+lwC4iTVNxrg4L25B2cmo6lvstiiSBCtHVp4DeBrWW3k9Nz3Dfc0cABXXpXY0G56RsRt1tCuhtcFV/X2CZ3bIZd3732cOM/PDti2OK5V/wwuQUGTNm3MmpFyIp1Ghwzo8WLq7ErtTNstVxFWkM3cw2AI8DGeBJdx+uOn8d8EfA9cB/cPffr/ecvTiGHqa/L8t7759nemb2vdDmGZI264cPBHZ4+vuyXP6hy2p2hqoZ8IPhf9bC1sXfnBYWmVkGeAK4BVgJbDazlVWXvQ38O6BuIO8F5QJeCxdkI10/OTUdGMxB5XAlfcKGJCenphsK5qBCdNWi5KGvA467+wl3fx/YA2ysvMDdf+Tuh4DpNrQxkYYGcow++Gm+evfaOS+mUDlcSZNWBWEVopstSkDPAacqHo+XjjXMzLaY2YiZjUxMTDTzFIkzNJDjsc+sCd3pKAr1QiRNgvYUaFTGTEORAaIE9KBY1FTyurvvdvdBdx9ctGhRM0+RSEMDOT5749Kmgrp6IZI2QXsKRB2ehOJ74rHPrFEwDxAly2UcqFyvuxg43Z7mpNcjQ6sZvPqKi5ksxqWfitl5xkc+fBlnzk0ry0VSr3pPgaiJBHpP1BYloB8CVpjZcqAAbALuaWurUqryl1iLJEQ+UFnbv3pitC87j0fv/EW9PyKImrZ4K/BVimmLT7n7l81sK4C77zKzjwEjwM8CF4CzwEp3fzfsOdOctigi0i5zXvrv7vuAfVXHdlX8/f9QHIoREZEuUflcEZGUUEAXEUkJBXQRkZRQQBcRSYmubXBhZhPADxv8Z1cCb7WhOZ2U9NeQ9PaDXkNc6DU052p3D1yZ2bWA3gwzGwlL10mKpL+GpLcf9BriQq+h9TTkIiKSEgroIiIpkbSAvrvbDWiBpL+GpLcf9BriQq+hxRI1hi4iIuGS1kMXEZEQCugiIikRu4BuZhvM7JiZHTez7QHnzcz+S+n898zs+m60s5YIr+ETZvaOmR0u/XmwG+2sxcyeMrMfmdlrIedjfR8itD8J92CJmX3bzN4wszEz+52Aa+J+H6K8hljfCzP7sJn9LzM7UnoNDwdcE4/74O6x+UOxPO/fAj8PzAeOUCzDW3nNrcC3KO6kdCPwSrfb3cRr+ATw591ua53X8U+A64HXQs7H/T7Ua38S7sHHgetLf/8Z4PsJfD9EeQ2xvhel/9uPlP6eBV4BbozjfYhbD73uhtSlx3/iRQeBfjP7eKcbWkOU1xB77v4d4O0al8T6PkRof+y5+9+5+3dLf/9/wBvM3s837vchymuItdL/7dnSw2zpT3U2SSzuQ9wCepQNqVu2aXWbRG3fr5S+wn3LzFZ1pmktFff7EEVi7oGZLQMGKPYOKyXmPtR4DRDze2FmGTM7DPwI+G/uHsv7EGmDiw6KsiF1yzatbpMo7fsuxXoMZ0u7QeWBFe1uWIvF/T7Uk5h7YGYfAb4JfNFn7wKWiPtQ5zXE/l64+wyw1sz6gT81s3/o7pXzM7G4D3HroUfZkDrum1bXbZ+7v1v+CufF3aCyZnZl55rYEnG/DzUl5R6YWZZiIPy6u78QcEns70O915CUewHg7pPAXwMbqk7F4j7ELaBf3JDazOZT3JB6b9U1e4HPlWaVbwTecfe/63RDa6j7GszsY2Zmpb+vo3gfftzxls5N3O9DTUm4B6X2/SHwhrv/55DLYn0foryGuN8LM1tU6pljZn3APwXerLosFvchVkMu7n7ezO4F9vPBhtRjVrEhNcW9TW8FjgPngM93q71BIr6Gu4AvmNl5YArY5KWp8rgws2coZh9caWbjwEMUJ4MScR8itD/29wBYD/wmcLQ0fgvw74GlkIz7QLTXEPd78XHgv5pZhuKHzXPu/udxjEta+i8ikhJxG3IREZEmKaCLiKSEArqISEoooIuIpIQCuohISiigi4ikhAK6iEhK/H/PGo+LmHgGeAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_train[:,2], y_train, \"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b0b63baf4ce45428cb1a7f7a107edbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.07010439938315038\n",
      "epoch: 1, loss: 0.06417703168984619\n",
      "epoch: 2, loss: 0.0637701954653251\n",
      "epoch: 3, loss: 0.0627859736108793\n",
      "epoch: 4, loss: 0.06119073174377905\n",
      "epoch: 5, loss: 0.0583120683919079\n",
      "epoch: 6, loss: 0.054030508653060985\n",
      "epoch: 7, loss: 0.049880394656081205\n",
      "epoch: 8, loss: 0.04709510893741544\n",
      "epoch: 9, loss: 0.04308720745331316\n",
      "epoch: 10, loss: 0.0397028963836519\n",
      "epoch: 11, loss: 0.037313584163025645\n",
      "epoch: 12, loss: 0.035222820645219956\n",
      "epoch: 13, loss: 0.03314572444081112\n",
      "epoch: 14, loss: 0.03147954632655843\n",
      "epoch: 15, loss: 0.029526322398561497\n",
      "epoch: 16, loss: 0.028462326514156054\n",
      "epoch: 17, loss: 0.026711108906601586\n",
      "epoch: 18, loss: 0.025812384818126338\n",
      "epoch: 19, loss: 0.024986153714176257\n",
      "epoch: 20, loss: 0.024145587702151833\n",
      "epoch: 21, loss: 0.023793497678624608\n",
      "epoch: 22, loss: 0.02395881468179138\n",
      "epoch: 23, loss: 0.024098559159076393\n",
      "epoch: 24, loss: 0.0240971263692222\n",
      "epoch: 25, loss: 0.0237515608277706\n",
      "epoch: 26, loss: 0.02388762705987439\n",
      "epoch: 27, loss: 0.023558602892235103\n",
      "epoch: 28, loss: 0.023044231342424407\n",
      "epoch: 29, loss: 0.022910879483471588\n",
      "epoch: 30, loss: 0.02281367036302546\n",
      "epoch: 31, loss: 0.022572783521794967\n",
      "epoch: 32, loss: 0.022538316832482162\n",
      "epoch: 33, loss: 0.022204936446471386\n",
      "epoch: 34, loss: 0.021885310534537895\n",
      "epoch: 35, loss: 0.021591915832538503\n",
      "epoch: 36, loss: 0.021641797060588237\n",
      "epoch: 37, loss: 0.021957968487297773\n",
      "epoch: 38, loss: 0.021477094424925066\n",
      "epoch: 39, loss: 0.021307905232878906\n",
      "epoch: 40, loss: 0.02161193589336906\n",
      "epoch: 41, loss: 0.021461374433894585\n",
      "epoch: 42, loss: 0.021487761243167324\n",
      "epoch: 43, loss: 0.021091559428794263\n",
      "epoch: 44, loss: 0.021508774391526125\n",
      "epoch: 45, loss: 0.021219978207596135\n",
      "epoch: 46, loss: 0.020992684538846066\n",
      "epoch: 47, loss: 0.021004244870909558\n",
      "epoch: 48, loss: 0.021172270210150293\n",
      "epoch: 49, loss: 0.02132581830410922\n",
      "epoch: 50, loss: 0.02118207065328946\n",
      "epoch: 51, loss: 0.02110452470008766\n",
      "epoch: 52, loss: 0.020999163381864666\n",
      "epoch: 53, loss: 0.020958784836231533\n",
      "epoch: 54, loss: 0.020975296351518114\n",
      "epoch: 55, loss: 0.021102806596233155\n",
      "epoch: 56, loss: 0.021096886356540567\n",
      "epoch: 57, loss: 0.021094717508019036\n",
      "epoch: 58, loss: 0.02083537317122496\n",
      "epoch: 59, loss: 0.020926279933455902\n",
      "epoch: 60, loss: 0.02098379047242366\n",
      "epoch: 61, loss: 0.020980710189971174\n",
      "epoch: 62, loss: 0.02100786016837142\n",
      "epoch: 63, loss: 0.021206428037731147\n",
      "epoch: 64, loss: 0.02102191378929493\n",
      "epoch: 65, loss: 0.021096898427102554\n",
      "epoch: 66, loss: 0.02104761175928788\n",
      "epoch: 67, loss: 0.02078808263971196\n",
      "epoch: 68, loss: 0.020995816355976412\n",
      "epoch: 69, loss: 0.02090199969169293\n",
      "epoch: 70, loss: 0.02099619049258009\n",
      "epoch: 71, loss: 0.020859074361713414\n",
      "epoch: 72, loss: 0.020788865424174522\n",
      "epoch: 73, loss: 0.020936882652176605\n",
      "epoch: 74, loss: 0.020870520335424664\n",
      "epoch: 75, loss: 0.02103503119107726\n",
      "epoch: 76, loss: 0.020890543313453757\n",
      "epoch: 77, loss: 0.021182955482998672\n",
      "epoch: 78, loss: 0.021185276256087623\n",
      "epoch: 79, loss: 0.02093798241763347\n",
      "epoch: 80, loss: 0.02078419340954513\n",
      "epoch: 81, loss: 0.021063896313180414\n",
      "epoch: 82, loss: 0.02083249617416295\n",
      "epoch: 83, loss: 0.020937270999218386\n",
      "epoch: 84, loss: 0.020948389419806795\n",
      "epoch: 85, loss: 0.02088781022927179\n",
      "epoch: 86, loss: 0.02103774170506977\n",
      "epoch: 87, loss: 0.020852557590617295\n",
      "epoch: 88, loss: 0.0208419770266328\n",
      "epoch: 89, loss: 0.02095015206917295\n",
      "epoch: 90, loss: 0.02079150918475817\n",
      "epoch: 91, loss: 0.021002721049556708\n",
      "epoch: 92, loss: 0.020677505199431047\n",
      "epoch: 93, loss: 0.020796827496273682\n",
      "epoch: 94, loss: 0.02091787317676995\n",
      "epoch: 95, loss: 0.020779798407021346\n",
      "epoch: 96, loss: 0.021347720477705473\n",
      "epoch: 97, loss: 0.02089860876426714\n",
      "epoch: 98, loss: 0.020674885538839564\n",
      "epoch: 99, loss: 0.02117115129116977\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(lr=0.1)\n",
    "model = RegularizedModel(n_features=n_features, \n",
    "                             n_targets=1, \n",
    "                             reps=2,\n",
    "                             alpha=0.00,\n",
    "                             backend=backend, \n",
    "                             shots=10000, \n",
    "                             optimizer=optimizer)\n",
    "    \n",
    "model.encoder.reg = False\n",
    "model.train(x_train, y_train, epochs=epochs, verbose=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_train[:,2], y_train, \"o\")\n",
    "plt.plot(x_train[:,2], y_pred3, \"o\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_qiskit",
   "language": "python",
   "name": "env_qiskit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
