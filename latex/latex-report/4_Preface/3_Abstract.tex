%================================================================
%------------------------- Abstract -----------------------------
%================================================================
\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}
\thispagestyle{plain}

In this thesis we have made a Python framework for implementing machine learning models based on parameterized quantum circuits that are evaluated on quantum hardware. The framework is capable of implementing quantum neural networks (QNNs) and quantum circuit networks (QCNs). The latter, which is the main topic of this thesis, is a multi-circuit machine learning model. To train the models on data, we have implemented gradient-based methods using their analytical gradients. For quantum neural networks, we utilize the parameter shift rule to calculate the gradient analytically on quantum hardware. For quantum circuit networks, we have developed a backpropagation algorithm based on the parameters shift rule. We perform a numerical study where we seek to characterize how dense neural networks (DNNs), QNNs and QCNs behave as a function of model architecture. We focus on investigating the vanishing gradient phenomenon, and quantifying the models trainability and expressivity using the empirical fisher information matrix (EFIM) and trajectory length, respectively. We also test the performance of the models by training them on mixed Gaussian data in one, two and three dimensions, as well as on the real-world data sets Boston Housing data and Breast Cancer Wisconsin data. The models are trained on both ideal and simulated noisy quantum hardware.

For QCNs, we found that the magnitude of their local gradients stayed constant (and not decreasing) when increasing the number of layers of the model. This indicates that the model size of QCNs can be increased by adding additional layers of circuits without significantly increasing the computational overhead on quantum hardware. However, we showed that performing backpropagating with the local gradients still induce a vanishing gradient for the QCN, exponentially so in the number of layers and qubits. From this, large QCNs are likely intractable to train, like DNNs and QNNs. For few qubits, we showed that QCNs have a larger gradient and a can obtain a higher expressivity than similarly sized DNNs, indicating that they should train faster and make a better fit to data. When training the QCNs and DNNs on the mixed Gaussian data, we showed that QCNs of few qubits and layers indeed trained faster and achieved a better fit than similar DNNs. This holds true also when simulated on noisy hardware, showing that small QCNs are suitable for near-term quantum computers. On the other hand, the QNNs implemented in this thesis were unable to make a good fit to the mixed Gaussian data, for neither the ideal nor noisy simulation. This suggests that either the encoding or the ansatz (or both) used to construct the QNNs are unfit for fitting nonlinear data. For the real-world data, we found that QCNs generalized better than DNNs to unseen data for the Boston Housing data, and even more so using noisy simulation. However, this was not the case for the Breast Cancer data. This suggests that QCNs have merit for some data sets, even using today's quantum computers.