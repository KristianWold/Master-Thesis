%================================================================
\chapter{Implementation}\label{chap:implementation}
%================================================================
In this chapter, we will present details surrounding implementation of algorithms and methods presented in \autoref{part:Theory}. For this thesis, we have developed an elaborate frame work for doing machine learning, capable of implementing dense neural networks(DNN, \autoref{eq:DNN}) and quantum circuit networks(QCN, \autoref{eq:QCN}). In addition, various numerical tools for analyzing the models are available. The code base is object-orientated using Python, focusing on flexibility. This grants a high degree freedom when specifying model architecture, such as setting the number of layers, number of nodes, type of activation functions, loss function and optimizer. The frame work is also capable of implementing hybrid models mixing both DNN and QCN layers. To allow implementation of quantum machine learning, the frame work is built around Qiskit\cite{Qiskit}, an IBM-made python-package used for emulating quantum circuits. 

All source code developed for this thesis can be found on our GitHub page \url{https://github.com/KristianWold/Master-Thesis}, together with notebooks containing training of models, generation of data, analysis and plotting. For easier reading, all python types referred to in this thesis will be highlighted in \textbf{bold}. All simulations in this thesis were performed on an Ubuntu desktop computer equipped with a Ryzen 3900x CPU and 32 GB RAM.

%================================================================
\section{Qiskit}\label{sec:Qiskit}
%================================================================

Qiskit\cite{Qiskit} is an open source python-package used for practically emulating quantum circuits and quantum algorithms. It can be installed using pip with the following command:

\begin{lstlisting}[language=bash]
  $ pip install qiskit
\end{lstlisting}
To import the package, include the following among the import in any python scrip:
\begin{lstlisting}[language=python]
  import qiskit as qk
\end{lstlisting}

%================================================================
\subsection{Registers and Circuits}\label{sec:QMLE}
%================================================================

To create a quantum circuit in Qiskit, one can first create one or more \emph{quantum registers}, which are list structures containing qubits. The registers can be put together into a circuit in the following way:

\begin{lstlisting}[language=python, numbers=left]
q_reg_1 = qk.QuantumRegister(2)
q_reg_2 = qk.QuantumRegister(2)
c_reg = qk.ClassicalRegister(2)
circuit = qk.QuantumCircuit(q_reg_1, q_reg_2, c_reg)
\end{lstlisting}
Here, each of the registers \textbf{q\_reg\_1} and \textbf{q\_reg\_2} contains two qubits. By default, they are each initialized in the state $\ket{0}$. Thus, the total circuit can be written as
\begin{equation}
    \ket{00}\ket{00},
\end{equation}
where each \emph{ket} refers to one register. Further, \textbf{c\_reg} is a \emph{classical register} of classical bits, meant for storing classical information when the circuit is later measured. In general, a circuit can contain any number of quantum registers with any number of qubits. However, if one wishes to include a classical register, it must be included as the last argument in \textbf{qk.QuantumCircuit()}.

%================================================================
\subsection{Applying Gates}\label{sec:operationsOnQubits}
%================================================================

Continuing after creating our circuit, we can apply a variety of quantum gates by calling different methods for the \textbf{circuit} object. Hadamard gates can be applied to the two qubits of register \textbf{q\_reg\_1} in the following way:

\begin{lstlisting}[language=python, numbers=left]
circuit.h(q_reg_1[0])
circuit.h(q_reg_1[1])
\end{lstlisting}

This prepares the state 
\begin{equation*}
    \ket{00}\ket{00} \rightarrow 
    \big(\frac{1}{2}\ket{00} + \frac{1}{2}\ket{01} +
    \frac{1}{2}\ket{10} + \frac{1}{2}\ket{11}\big)\ket{00}  
\end{equation*}


A possible way of creating entanglement between the registers is to use CNOT gates on \textbf{q\_reg\_2} conditioned on the qubits in \textbf{q\_reg\_1}:


\begin{lstlisting}[language=python, numbers=left]
circuit.cx(q_reg_1[0], q_reg_2[0])
circuit.cx(q_reg_1[1], q_reg_2[1])
\end{lstlisting}
resulting in the state 

\begin{equation*}
\begin{aligned}
\big(\frac{1}{2}\ket{00} + \frac{1}{2}\ket{01} +
\frac{1}{2}\ket{10} + \frac{1}{2}\ket{11}\big)\ket{00} \rightarrow \\
\frac{1}{2}\ket{00}\ket{00} + \frac{1}{2}\ket{01}\ket{01} +
\frac{1}{2}\ket{10}\ket{10} + \frac{1}{2}\ket{11}\ket{11}
\end{aligned}
\end{equation*}


For a complete documentation of the gates available in Qiskit, see \url{https://qiskit.org/documentation/stubs/qiskit.circuit.QuantumCircuit.html}.

%================================================================
\subsection{Measurement}\label{sec:MeasurementQiskit}
%================================================================

To measure the state of \textbf{q\_reg\_2} in the computational basis and store it to \textbf{c\_reg}, we make use of the method \textbf{measure()}:

\begin{lstlisting}[language=python, numbers=left]
  circuit.measure(q_reg_2, c_reg)
\end{lstlisting}

Finally, to repeatedly execute the circuit and sample the results, we make use of \textbf{qk.execute} together with the backend \emph{qasm\_simulator}:


\begin{lstlisting}[language=python, numbers=left]
job = qk.execute(circuit, 
                 backend = 
                 qk.Aer.get_backend("qasm_simulator"),
                 shots = 1000)
result = job.result().get_counts(circuit)
print(result)
\end{lstlisting}

\begin{flalign*}
    & \rightarrow \{'00':261, '01':242, '10':253, '11':244\} &
\end{flalign*}
This results in a python dictionary whose keys are strings indicating the different states that were measured. The value corresponding to each key is the number of times that state was measured. To set the number of times to execute and measure the circuit, the argument \textbf{shots} may be used. In this case, it was set to 1000. Using \textbf{qk.Aer.get\_backend("qasm\_simulator")} as the backend, the circuit is simulated locally on the classical machine in an ideal fashion, meaning the imperfections of real quantum computers as described in \autoref{sec:Nisq} are disregarded. Still, since a finite number of shots was used, the normalized results $\frac{261}{1000}$, $\frac{242}{1000}$, $\frac{253}{1000}$ and $\frac{244}{1000}$ only approximate the exact value $\frac{1}{4}$. 

%================================================================
\subsection{Exact Expectation Value}\label{sec:Exact Expectation Value}
%================================================================

When simulating circuits on classical hardware, e.g. with Qiskit, we have the luxury of accessing the state resulting from some computation directly and calculate exact expectation values. As explained in \autoref{sec:MeasuringState}, this is not possible when using real quantum computers. Having access to exact expectation values is useful when the noise of finite sampling or realistic hardware is uninteresting for the analysis. 

To access the exact state, the classical register \textbf{c\_reg} must be omitted from the circuit, as we never plan to measure it in the ordinary way. Then, the circuit is simulated using the \emph{statevector\_simulator} backend:

\begin{lstlisting}[language=python, numbers=left]
job = qk.execute(circuit, 
                 backend = 
                 qk.Aer.get_backend("statevector_simulator"))
result = job.result().get_counts(circuit)
print(result)
\end{lstlisting}
\begin{flalign*}
    & \rightarrow \{'00':0.25, '01':0.25, '10':0.25, '11':0.25\} &
\end{flalign*}
Here, the "measurements" are exact and normalized, as if infinitely many shots were used for sampling. 


%================================================================
\subsection{Simulating Real Devices}\label{sec:Simulating Real Devices}
%================================================================

Even though a given quantum algorithm may produce a satisfying result when executed on idealized hardware, like simulated with Qiskit, this may not apply when run on real hardware. This is due to the introduced noise and inaccuracies as explained in \autoref{sec:Nisq}. To produce a more realistic result, Qiskit allows for realistic simulation of many noisy IBM quantum computers by choosing an appropriate backend. 

\subsubsection*{Noisy Backend}

There are three main components for simulating noisy devices. The first is the \emph{noise model} is responsible for implementing noise and inaccuracies present in the real hardware. In Qiskit, noise models have 4 components that determine the total model:

\begin{itemize}
    \item \textbf{Decoherence} Error resulting from interactions from the enviroment on the qubits, such as thermal noise.
    \item \textbf{Gate Error}: Error resulting from application of gates.
    \item \textbf{Gate Length}: Error resulting from the length of the gate.
    \item \textbf{Gate Length}: Error resulting from the measurement of the qubits. 
\end{itemize}

The next component is a \emph{coupling map} that defined which the coupling of the qubit, i.e. what pairs of qubits that can interact via two-qubits gates (see \autoref{sec:Nisq}). The last component defines the basis gates of the quantum computer. 

In this thesis, we will be using the IBM quantum computer Santiago \cite{santiago}, which has 5 qubits with only linear connectivity between the qubits. This choice is deliberate, as qubit encoding and the simple ansatz are specially made to work efficiently on such architectures. To access and store the backend simulating this quantum computer, we can use the following code:

\begin{lstlisting}[language=python, numbers=left]
import pickle
from qiskit.providers.aer import QasmSimulator
from qiskit import IBMQ

IBMQ.enable_account(token)
backend = provider.get_backend('ibmq_santiago')
backend = QasmSimulator.from_backend(backend)
pickle.dump(backend, open("backend_santiago", "wb"))
\end{lstlisting}

Here, \textbf{token} is a string identifying an IBM account necessary for accessing the correct backend. 
\textbf{backend = QasmSimulator.from\_backend(backend)} pulls the necessary components describes earlier and implements them into the \textbf{QasmSimulator} backend, ready to be used for noisy simulation. 

\subsubsection*{Transpiling}
When using a noisy backend, it is important to transpile the circuit prior to simulation, because the gates must be decomposed into the correct basis gates, and such that the specific coupling map is respected. Transpiling a circuit with respect to a given backend is done automatically when executing the circuit:

\begin{lstlisting}[language=python, numbers=left]
jov = qk.execute(transpile(circuit, noisy_backend, seed_transpiler=42, seed_simulator=42)
\end{lstlisting}
Here, the \textbf{seed\_transpiler} and \textbf{seed\_simulator} are seeds that make the work of the transpiler and the noise model reproducible. In this thesis, they will be set to $42$. Transpiling will also apply a light optimization of the the circuit, in the sense that it will attempt to reduce the number of basis gates needed to reproduce the circuit. This is particularly important, since we want the depth to be as shallow as possible. Heavier optimization routines may be used to reduce the circuit even more, with the price of more time spent transpiling.  






%================================================================
\section{QNN Example}\label{sec:QNNimpement}
%================================================================
We will now present a possible way of implementing a QNN \autoref{eq:QNN} for fitting data. The model will be optimized using the parameter shift rule and gradient descent. 

%================================================================
\subsection{Encoding}
%================================================================

To encode the data, we will make a callable object on the form \textbf{circuit = encoder(circuit, data\_reg, data)}, where \textbf{data\_reg} is a quantum register of \textbf{circuit}, and \textbf{data} is a numpy array containing the features of one sample. Qubit encoding using $R_x$ rotations, as presented in \autoref{sec:QubitEncoding}, can be implemented as the following function:

\begin{lstlisting}[language=python, numbers=left]
def qubit_encoder(circuit, data_reg, data):
    for i, x in enumerate(data):
        circuit.rx(x, data_register[i])
        
    return circuit
\end{lstlisting}

This function requires that the number of features does not exceed the number of qubits.

%================================================================
\subsection{Ansatz}
%================================================================
To implement the ansatz, we want a callable object on the form 
\textbf{circuit = ansatz(circuit, data\_reg, theta, reps)}, where \textbf{theta} is a numpy array containing the parameters. The "simple ansatz" detailed in \autoref{sec:Ansätze} can be implemented as a python function:

\begin{lstlisting}[language=python, numbers=left]
def simple_ansatz(circuit, data_reg, theta):
    n_qubits = data_reg.size()
    
    for i range(n_qubits - 1):
        circuit.cx(data_reg[i], data_reg[i+1])
    
    for i, w in enumerate(theta):
        circuit.ry(w, data_register[i])
        
    return circuit
\end{lstlisting}
Here, \textbf{data\_reg.size()} was used to retrieve the number of qubits present in the register. The first for-loop entangles the qubits in sequence using CNOT gates. The last for-loop applies an $R_y$ rotation to each qubit corresponding to the parameters.

%================================================================
\subsection{Model Output}\label{sec:InferenceImplementation}
%================================================================
To derive a model output, we must estimate an expectation value as explained in \autoref{sec:Inference}. We can do this by making a callable object \textbf{y\_pred = sampler(counts)}, where \textbf{counts} is a python dictionary containing the measuring results, as explained in \autoref{sec:MeasurementQiskit} and \autoref{sec:Exact Expectation Value}. We can implement a function estimating the parity(see \autoref{sec:Inference}) in the following way:

\begin{lstlisting}[language=python, numbers=left]
def parity(counts):
    shots = sum(counts.values())
    
    output = 0
    for bitstring, samples in counts.items():
        if parity_of_bitstring(bitstring) == 1:
            output += samples

    output = output / shots

    return output
\end{lstlisting}
where \textbf{parity\_of\_bitstring(bitstring)} is a function that calculates the parity of a bitstring, which can be implemented as 
\begin{lstlisting}[language=python, numbers=left]
def parity_of_bitstring(bitstring):
    binary = [int(i) for i in bitstring]
    parity = sum(binary) % 2
    
    return parity
\end{lstlisting}

The function \textbf{parity()} iterates over the different measured states and makes a weighted average of their parities, resulting in the estimation of the average parity of the state.

To perform the inference, we can implement a function \textbf{qnn(x, theta)}, where \textbf{x} is a numpy array containing features of a single sample, and \textbf{theta} is a numpy array containing parameters. The function can be implemented as 

\begin{lstlisting}[language=python, numbers=left]
def qnn(x, theta):
    n_qubits = len(x)
    reps = 2
    data_reg = qk.QuantumRegister(n_qubits)
    clas_reg = qk.ClassicalRegister(n_qubits)
    circuit = qk.QuantumCircuit(data_reg, clas_reg)
    
    circuit = qubit_encoder(circuit, data_reg, x)
    circuit = simple_ansatz(circuit, theta, reps)

    job = qk.execute(circuit, 
                     backend = 
                     qk.Aer.get_backend("qasm_simulator"),
                     shots = 1000)
    counts = job.result().get_counts(circuit)
    y_pred = parity(counts)
    
    return y_pred
\end{lstlisting}


%================================================================
\subsection{Gradient}\label{sec:GradientImplementation}
%================================================================
Having a function that implements a QNN that performs inference, we can apply the parameter shift rule described in \autoref{sec:AnalyticalGrad} to calculate the gradient of the output with respect to the parameters:

\begin{lstlisting}[language=python, numbers=left]
def gradient(x, theta):
    deriv_plus = np.zeros(len(theta))
    deriv_minus = np.zeros(len(theta))
    
    for i in range(len(theta)):
        theta[i] += np.pi/2 #parameter shifted forward
        deriv_plus[i] = qnn(x, theta) 
        
        theta[i] -= np.pi   #parameter shifted backwards
        deriv_minus[i] = qnn(x, theta)
        
        theta[i] += np.pi/2 #parameter reset
    
    return 0.5*(deriv_plus - deriv_minus) #linear combination
\end{lstlisting}
This function returns a numpy array with the same length as \textbf{theta}, containing the derivatives $\frac{\partial y}{\partial \theta_i}$.

%================================================================
\subsection{Training}\label{sec:QNNTraining}
%================================================================

Finally, we can implement a function \textbf{train(x\_list, y\_list, theta, lr, epochs)} that calculates the average gradient \autoref{eq:averageGradient} resulting from the samples and targets \textbf{x\_list} and \textbf{y\_list}, using MSE loss. The function then updates the parameters \textbf{theta} iterative(\textbf{epochs} number of times) using gradient descent with learning rate \textbf{lr}:

\begin{lstlisting}[language=python, numbers=left]
def train(x_list, y_list, theta, lr, epochs):
    loss = []
    for i in range(epochs):
        grad = np.zeros(len(theta))
        loss.append(0)
        
        for x, y in zip(x_list, y_list):
            y_pred = qnn(x, theta)      #inference
            loss[-1] += (y_pred - y)**2 #accumulate loss        
            grad = grad + (y_pred - y)*gradient(x, theta)
        
        loss[-1] = loss[-1]/len(y)      #normalize
        grad = grad/len(y)
        theta += -lr*grad               #update parameters
    
    return theta, loss
\end{lstlisting}

At line 10, \textbf{grad += (y\_pred - y)*gradient(x, theta)} accumulates the gradient of the MSE loss function with respect to the parameter, i.e. \autoref{eq:LossDerivateWRTparameter}. The parameters are then updated at line 14.


%================================================================
\section{Quantum Circuit Network}\label{sec:QCNimplementation}
%================================================================
In this section, we will introduce how our frame work can used to implement various QCN architectures, and how these can be used to fit data. We will also show how the framework can be used to implements single-circuit QNNs, pure classical DNNS, and hybrid models combining QCN and DNN. 

%================================================================
\subsection{Encoders, Ansätze and Samplers}\label{sec:EAaS}
%================================================================
In the QCN framework, we implement encoders, ansätze and samplers as callable python classes with much the same functionality as described in \autoref{sec:QNNimpement}. We will now go through the use of the most important classes.

\subsubsection*{QubitEncoder}
The encoder class \textbf{QubitEncoder} can be instantiated as 

\begin{lstlisting}[language=python, numbers=left]
from encoders import QubitEncoder

encoder = QubitEncoder(mode)
\end{lstlisting}

Here, \textbf{mode} is a string that specifies the rotation used for encoding, either \textbf{"x"}, \textbf{"y"} or \textbf{"z"}. See \autoref{sec:QubitEncoding} for details.

\subsubsection*{Ansatz}
The ansatz class \textbf{Ansatz} can be instantiated as
\begin{lstlisting}[language=python, numbers=left]
from ansatzes import Ansatz

ansatz = Ansatz(block, reps)
\end{lstlisting}
Here, \textbf{block} is a python list containing strings that specify gates applied to the circuit. For example, 
\textbf{block = ["entangle", "ry"]} will first apply CNOT gates to all neighboring qubits in sequence. $R_y$ rotations are then applied to every qubit. This particular argument recreates the simple ansatz described in \autoref{sec:Ansätze}. \textbf{reps} specifies the number of times the ansatz is then repeated.

\subsubsection*{Parity}
The sampler class \textbf{Parity} can be instantiated as
\begin{lstlisting}[language=python, numbers=left]
from samplers import Parity

sampler = Parity()
\end{lstlisting}
This class implements the same functionality as the \textbf{parity} function described in \autoref{sec:QNNimpement}.

%================================================================
\subsection{QLayer}\label{sec:QLayer}
%================================================================

Our framework for making QCN models implements layers consisting of QNN models as nodes, as explained in \autoref{sec:Quantum Circuit Network}. In the framework, a QCN layer can be created as a python object of the type \textbf{QLayer} as follows:

\begin{lstlisting}[language=python, numbers=left]
from layers import QLayer

qlayer = QLayer(n_qubits,   #number of qubits in each QNN
                n_features, #number of input features
                n_targets,  #number of outputs, i.e. nodes
                scale,      #scaling of output
                encoder,
                ansatz,
                sampler,
                backend,
                shots)
\end{lstlisting}

The arguments \textbf{encoder}, \textbf{ansatz} and \textbf{sampler} define the architecture of each QNN in the layer. Examples of possible choices are described in \autoref{sec:EAaS}. 

As an example, a \textbf{QLayer} can be instantiated and used on a data in the following way:


\begin{lstlisting}[language=python, numbers=left]
import numpy as np
from layers import QLayer
backend = qk.Aer.get_backend("qasm_simulator")

x = np.random.normal((4,3))

np.random.seed(42)
qlayer = QLayer(n_qubits = 3,
                n_features = 3,
                n_targets = 2,
                scale = 2*np.pi,
                encoder = Encoder(mode = "x"),
                ansatz = Ansatz(blocks=["entangle", "ry"],
                                reps = 2),
                sampler = Parity(),
                backend = backend,
                shots=1000)
                
y_pred = qlayer(x)
print(y_pred)
\end{lstlisting}

\begin{left}
\begin{tabular}{ c c c }
 \rightarrow & [[5.19619425 4.29769875] &   \\ 
       & [3.84530941 2.14256619] &   \\  
       & [3.08504399 2.19283167] &  \\    
       & [4.09663682 2.58867235]] &    
\end{tabular}
\end{left}

Here, \textbf{x} is a dataset containing four samples of three features each. By specifying \textbf{n\_targets=2}, the layer consists of two nodes and thus produces two output targets. The layer is callable, and performs inference on the input \textbf{x} sample-wise.

If the number of shots are set to zero, i.e. \textbf{shots=0}, the outputs are exactly calculated with the \emph{statevector\_simulator} backend, as explained in \autoref{sec:Exact Expectation Value}.

%================================================================
\subsection{Constructing QCNs from QLayers}\label{sec:ConstructingNetworks}
%================================================================
In general, a QCN can be constructed with any number of layers, with any number of inputs and outputs. The only constraint is that the outputs of one layer and the inputs of a subsequent layer must match in shape.

A two-layer QNC can be constructed in the following way using the \textbf{NeuralNetwork} class:

\begin{lstlisting}[language=python, numbers=left]
from neuralnetwork import NeuralNetwork

x = np.random.normal(0, 1, (4,3))

#unspecified arguments assumes default values
layer1 = QLayer(n_qubits=3,
                n_features=3,
                n_targets=4) 
                
layer2 = QLayer(n_qubits=4,
                n_features=4,
                n_targets=1)

network = NeuralNetwork(layers = [layer1, layer2],
                        cost = MSE(),
                        optimizer = Adam(lr=0.1))          
y_pred = network.predict(x)
print(y_pred)
\end{lstlisting}
 
In the above code, the \textbf{NeuralNetwork} class stores the layer objects in a python list \textbf{self.layers}. When doing inference, the class implements feed forward, as described in \autoref{sec:FeedForward}, using a \textbf{\_call\_} method:
\begin{lstlisting}[language=python, numbers=left]
def __call__(self, x):
        self.a = []
        self.a.append(x)
        for layer in self.layers:
            x = layer(x)
            self.a.append(x)
\end{lstlisting}
The outputs of all layers are stored, as they are needed during back-propagation. \textbf{network.predict(x)} returns only the output of the last layer, i.e. the model output. 

%================================================================
\subsection{Back Propagation}\label{sec:BackpropImplementation}
%================================================================

The class \textbf{NeuralNetwork} performs back propagation, as described in \autoref{sec:BackwardPropagationQCN}, using a class method \textbf{network.backward(x,y)}. In simplified terms, the method is implemented as:
\begin{lstlisting}[language=python, numbers=left]
def backward(self, x, y):
    self(x)                 #feed forward      
    y_pred = self.a[-1]     #inference
    delta = self.cost.derivative(y_pred, y)

    #work thru layers in reverse
    for i, layer in reversed(list(enumerate(self.layers))):
        weight_gradient, delta = layer.grad(self.a[i], 
                                            delta)
        self.weight_gradient_list.append(weight_gradient)

    self.weight_gradient_list.reverse()
\end{lstlisting}
\textbf{network.backward(x,y)} starts by performing feed forward and inference. In line 4, the error of the last layer \autoref{eq:lastLayerErrorQCN} is initiated as \textbf{delta}. For each layer, starting with the last first, the gradient is calculated and the error \textbf{delta} is updated. This is done using \autoref{eq:derivweightsQCN} and \autoref{eq:errorQCN}, respectively, which is implemented in the layer method \textbf{layer.grad(self.a[i], delta)}.

%================================================================
\subsection{Training}\label{sec:QCNTraining}
%================================================================
To train the QCN, the class method \textbf{network.train(self, x, y, epochs)} can be used. In simplified terms, it is implemented as

\begin{lstlisting}[language=python, numbers=left]
def train(self, x, y):
    self.loss = []
    for i in range(epochs):
        self.backward(x, y)
        self.step()

        y_pred = self.a[-1]
        self.loss.append(self.cost(y_pred, y))
            
    y_pred = self.predict(x)
    self.loss.append(self.cost(y_pred, y))
\end{lstlisting}
The method for training starts by calling \textbf{self.backward} in order to calculate and store the gradient in \textbf{self.weight\_gradient\_list}. Then, the method \textbf{self.step()} is used to update the parameters of the layers. This is done using \autoref{eq:ParameterUpdate}, but with the gradient modified by the specified optimizer. This is then repeated a number of times specified by \textbf{epochs}.

%================================================================
\subsection{Single-Circuit Models}\label{sec:Single-CircuitModel}
%================================================================
Using the \textbf{NeuralNetwork}, it is possible to construct single-circuit QNNs in addition to the usual multi-circuit QCNs. This can be done using a single \textbf{QLayer} with a single node, as this will constitute only one QNN:
\begin{lstlisting}[language=python, numbers=left]
layer = QLayer(n_qubits = 4,
               n_features = 4,
               n_targets = 1,
               encoder = RZZEncoder(),
               ansatz = Ansatz(blocks=["entangle", "ry"],
                               reps=2),
               sampler = Parity(),
               backend = backend,
               shots = 1000)
                               

qnn_model = NeuralNetwork(layers = [layer1])
\end{lstlisting}
As there are no intermediate layers, we do not need to compute the derivative of the node outputs with respect to their inputs. This opens up for ways of encoding where the parameter shift rule, as implemented in \autoref{sec:AnalyticalGrad} and \autoref{sec:GradientImplementation}, fails. Possible choices are RZZ encoding(as used in the above code) and amplitude encoding.

%================================================================
\subsection{Dense Neural Networks}\label{sec:DNNs}
%================================================================
In addition to \textbf{QLayer} layers, the neural network framework also implements \textbf{Dense} layers, which are densely connected, classical layers as defined in \autoref{sec:DenseNeuralNetwork}. It can be instantiated in the following way, and put together to form a DNN:

\begin{lstlisting}[language=python, numbers=left]
from layers import Dense, Sigmoid

dense1 = Dense(n_features = 4,
              n_targets = 3,
              scale = 1,
              activation = Sigmoid(),
              bias = True)
\end{lstlisting}
Here, \textbf{activation} specifies the activation function of the layer, in this case the sigmoid function. Setting \textbf{bias} to true enables the use of bias parameters in the layer. Like \textbf{QLayer}, \textbf{Dense} also implements methods like \textbf{\_call\_} for feed forward, and \textbf{grad()} for back-propagation. A DNN can be set up the following way:

\begin{lstlisting}[language=python, numbers=left]
from layers import Dense, Sigmoid

dense1 = Dense(n_features = 4,
               n_targets = 3,
               scale = 1,
               activation = Sigmoid(),
               bias = True)
               
dense2 = Dense(n_features = 3,
               n_targets = 2,
               scale = 1,
               activation = Sigmoid(),
               bias = True)
               
layers=[dense1, dense2]       
network = Neuralnetwork(layers)
\end{lstlisting}

This opens up for construction of neural networks that consists of an arbitrary combination of \textbf{QLayer} and \textbf{Dense} layers, which can be simultaneously optimized using the methods described in \autoref{sec:QCNTraining}.

%================================================================
\subsection{Hybrid Models}\label{sec:Hybrid Models}
%================================================================
Due to the flexibility of the framework and compatibility of the different layers, it is possible to make hybrid models by combining \textbf{Dense} and \textbf{QLayer} layers:

\begin{lstlisting}[language=python, numbers=left]
dense = Dense(n_features = 64,
              n_targets = 4,
              scale = np.pi,
              activation = Tanh(),
              bias = True)
              
qlayer = QLayer(n_qubits = 4,
                n_features = 4,
                n_targets = 1,
                encoder = Encoder(),
                ansatz = Ansatz(blocks=["entangle", "ry"],
                                reps=2),
                sampler = Parity(),
                backend = backend,
                shots = 1000)
layers=[dense, qlayer]       
network = Neuralnetwork(layers)
\end{lstlisting}
In this code, the initial \textbf{Dense} layer is used to produce 4 outputs from 64 features, which are subsequently fed to the following \textbf{QLayer} layer. It may be useful to construct such hybrid models for training on data sets with many features, since feeding 64 features directly to a QCN would require 64 qubits when using qubit encoding. This high amount of qubits is generally not feasible for near-term hardware. Note that the use of tanh activation and a scaling of $\pi$ ensure that the output of the \textbf{Dense} layer is in $[-\pi, \pi]$, which we argue in \autoref{sec:Configuring QCNs and DNNs} is an appropriate scaling for QCNs.


%================================================================
\section{Tools for Analysis}\label{sec:Tools for Analysis Imp}
%================================================================
In this section, we present details surrounding the implementation of methods in \autoref{chap:TfA}. 


%================================================================
\subsection{Magnitude of Gradients}\label{sec:Magnitude of Gradients}
%================================================================
In order to investigate the vanishing gradient phenomenon discussed in \autoref{sec:BarrenPlateus} for QNNs, QCNs and DNNs, we will calculate the average magnitude of the gradient for different models and architectures. Instead of calculating the gradient of some loss function, i.e. \autoref{eq:LossDerivateWRTparameter}, we will instead calculate the gradient of the model output itself, i.e.
\begin{equation}\label{eq:model gradient}
    \frac{\partial f(\boldsymbol{x}^{(i)};\boldsymbol{\theta})}{\partial \theta_j}.
\end{equation}
Using our framework for neural networks, \autoref{eq:model gradient} is calculated for each data sample using the \textbf{NoCost()} loss function together with sample-wise backward propagation. Given a model \textbf{network}, this can be implemented in the following way:

\begin{lstlisting}[language=python, numbers=left]
network.cost = NoCost()
network.backward(samplewise=True)
\end{lstlisting}

If \autoref{eq:model gradient} vanishes, so does does \autoref{eq:LossDerivateWRTparameter}, for any loss function. The quantity \autoref{eq:model gradient} also has the added benefit of being data agnostic, i.e., it is independent of labels $y^{(i)}$.

Given a QNN $f_{QNN}$, we wish to compute the magnitude of the gradient averaged over $N$ samples $\boldsymbol{x}^{(i)}$ and the parameters $\theta_j$. This allows us to capture the average behavior of the model's gradient. To produce a more significant result, this quantity will finally be averaged over $T$ different realizations of the parameters $\boldsymbol{\theta}^{(k)}$. This quantity can be expressed as

\begin{equation}\label{eq:magnitude QNN}
    \frac{1}{TNn_{\theta}}\sum_{k=1}^T\sum_{i=1}^N \sum_{j=1}^{n_{\theta}}\big|\frac{\partial f_{QNN}(\boldsymbol{x}^{(i)};\boldsymbol{\theta}^{(k)})}{\partial \theta_j}\big|.
\end{equation}

For QCNs and DNNs, we want to compute the same quantity as \autoref{eq:magnitude QNN}, but averaged over the parameters within each layer, rather than all parameters of the model. This enables us to investigate how the average behavior of the gradient changes from layer to layer. This quantity can be formulated as

\begin{equation}\label{eq:magnitude QCN DNN}
    \frac{1}{TNn_{\theta}}\sum_{k=1}^T\sum_{i=1}^N \sum_{j=1}^{n_{\theta}^{l}}\big|\frac{\partial f(\boldsymbol{x}^{(i)};\boldsymbol{\theta}^{k)})}{\partial \theta^{[l]}_j}\big|,
\end{equation}
where $f$ is a QCN or DNN model, $n_{\theta}^{l}$ are the number of parameters in layer $l$, and $\theta^{[l]}_j$ is the j'th of these parameters.


We are also interested in the local gradients of QCNs, \autoref{eq:localGradients}, with respect to the intermediate inputs, i.e. $\frac{\partial a_{m}^{(l)}}{\partial a_{n}^{(l-1)}}$. We will average the magnitude of the local gradients within the same layer $l$, over $N$ samples $\boldsymbol{x}^{(i)}$, and over $T$ different realizations of the parameters. This quantity can be expressed as 

\begin{equation}\label{eq:magnitude local}
    \frac{1}{TNn_{\theta}m^{(l)}m^{(l-1)}}\sum_{k=1}^T\sum_{i=1}^N \sum_{m,n}\big|\frac{\partial a_{m}^{(l)}}{\partial a_{n}^{(l-1)}}\big|,
\end{equation}
where $m^{(l)}$ is the number of nodes in layer $l$, and the indices $m$ and $n$ iterates over nodes in layer $l$ and $l-1$, respectively. Note that the dependence of $\big|\frac{\partial a_{m}^{(l)}}{\partial a_{n}^{(l-1)}}\big|$ on the samples and parameter realizations has been suppressed for clarity.

%================================================================
\subsection{Empirical Fisher Information}\label{sec:FIMImplement}
%================================================================
To investigate the loss landscape of the QCN model, we calculate the EFIM \autoref{eq:EmpiricalFisher} and its eigen value spectrum using a class \textbf{EFIM}. Given some \textbf{network} and data set \textbf{x}, it can be used in the following way:
\begin{lstlisting}[language=python, numbers=left]
from analysis import FIM

fim = FIM(network)
fim.fit(x)
\end{lstlisting}
Calling \textbf{fim.fit(x)} calculates the EFIM of \textbf{network} over the data \textbf{x}, and is implemented as
\begin{lstlisting}[language=python, numbers=left]
def fit(self, x):
    n_samples = x.shape[0]

    self.model.backward(x, samplewise=True)
    gradient = self.model.weight_gradient_list

    gradient_flattened = []
    for grad in gradient:
        gradient_flattened.append(grad.reshape(n_samples, -1))

    gradient_flattened = np.concatenate(gradient_flattened, axis=1)

    self.fim = 1 / n_samples * gradient_flattened.T @ gradient_flattened
\end{lstlisting}
At line 4, the cost function of the network is set to \textbf{NoCost()}. This ensures that \textbf{backward} calculates the gradient of the model output and not any particular loss, which is required by the EFIM. In addition, specifying \textbf{samplewise=True} in the \textbf{backward()} method stops the gradient from being averaged over all the samples. Rather, it is stored individually for each sample. The following for-loop unravels and concatenates all the gradients of the various layers into a single matrix with dimension $(N, n_{\theta})$, which is the number of samples and parameters, respectively. The EFIM is calculated as a matrix product in line $13$, normalized by the number of samples. This matrix is then stored in \textbf{self.fim}

After calculating the EFIM, its eigenvalue spectrum can be calculated as 

\begin{lstlisting}[language=python, numbers=left]
eigenvalue_spectrum = fim.eigen(x)
\end{lstlisting}
This performs a simple eigenvalue decomposition of \textbf{self.fim} using numpy's \textbf{linalg.eigh} to extract the eigenvalues. Because the EFIM is often highly degenerate, some of the lower lying eigenvalues turn out negative, likely because of floating-point errors. To combat this, any eigenvalue lower than $10^{-25}$ is set to this value. 

%================================================================
\subsection{Trajectory Length}\label{sec:TrajectoryLengthImplement}
%================================================================
Assume we have a \textbf{NeuralNetwork} object and a trajectory $\boldsymbol{x}(t_i)$, as described in \autoref{sec:TrajectoryLength}. Then, we can calculate the trajectory length \autoref{eq:TrajectoryLengthDiscrete} of the resulting outputs of each layer using the class \textbf{TrajectoryLength}:

\begin{lstlisting}[language=python, numbers=left]
from analysis import TrajectoryLength

tl = TrajectoryLength(network)
traj_len, traj_proj = tl.fit(x)
\end{lstlisting}
This produces two python lists: \textbf{traj\_len} containing the trajectory length of the layer outputs and \textbf{traj\_proj} containing the layer outputs themselves, projected down onto 2D for visualization. The projection was done using scikit-learn's \cite{scikit-learn} PCA decomposition. 


%================================================================
\section{Numerical Experiments}\label{sec:Numerical Experiments}
%================================================================
For easy reading, we will present hyper-parameters and configuration details in \autoref{chap:results_discussion} alongside the relevant results and discussion. However, for sake of tidiness, we will present and discuss configuration choices that appear frequently in the analysis in this section.

%================================================================
\subsection{Initialization}\label{sec:Initialization}
%================================================================
For QNNs and QCNs, the parameters will be initialized uniformly as $\theta_i \sim U(-\pi, \pi)$. Note that Pauli rotations(used in the simple ansatz \autoref{eq:simple ansatz}) have a periodicity of $2\pi$, i.e. $R_j(x) = R_j(x+2\pi)$, so all possible rotation angles can be realized using this initialization. Thus, it is possible to reach the whole space of models defined by the architecture. Initializations with this characteristic is often used for machine learning models based on PQCs \cite{abbas2020power, skolik2020layerwise}.

For DNNs, we will use the popular Xavier initialization \cite{xavier}, which is the default initialization used by pyTorch\cite{pytorch} when using densely connected layers. The Xavier initialization is obtained by sampling the weights and biases $\boldsymbol{\theta^{l}}$ of layer $l$ uniformly as 
\begin{equation}
    \theta^{l} \sim U\big(-\frac{1}{\sqrt{n}},\frac{1}{\sqrt{n}}\big),
\end{equation}
where $n$ is the number nodes in the previous layer. 

%================================================================
\subsection{Pre-processing Data}\label{sec:Pre-processing Input}
%================================================================
For QNNs and QCNs, features will be min-max scaled such that $x_i \in [-\frac{\pi}{2}, \frac{\pi}{2}]$. This is deliberately half the periode of Pauli rotations, which are used when performing qubit encoding (\autoref{sec:QubitEncoding}). If inputs were rather scaled to one period, i.e. $x_i \in [-\pi, \pi]$, extremal inputs would result in the same quantum state after encoding. Since mapping of different data point to the same quantum state can potentially inhibit learning, we opt for the original way of scaling. 
For DNNs, we apply standardization of the input, as explained in \autoref{sec:Scaling Features} by subtracting the mean and dividing by the standard deviation, feature-wise.

To scale the data, we use the scalers included in scikit-learn's \cite{scikit-learn}. They can be applied the following way:
\begin{lstlisting}[language=python, numbers=left]
from sklearn.preprocessing import StandardScaler, MinMaxScaler

standard = StandardScaler()
x_train_standard = standard.fit_transform(x_train)
x_test_standard = standard.transform(x_test)

minmax = MinMaxScaler(feature_range=(-np.pi/2, np.pi/2))
x_train_minmax = standard.fit_transform(x_train)
x_test_minmax = standard.transform(x_test)
\end{lstlisting}
Note that when using a training and test set \textbf{x\_train} and \textbf{x\_test}, like in the above code, the test set must be scaled after the training data. In practice, it should not be scaled together with the training data, as it is usually not available when training the model.

To perform feature reduction using PCA, as described in \autoref{sec:Principal Component Analysis}, we will again use scikit-learn. It can be implemented using:

\begin{lstlisting}[language=python, numbers=left]
from sklearn.decomposition import PCA

standard = StandardScaler()
x_train = standard.fit_transform(x_train)
x_test = standard.transform(x_test)

pca = PCA(n_components=4)
x_train = pca.fit_transform(x_train)
x_test = pca.fit_transform(x_test)
\end{lstlisting}
Note that we first perform a standardization of the data. This is to insure that the amount of variance the features contribute is not affected their units and scaling.


%================================================================
\subsection{Optimization}\label{sec:Optimization}
%================================================================
We use Adam, as presented in \autoref{sec:AdamOptimizer}, to optimize all models in this thesis. We use default hyper-parameters suggested by the authors, \citet{kingma2017adam}, together with a learning rate of $lr=0.1$. This is the same learning rate as used by \citet{abbas2020power} for training QNNs. Being a relatively high learning rate, it leads to quick optimization of the models. This is a useful property, as each training iteration can be quite time consuming due to the overhead associated with simulating quantum circuits on classical hardware.

%================================================================
\subsection{Configuring QCNs and DNNs}\label{sec:Configuring QCNs and DNNs}
%================================================================
Unless specified otherwise, the outputs of intermediate layers of QCNs withwill be scaled to the interval $a_i^{(l)} \in [-\pi, \pi]$. Using the same argument about the periodicity of Pauli rotations from \autoref{sec:Initialization}, this enables the outputs of one layer to potentially realize any rotation angle in the next layer. For the last layer, the output will be scaled to $a_i^{(L)} \in [0, 1]$. This is sufficient, given that the target $y$ is scaled to within this interval. 

For DNNs, we will be using tanh activations on all hidden layers. This is partly because it is a hugely popular choice, known to produce fast converging neural models\cite{hands-on}. Further, tanh is also a bounded function, returning values on the interval $[-1, 1]$, unlike the also popular activation function, namly ReLU. This results in the outputs of intermediate layers to be bounded as well, like for QCNs, making them easier to compare.





















